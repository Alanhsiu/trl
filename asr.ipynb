{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### faster whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size_tiny = \"tiny\"\n",
    "model_size_medium = \"medium\"\n",
    "model_size_large = \"large\"\n",
    "model_size_large_v2 = \"large-v2\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "model_1 = WhisperModel(model_size_tiny, device=\"cpu\", compute_type=\"int8\")\n",
    "model_2 = WhisperModel(model_size_medium, device=\"cuda\", compute_type=\"float16\")\n",
    "model_3 = WhisperModel(model_size_large, device=\"cuda\", compute_type=\"float16\")\n",
    "model_4 = WhisperModel(model_size_large_v2, device=\"cuda\", compute_type=\"float16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from jiwer import wer\n",
    "\n",
    "def reward_wer(reference, hypothesis):\n",
    "    raw_wer = wer(reference, hypothesis)\n",
    "    normalized = min(raw_wer, 1.0)\n",
    "    return 1 - normalized\n",
    "\n",
    "# original_transcription[386] = \"words\"\n",
    "# original_transcription[474] = \"milk\"\n",
    "# original_transcription[477] = \"well\"\n",
    "# original_transcription[693] = \"yes\"\n",
    "# original_transcription[1294] = \"i can do that\"\n",
    "\n",
    "def test(asr_model, beam_size=1, num=0):\n",
    "    # get all examples which name contains \"example_generate_data_3\" in directory \"output/1124-2204\", i=0 to 39\n",
    "    # ground_truths = [\"but i will be in a minute\", \"i dont know\", \"why not\",\"goodbye\", \"look\"]\n",
    "    # name = f\"example_generate_data_{num}\"\n",
    "    # wavs = [f\"output/1124-2204/{name}_item_{i}.wav\" for i in range(40)]\n",
    "    name = \"example_generate_eval_-1\"\n",
    "    index_map = {\n",
    "        0: 386,\n",
    "        1: 474,\n",
    "        2: 477,\n",
    "        3: 693,\n",
    "        4: 1294\n",
    "    }\n",
    "    ground_truths = [\n",
    "        \"words\",\n",
    "        \"milk\",\n",
    "        \"well\",\n",
    "        \"yes\",\n",
    "        \"i can do that\"\n",
    "    ]\n",
    "    wavs = [f\"output/1124-2204/{name}_data_{index_map[num]}_item_{i}.wav\" for i in range(10)]\n",
    "    \n",
    "    rewards = []\n",
    "    for wav in wavs:\n",
    "        segments, info = asr_model.transcribe(wav, beam_size=beam_size)\n",
    "        segments = list(segments)\n",
    "        modified_text = ''.join(char for char in segments[0].text if char not in string.punctuation).lower().strip()\n",
    "        ground_truth = ground_truths[num]\n",
    "        reward = reward_wer(modified_text, ground_truth)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Beam size: 1\n",
      "Average reward for data 0: 60.00%\n",
      "Time: 6.36s\n",
      "Average reward for data 1: 90.00%\n",
      "Time: 4.50s\n",
      "Average reward for data 2: 10.00%\n",
      "Time: 6.24s\n",
      "Average reward for data 3: 100.00%\n",
      "Time: 4.03s\n",
      "Average reward for data 4: 46.50%\n",
      "Time: 4.62s\n",
      "Beam size: 5\n",
      "Average reward for data 0: 60.00%\n",
      "Time: 6.38s\n",
      "Average reward for data 1: 90.00%\n",
      "Time: 4.33s\n",
      "Average reward for data 2: 10.00%\n",
      "Time: 6.25s\n",
      "Average reward for data 3: 100.00%\n",
      "Time: 4.05s\n",
      "Average reward for data 4: 56.50%\n",
      "Time: 4.10s\n",
      "--------------------\n",
      "Model 2\n",
      "Beam size: 1\n",
      "Average reward for data 0: 10.00%\n",
      "Time: 4.25s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 2.77s\n",
      "Average reward for data 2: 0.00%\n",
      "Time: 5.18s\n",
      "Average reward for data 3: 90.00%\n",
      "Time: 2.40s\n",
      "Average reward for data 4: 40.83%\n",
      "Time: 2.57s\n",
      "Beam size: 5\n",
      "Average reward for data 0: 10.00%\n",
      "Time: 3.45s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 3.09s\n",
      "Average reward for data 2: 0.00%\n",
      "Time: 4.87s\n",
      "Average reward for data 3: 80.00%\n",
      "Time: 2.65s\n",
      "Average reward for data 4: 47.50%\n",
      "Time: 2.96s\n",
      "--------------------\n",
      "Model 3\n",
      "Beam size: 1\n",
      "Average reward for data 0: 50.00%\n",
      "Time: 3.07s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 3.11s\n",
      "Average reward for data 2: 10.00%\n",
      "Time: 3.08s\n",
      "Average reward for data 3: 80.00%\n",
      "Time: 3.07s\n",
      "Average reward for data 4: 55.00%\n",
      "Time: 3.24s\n",
      "Beam size: 5\n",
      "Average reward for data 0: 50.00%\n",
      "Time: 3.46s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 3.30s\n",
      "Average reward for data 2: 10.00%\n",
      "Time: 3.33s\n",
      "Average reward for data 3: 80.00%\n",
      "Time: 3.34s\n",
      "Average reward for data 4: 57.00%\n",
      "Time: 3.60s\n",
      "--------------------\n",
      "Model 4\n",
      "Beam size: 1\n",
      "Average reward for data 0: 50.00%\n",
      "Time: 5.20s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 3.12s\n",
      "Average reward for data 2: 0.00%\n",
      "Time: 6.81s\n",
      "Average reward for data 3: 50.00%\n",
      "Time: 3.11s\n",
      "Average reward for data 4: 25.00%\n",
      "Time: 5.80s\n",
      "Beam size: 5\n",
      "Average reward for data 0: 60.00%\n",
      "Time: 4.58s\n",
      "Average reward for data 1: 100.00%\n",
      "Time: 3.45s\n",
      "Average reward for data 2: 0.00%\n",
      "Time: 5.80s\n",
      "Average reward for data 3: 40.00%\n",
      "Time: 3.61s\n",
      "Average reward for data 4: 25.00%\n",
      "Time: 7.35s\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def test_different_model_sizes():\n",
    "    # for model in [model_1, model_2, model_3, model_4]:\n",
    "    models = [model_1, model_2, model_3, model_4]\n",
    "    for m in range(1,5):\n",
    "        print(f\"Model {m}\")\n",
    "        model = models[m-1]\n",
    "        \n",
    "        print(f\"Beam size: 1\")\n",
    "        for num in range(5):\n",
    "            start = time.time()\n",
    "            rewards = test(model, num=num)\n",
    "            print(f\"Average reward for data {num}: {sum(rewards) / len(rewards):.2%}\")\n",
    "            print(f\"Time: {time.time() - start:.2f}s\")\n",
    "            \n",
    "        print(f\"Beam size: 5\")\n",
    "        for num in range(5):\n",
    "            start = time.time()\n",
    "            rewards = test(model, beam_size=5, num=num)\n",
    "            print(f\"Average reward for data {num}: {sum(rewards) / len(rewards):.2%}\")\n",
    "            print(f\"Time: {time.time() - start:.2f}s\")\n",
    "            \n",
    "        print(\"--------------------\")\n",
    "            \n",
    "test_different_model_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_size = 5\n",
    "\n",
    "# start = time.time()\n",
    "# rewards = test(model, beam_size)\n",
    "# print(f\"Reward: {rewards}\")\n",
    "# print(f\"Average reward: {sum(rewards) / len(rewards):.2%}\")\n",
    "# print(f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "# start = time.time()\n",
    "# rewards = test(model_2, beam_size)\n",
    "# print(f\"Reward: {rewards}\")\n",
    "# print(f\"Average reward: {sum(rewards) / len(rewards):.2%}\")\n",
    "# print(f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "# start = time.time()\n",
    "# rewards = test(model_3, beam_size)\n",
    "# print(f\"Reward: {rewards}\")\n",
    "# print(f\"Average reward: {sum(rewards) / len(rewards):.2%}\")\n",
    "# print(f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "# start = time.time()\n",
    "# rewards = test(model_4, beam_size)\n",
    "# print(f\"Reward: {rewards}\")\n",
    "# print(f\"Average reward: {sum(rewards) / len(rewards):.2%}\")\n",
    "# print(f\"Time: {time.time() - start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_size_large = \"medium\"\n",
    "# model_3 = WhisperModel(model_size_large, device=\"cuda\", compute_type=\"float16\")\n",
    "# start = time.time()\n",
    "# rewards = [test(model_3) for _ in range(10)]\n",
    "# print(f\"Average reward: {sum(rewards) / len(rewards):.2%}\")\n",
    "# print(f\"Time: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "text1 = \" Neighboring fields\"\n",
    "text2 = \"neighboring fields\"\n",
    "error_rate = wer(text1, text2)\n",
    "print(error_rate)\n",
    "\n",
    "print(f\"Word Error Rate: {error_rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_wer(reference, hypothesis):\n",
    "    raw_wer = wer(reference, hypothesis)\n",
    "    normalized = min(raw_wer, 1.0)\n",
    "    return 1 - normalized\n",
    "\n",
    "text1 = \"make a ring for you\"\n",
    "text2 = \"neighboring fields\"\n",
    "\n",
    "reward = reward_wer(text1, text2)\n",
    "print(f\"Reward: {reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text = \"Neighboring fields.\" # 8\n",
    "text = \"But I will be, in a minute.\" # 16\n",
    "text = \"Will you?\" # 65\n",
    "text = \"Do they?\" # 100\n",
    "text = \"Don't you?\" # 102\n",
    "\n",
    "text = \"I don't know\" # 105\n",
    "text = \"Why is it?\" # 112\n",
    "text = \"Why not?\" # 132\n",
    "text = \"Good-bye\" # 140\n",
    "text = \"The idea!\" # 184\n",
    "\n",
    "\n",
    "modified_text = ''.join(char for char in text if char not in string.punctuation).lower().strip()\n",
    "print(modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "text_list = [\"Neighboring fields.\", \"But I will be, in a minute.\", \"Will you?\", \"Do they?\", \"Don't you?\", \"I don't know\", \"Why is it?\", \"Why not?\", \"Good-bye\", \"The idea!\"]\n",
    "index_list = [8, 16, 65, 100, 102, 105, 112, 132, 140, 184]\n",
    "for i, text in enumerate(text_list):\n",
    "    modified_text = ''.join(char for char in text if char not in string.punctuation).lower().strip()\n",
    "    print(f\"{index_list[i]} {modified_text}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
