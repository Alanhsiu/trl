{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL about text-guided voice conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "import sys\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load the model\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = AutoModelForCausalLMWithValueHead.from_pretrained(ar_checkpoint)\n",
    "# model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(ar_checkpoint)\n",
    "model_ref = create_reference_model(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# define the path\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "if not os.path.exists(agent_output_dir):\n",
    "    os.makedirs(agent_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = load_from_disk(agent_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "# all_instruction_ids = []\n",
    "\n",
    "layer_len = 8\n",
    "data_len = 3\n",
    "# data_len = len(dataset)\n",
    "print(\"data_len:\", data_len)\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):\n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    # all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the length of all src encodec\n",
    "for i in range(data_len):\n",
    "    print(f\"src_encodec_{i} len:\", len(all_src_encodec[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list = []\n",
    "for i in range(data_len):\n",
    "    observation_list.append(\n",
    "        {\n",
    "            \"input\": \"\",\n",
    "            \"src_encodec\": all_src_encodec[i],\n",
    "            \"instruction\": all_instruction[i],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# # pop the first one\n",
    "observation_list.pop(0)\n",
    "all_instruction.pop(0)\n",
    "observation_list.pop(0)\n",
    "all_instruction.pop(0)\n",
    "print(\"observation_list:\", observation_list)\n",
    "print(\"all_instruction:\", all_instruction)\n",
    "\n",
    "\n",
    "# for i in range(data_len):\n",
    "#     observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/TextRL/vc\")\n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "args_predict = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=0, device=device)\n",
    "\n",
    "decode_ar = get_ar_prediction(args_predict, model, nar_model, tokenizer, nar_tokenizer, all_src_encodec[0], all_instruction[0], 0)\n",
    "\n",
    "decode_ar_str = tokenizer.convert_tokens_to_string(\n",
    "                [f\"v_tok_{u}\" for u in decode_ar]\n",
    "            )\n",
    "print(\"Decode AR:\", decode_ar)\n",
    "print(\"Decode AR str: \", decode_ar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "log_dir = f\"logs/{ts}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "lr= 0.0000141\n",
    "batch_size = 1\n",
    "mini_batch_size = 1\n",
    "\n",
    "\n",
    "ppo_config = PPOConfig(batch_size=1, mini_batch_size=1, log_with='tensorboard', learning_rate=lr, project_kwargs={'logging_dir': log_dir})\n",
    "ppo_trainer = PPOTrainer(config = ppo_config, model = model, ref_model=model_ref, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\") \n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction_v2\n",
    "\n",
    "\n",
    "def get_reward(predicted_list, single_src_encodec, single_instruction, episode_counter,finish):\n",
    "    reward = 0\n",
    "    # predicted_list will be one text of \"v_tok_410v_tok_411v_tok_595 ...\"\"\n",
    "    # predicted_token will be a list of [v_tok_410, v_tok_411, v_tok_595 ...]\n",
    "    \n",
    "    if finish or len(predicted_list) >= 1000:\n",
    "        try:\n",
    "            # predicted_tokens = predicted_list[0][1:-1]\n",
    "            predicted_tokens = [f'v_tok_{u}' for u in predicted_list.split(\"v_tok_\")[1:]]\n",
    "            predicted_ids = tokenizer.convert_tokens_to_ids([f\"{u}\" for u in predicted_tokens])\n",
    "            print(\"predict length: \", len(predicted_ids))\n",
    "            print(\"predicted_tokens: \", predicted_tokens)\n",
    "            print(\"predicted_ids: \", predicted_ids)\n",
    "\n",
    "            decode_ar = get_ar_prediction_v2(\n",
    "                args_predict,\n",
    "                predicted_ids,\n",
    "                nar_model,\n",
    "                tokenizer,\n",
    "                nar_tokenizer,\n",
    "                single_src_encodec,\n",
    "                single_instruction,\n",
    "                episode_counter,\n",
    "            )\n",
    "            # print(\"decode_ar:\", decode_ar)\n",
    "            \n",
    "            # use nisqa to get the reward\n",
    "            args_nisqa = {\n",
    "                \"mode\": \"predict_file\",\n",
    "                \"pretrained_model\": f\"{base_path}/NISQA/weights/nisqa.tar\",\n",
    "                \"deg\": f\"{base_path}/output/{ts}/example.wav\",\n",
    "                \"data_dir\": None,\n",
    "                \"output_dir\": f\"{base_path}/NISQA/result/\",\n",
    "                \"csv_file\": None,\n",
    "                \"csv_deg\": None,\n",
    "                \"num_workers\": 0,\n",
    "                \"bs\": 1,\n",
    "                \"ms_channel\": None,\n",
    "            }\n",
    "            args_nisqa[\"tr_bs_val\"] = args_nisqa[\"bs\"]\n",
    "            args_nisqa[\"tr_num_workers\"] = args_nisqa[\"num_workers\"]\n",
    "\n",
    "            nisqa = nisqaModel(args_nisqa)\n",
    "            prediction = nisqa.predict()\n",
    "            reward = float(prediction[\"mos_pred\"].iloc[0])*10\n",
    "            # reward = float(prediction[\"mos_pred\"].iloc[0])-3.0\n",
    "            print(\n",
    "                \"Length of predicted_list:\",\n",
    "                len(predicted_list),\n",
    "                \", Reward:\",\n",
    "                reward,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            reward = 0\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# output_log_path = f\"logs/log_{ts}.log\"\n",
    "\n",
    "# logger = logging.getLogger(__name__)\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# handlers = logger.handlers[:]\n",
    "# for handler in handlers:\n",
    "#     logger.removeHandler(handler)\n",
    "\n",
    "# file_handler = logging.FileHandler(output_log_path)\n",
    "# logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from trl.core import respond_to_batch\n",
    "\n",
    "start_time = time.time()\n",
    "output_file_path = f\"logs/{ts}/output_{ts}.txt\"\n",
    "\n",
    "# with open(output_file_path, \"w\") as f:\n",
    "#     original_stdout = sys.stdout\n",
    "#     sys.stdout = f\n",
    "try:\n",
    "    for iteration in tqdm(range(100)):\n",
    "        query_txt = decode_ar_str\n",
    "        query_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\")\n",
    "        query_tensor = query_tensor.to(device)\n",
    "        \n",
    "        # FILEPATH: /work/b0990106x/trl/textrl.ipynb\n",
    "        response_tensor = respond_to_batch(model, query_tensor, txt_len=2000)\n",
    "        # print(\"response_tensor:\", response_tensor)\n",
    "        # response_tensor = model.generate(query_tensor)\n",
    "        response_text = tokenizer.decode(response_tensor[0], skip_special_tokens=True)\n",
    "        # Mimic batch structure\n",
    "        batch = {\n",
    "            \"query\": query_tensor,\n",
    "            \"response\": response_text\n",
    "        }\n",
    "        reward_float = get_reward(response_text, all_src_encodec[0], all_instruction[0], iteration, True)\n",
    "        reward_length = len(tokenizer.decode(response_tensor[0], skip_special_tokens=True))\n",
    "        reward = torch.tensor([float(reward_float)], device=device)\n",
    "        \n",
    "        train_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], [reward])\n",
    "        ppo_trainer.log_stats(train_stats, batch, reward)\n",
    "\n",
    "        print(f\"Iteration {iteration + 1}, Reward: {reward.item()}, Length: {len(response_tensor[0])}, Reward_Length: {reward_length}, Predicted Text: {response_text}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "    \n",
    "    # sys.stdout = original_stdout   \n",
    "\n",
    "print(\"used time: \", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
