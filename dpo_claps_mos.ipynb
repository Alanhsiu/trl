{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\")\n",
    "import importlib\n",
    "import vc\n",
    "importlib.reload(vc)\n",
    "import torch\n",
    "from vc.trainer_encodec_vc_inference import pack_inputs_v2, get_ar_prediction_get_audio, get_ar_prediction_audio_batch\n",
    "from types import SimpleNamespace\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from trl import DPOTrainer, DPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from dpo_eval import get_reward_claps ,eval_dpo_claps_batch, convert_array_to_tensor_format\n",
    "from dpo_eval import process_and_get_mos_reward, eval_dpo_mos\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "sys.path.append('/work/b0990106x/trl/CLAPS')\n",
    "from CLAPS.inference import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate_output_batch(\n",
    "        model,\n",
    "        ar_model, \n",
    "        nar_model, \n",
    "        ar_tokenizer, \n",
    "        nar_tokenizer, \n",
    "        clap_model,\n",
    "        accelerator,\n",
    "        src_encodec: list, \n",
    "        instruction: list, \n",
    "        args_predict: SimpleNamespace, \n",
    "        episode_counter: int = 0, \n",
    "        base_path: str = \"/work/b0990106x/trl\", \n",
    "        temperature: float = 1.0\n",
    ") -> tuple[float, str]:\n",
    "    '''\n",
    "    Generates output from AR model, synthesize the audio, and evaluate the audio using NISQA.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            reward(float): The reward of the audio.\n",
    "            tokenized_decode_ar(str): The tokenized output of the AR model - first layer.\n",
    "    '''\n",
    "    # Generate predictions using the AR model\n",
    "    audio_list, decode_ar_list = get_ar_prediction_audio_batch(\n",
    "        args_predict, model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter, temperature=temperature\n",
    "    )\n",
    "    # extract the instruction from the list \n",
    "    reward_list,tokenized_decode_ar_list = [], []\n",
    "\n",
    "    for i, audio in enumerate(audio_list): \n",
    "        # audio ---> tensor([])\n",
    "        if audio is not None:\n",
    "            tensor_audio = convert_array_to_tensor_format(audio)\n",
    "            if tensor_audio[0].shape[0]==1:\n",
    "                tensor_audio[0] = tensor_audio[0].squeeze(0)\n",
    "            # print(tensor_audio)\n",
    "            reward_claps = get_reward_claps(clap_model=clap_model, accelerator=accelerator, prompts = instruction[i], wavs = tensor_audio)\n",
    "            reward_mos = process_and_get_mos_reward(model=ar_model, nar_model=nar_model, ar_tokenizer=ar_tokenizer, nar_tokenizer=nar_tokenizer, src_encodec=src_encodec[i], instruction=instruction[i], args_predict=args_predict, episode_counter=episode_counter, base_path=base_path)\n",
    "            reward = (reward_claps + reward_mos/5) / 2\n",
    "        else: \n",
    "            reward = 0\n",
    "        reward_list.append(reward)\n",
    "    \n",
    "    for decode_ar in decode_ar_list:\n",
    "        list_decode_ar = decode_ar.flatten().tolist()   \n",
    "        filtered_decode_ar_list = list_decode_ar[2:-1]\n",
    "        decode_ar_tokens = ar_tokenizer.convert_ids_to_tokens(filtered_decode_ar_list)\n",
    "        tokenized_decode_ar = ar_tokenizer.convert_tokens_to_string(decode_ar_tokens)\n",
    "        tokenized_decode_ar_list.append(tokenized_decode_ar)\n",
    "        \n",
    "    return reward_list, tokenized_decode_ar_list\n",
    "\n",
    "def extract_data_from_json(file_path: str) -> Tuple[List[list], List[str], List[list]]:\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file and extracts 'src_encodec', 'instruction', and 'tgt_encodec'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            all_src_encodec (List[list]): A list containing the 'src_encodec' data from each item in the JSON file.\n",
    "            all_instruction (List[str]): A list containing the 'instruction' data from each item in the JSON file.\n",
    "            all_tgt_encodec (List[list]): A list containing the 'tgt_encodec' data from each item in the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    all_src_encodec = [item[\"src_encodec\"] for item in data]\n",
    "    all_instruction = [item[\"instruction\"] for item in data]\n",
    "\n",
    "    return all_src_encodec, all_instruction\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        model_ref,\n",
    "        ar_tokenizer,\n",
    "        train_dataset: Dataset,\n",
    "        val_dataset: Dataset,\n",
    "        model_output_dir: str,\n",
    "        beta: float,\n",
    "        resume_from_checkpoint: bool,\n",
    "        model_checkpoint: str,\n",
    "        learning_rate: float = 5e-07,\n",
    "        num_train_epochs: int = 200,\n",
    "        max_length: int = 1024*9,\n",
    "        max_prompt_length: int = 1024*9,\n",
    "        max_target_length: int = 1024*9,\n",
    "        per_device_train_batch_size: int = 1,\n",
    "        gradient_accumulation_steps: int = 1,\n",
    "        seed: int = 42\n",
    ") -> None:\n",
    "    '''\n",
    "    Train the DPO model and save the model.\n",
    "\n",
    "    Args:\n",
    "        model(AutoModelForSeq2SeqLMWithValueHead): The DPO model.\n",
    "        model_ref(AutoModelForCausalLM): The reference model.\n",
    "        ar_tokenizer(AutoTokenizer): The tokenizer.\n",
    "        train_dataset(Dataset): The training dataset.\n",
    "        val_dataset(Dataset): The validation dataset.\n",
    "        model_output_dir(str): The output directory for the model.\n",
    "        beta(float): The beta value.\n",
    "        resume_from_checkpoint(bool): Whether to resume from a checkpoint.\n",
    "        model_checkpoint(str): The path to the model\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    training_args = DPOConfig(\n",
    "        beta = beta,\n",
    "        output_dir = model_output_dir,\n",
    "        resume_from_checkpoint = model_checkpoint if resume_from_checkpoint else None,\n",
    "        seed = seed,\n",
    "        per_device_train_batch_size = per_device_train_batch_size,\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        learning_rate = learning_rate,\n",
    "        max_length = max_length,\n",
    "        max_prompt_length = max_prompt_length,\n",
    "        max_target_length = max_target_length,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps = 5000,\n",
    "        logging_dir = f\"{model_output_dir}/logs\"\n",
    "    )\n",
    "    \n",
    "    trainer = DPOTrainer(\n",
    "        model=model,\n",
    "        ref_model=model_ref,\n",
    "        args=training_args,\n",
    "        tokenizer=ar_tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    # trainer.save_model(f\"{model_output_dir}/dpo_model\")\n",
    "    model.config.to_json_file(f\"{model_output_dir}/config.json\")\n",
    "    # ar_tokenizer.save_pretrained(f\"{model_output_dir}/dpo_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_data_batch(sample_size: int, \n",
    "                       model,\n",
    "                        ar_model, \n",
    "                        nar_model, \n",
    "                        ar_tokenizer, \n",
    "                        nar_tokenizer, \n",
    "                        clap_model,\n",
    "                        accelerator,\n",
    "                        selected_src_encodec: List[list], \n",
    "                        selected_instruction: List[str],\n",
    "                        args_predict: SimpleNamespace, \n",
    "                        base_path: str = \"/work/b0990106x/trl\", \n",
    "                        temperature: float = 1.0, \n",
    "                        iteration: int = 0\n",
    ") -> Tuple[List[str], List[str], List[str], List[float], List[float], List[float]]:\n",
    "    # If sample size is 1, we cannot choose the best and worst outputs\n",
    "    if sample_size < 2:\n",
    "        raise ValueError(\"Parameter 'sample_size' must be greater than 1.\")\n",
    "\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = [], [], [], [], [], []\n",
    "\n",
    "    disable_tqdm = not os.isatty(1)\n",
    "    for i in tqdm(range(len(selected_src_encodec)), desc=\"Processing Data\", disable=disable_tqdm):\n",
    "        rewards, tokenized_outputs = [], []\n",
    "        size_of_packed_input = (\n",
    "            len(selected_src_encodec[i][0]) +\n",
    "            len(ar_tokenizer(selected_instruction[i])[\"input_ids\"][1:-1]) +\n",
    "            3\n",
    "        )\n",
    "        if 4 < size_of_packed_input <= 1024:\n",
    "            selected_src_encodec_list = [selected_src_encodec[i]]*sample_size\n",
    "            selected_instruction_list = [selected_instruction[i]]*sample_size\n",
    "            rewards, tokenized_outputs = generate_output_batch(\n",
    "                model=model,\n",
    "                ar_model=ar_model, \n",
    "                nar_model=nar_model, \n",
    "                ar_tokenizer=ar_tokenizer, \n",
    "                nar_tokenizer=nar_tokenizer,\n",
    "                src_encodec = selected_src_encodec_list,\n",
    "                instruction=selected_instruction_list, \n",
    "                clap_model=clap_model,\n",
    "                accelerator=accelerator,\n",
    "                args_predict=args_predict,\n",
    "                episode_counter=f\"data_{i}\",\n",
    "                base_path=base_path, \n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "        valid_rewards = [r for r in rewards if r is not None]\n",
    "        valid_outputs = [tokenized_outputs[j] for j in range(len(rewards)) if rewards[j] is not None]\n",
    "\n",
    "        if len(valid_rewards) >= 2:\n",
    "            max_reward_index = np.argmax(valid_rewards)\n",
    "            min_reward_index = np.argmin(valid_rewards)\n",
    "            average_reward = np.mean(valid_rewards)\n",
    "            chosen_output = valid_outputs[max_reward_index]\n",
    "            rejected_output = valid_outputs[min_reward_index]\n",
    "\n",
    "            obs_input = pack_inputs_v2(ar_tokenizer, selected_src_encodec[i], selected_instruction[i])\n",
    "            tokenize_input = ar_tokenizer.convert_ids_to_tokens(obs_input)\n",
    "            tokenize_input_str = ar_tokenizer.convert_tokens_to_string(tokenize_input)\n",
    "            prompts.append(tokenize_input_str)\n",
    "\n",
    "            chosen.append(chosen_output)\n",
    "            chosen_rewards.append(valid_rewards[max_reward_index])\n",
    "            rejected.append(rejected_output)\n",
    "            rejected_rewards.append(valid_rewards[min_reward_index])\n",
    "            average_rewards.append(average_reward)\n",
    "        else:\n",
    "            print(f\"Not enough valid rewards for data index {i}\")\n",
    "\n",
    "    # If there is only one data, we need to double the data because we need it for training set and validation set\n",
    "    if len(selected_src_encodec) == 1:\n",
    "        chosen *= 2\n",
    "        rejected *= 2\n",
    "        prompts *= 2\n",
    "        chosen_rewards *= 2\n",
    "        rejected_rewards *= 2\n",
    "        average_rewards *= 2    \n",
    "    \n",
    "    return chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards\n",
    "\n",
    "def generate_data(model,\n",
    "                  ar_model, \n",
    "                  ar_tokenizer, \n",
    "                  nar_model, \n",
    "                  nar_tokenizer, \n",
    "                  clap_model,\n",
    "                  accelerator,\n",
    "                  selected_src_encodec: List[list], \n",
    "                  selected_instruction: List[str],\n",
    "                  args_predict: SimpleNamespace, \n",
    "                  sample_size: int, \n",
    "                  iteration: int, \n",
    "                  agent_output_dir: str, \n",
    "                  base_path: str = \"/work/b0990106x/trl\", \n",
    "                  temperature: float = 1.0\n",
    ") -> Tuple[dict, List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Generates data for the dataset and saves info to a JSON file.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            data_for_dataset (dict): A dictionary containing the data for the dataset.\n",
    "            chosen_rewards (List[float]): A list of rewards for the chosen outputs.\n",
    "            rejected_rewards (List[float]): A list of rewards for the rejected outputs.\n",
    "    \"\"\"\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = process_data_batch(\n",
    "        sample_size=sample_size,\n",
    "        model=model,\n",
    "        ar_model=ar_model,\n",
    "        nar_model=nar_model,\n",
    "        ar_tokenizer=ar_tokenizer,\n",
    "        nar_tokenizer=nar_tokenizer,\n",
    "        selected_src_encodec=selected_src_encodec,\n",
    "        selected_instruction=selected_instruction,\n",
    "        args_predict=args_predict,\n",
    "        base_path=base_path,\n",
    "        temperature=temperature,\n",
    "        iteration = iteration,\n",
    "        clap_model=clap_model,\n",
    "        accelerator=accelerator\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompts,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "        \"chosen_rewards\": chosen_rewards,\n",
    "        \"rejected_rewards\": rejected_rewards,\n",
    "        \"average_rewards\": average_rewards\n",
    "    }\n",
    "\n",
    "    with open(f\"{agent_output_dir}/data_iter_{iteration}.json\", \"w\") as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "    data_for_dataset = {key: data[key] for key in [\"prompt\", \"chosen\", \"rejected\"]}\n",
    "\n",
    "    return data_for_dataset, chosen_rewards, rejected_rewards\n",
    "\n",
    "def train_iteration(model, \n",
    "                    model_checkpoint,\n",
    "                    iteration, \n",
    "                    data_size, \n",
    "                    sample_size, \n",
    "                    ar_model, \n",
    "                    ar_tokenizer,\n",
    "                    nar_model, \n",
    "                    nar_tokenizer,\n",
    "                    all_src_encodec, \n",
    "                    all_instruction, \n",
    "                    args_predict, \n",
    "                    agent_output_dir,\n",
    "                    model_output_dir_base, \n",
    "                    clap_model,\n",
    "                    accelerator,\n",
    "                    beta = 0.1, \n",
    "                    temperature = 1.0,\n",
    "                    base_path=\"/work/b0990106x/trl\",\n",
    "                    resume_from_checkpoint = False,\n",
    "                    learning_rate = 5e-07,\n",
    "                    num_train_epochs = 100,\n",
    "                    max_length = 1024*9,\n",
    "                    max_prompt_length = 1024*9,\n",
    "                    max_target_length = 1024*9,\n",
    "                    per_device_train_batch_size = 1,\n",
    "                    gradient_accumulation_steps = 1,\n",
    "                    seed = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes one training iteration: generates data, trains the model, and saves the output.\n",
    "    \"\"\"\n",
    "    # print(f\"Iteration {iteration}\")\n",
    "\n",
    "    # ar_model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "    # ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "    # ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "    # nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "    # nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "\n",
    "    selected_src_encodec = all_src_encodec[:data_size]\n",
    "    selected_instruction = all_instruction[:data_size]\n",
    "\n",
    "    data_for_dataset, chosen_rewards, rejected_rewards = generate_data(model=model, \n",
    "                                                                    ar_model=ar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_model=nar_model,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    selected_src_encodec=selected_src_encodec,\n",
    "                                                                    selected_instruction=selected_instruction,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    sample_size=sample_size,\n",
    "                                                                    iteration=iteration,\n",
    "                                                                    agent_output_dir=agent_output_dir,\n",
    "                                                                    base_path=base_path,\n",
    "                                                                    temperature=temperature,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator)\n",
    "\n",
    "    dataset = Dataset.from_dict(data_for_dataset)\n",
    "    dataset_dict = dataset.train_test_split(test_size=0.1, shuffle=True, seed=seed)\n",
    "    train_dataset = dataset_dict[\"train\"]\n",
    "    val_dataset = dataset_dict[\"test\"]\n",
    "\n",
    "    model_output_dir = f\"{model_output_dir_base}/iter_{iteration}\"\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    # model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "    model_ref = create_reference_model(model)\n",
    "    \n",
    "    train_model(model=model,\n",
    "                model_ref=model_ref,\n",
    "                ar_tokenizer=ar_tokenizer,\n",
    "                train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                model_output_dir=model_output_dir,\n",
    "                beta=beta,\n",
    "                resume_from_checkpoint=resume_from_checkpoint,\n",
    "                model_checkpoint=model_checkpoint,\n",
    "                learning_rate = learning_rate,\n",
    "                num_train_epochs = num_train_epochs,\n",
    "                max_length = max_length,\n",
    "                max_prompt_length = max_prompt_length,\n",
    "                max_target_length = max_target_length,\n",
    "                per_device_train_batch_size = per_device_train_batch_size,\n",
    "                gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "                seed = seed)\n",
    "\n",
    "    return f\"{model_output_dir}/dpo_model\", chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 1020-2012\n",
      "length of all_src_encodec: 9254\n",
      "length of all_instruction: 9254\n"
     ]
    }
   ],
   "source": [
    "# Load all data\n",
    "selected_src_encodec, selected_instruction = extract_data_from_json('dpo_data/src_encodec.json')\n",
    "\n",
    "# Define paths and device\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define timestamp\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# Define paths\n",
    "model_output_dir = os.path.join(base_path, \"model_output\", ts) # Location where the model are saved\n",
    "agent_output_dir = os.path.join(base_path, \"output\", ts) # Path of saving the generated audio for reward model to evaluate\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(agent_output_dir, exist_ok=True)\n",
    "\n",
    "seed = 42 # Training: seed\n",
    "\n",
    "# Define arguments \n",
    "args_predict = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=seed, device=device)\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "# Models and Iterations\n",
    "model_checkpoint = ar_checkpoint # Prepare: set the initial model checkpoint\n",
    "sample_size = 10 # Prepare Dataset: generate how many outputs to select max and min for chosen and rejected (original: 10)\n",
    "num_iterations = 1000  # Training: train how many iterations (original: 100)\n",
    "train_selected_indices = [9]\n",
    "# train_selected_indices = random.sample(range(len(selected_src_encodec)), 5) # Training: train on selected data indicies from all_src_encodec\n",
    " # Training: train on selected data indicies from all_src_encodec\n",
    "data_size_per_iteration = len(train_selected_indices) # Training: each iteration will train how many data\n",
    "\n",
    "# Define Training Configuration\n",
    "beta = 0.1 # Training: beta value for DPO\n",
    "learning_rate = 5e-07 # Training: learning rate (original: 5e-07)\n",
    "num_train_epochs = 3 # Training: number of training epochs\n",
    "max_length = 1024*9 # Training: max length of the model\n",
    "max_prompt_length = 1024*9 # Training: max length of the prompt\n",
    "max_target_length = 1024*9 # Training: max length of the target\n",
    "per_device_train_batch_size = 1 # Training: batch size\n",
    "gradient_accumulation_steps = 1 # Training: gradient accumulation steps\n",
    "\n",
    "# Evaluation Configuration\n",
    "eval_train = True # Evaluation: evaluate on training data or not\n",
    "eval_test = False # Evaluation: evaluate on testing data or not\n",
    "eval_train_indices = train_selected_indices # Evaluation: evaluate on training data indicies from all_src_encodec\n",
    "eval_test_indices = random.sample(range(len(selected_src_encodec)), 5) # Evaluation: evaluate on testing data indicies from all_src_encodec\n",
    "eval_train_data_len = 1000 # Evaluation: evaluate how many training data\n",
    "eval_test_data_len = len(eval_test_indices) # Evaluation: evaluate how many testing data\n",
    "num_eval = 10 # Evaluation: evaluate how many times per data (original: 10)\n",
    "eval_frequency = 1 # Evaluation: evaluate every how many iterations\n",
    "# Define temperature\n",
    "# eval_selected_indices = random.sample(range(len(all_src_encodec)), eval_data_len) # Evaluation: select 10 data for evaluation\n",
    "print(f\"length of all_src_encodec: {len(selected_src_encodec)}\") # ~ 9000 data\n",
    "print(f\"length of all_instruction: {len(selected_instruction)}\") # ~ 9000 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/s3prl/upstream/wavlm/expert.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/work/b0990106x/trl/CLAPS/inference.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /work/b0990106x/trl/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "sr = 24000\n",
    "text_enc_name = \"google/flan-t5-large\"\n",
    "text_enc_dim = 1024\n",
    "text_blstm_dim = 256\n",
    "speech_enc_name = \"wavlm\"\n",
    "speech_enc_dim = 768\n",
    "speech_blstm_dim = 256\n",
    "rep_dim = 512\n",
    "sub_dim = 0\n",
    "n_sub = 1\n",
    "ckpt_pth=f'{base_path}/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000'\n",
    "project_dir = \"cp_claps\"\n",
    "\n",
    "a = argparse.Namespace(\n",
    "        sr=sr,\n",
    "        text_enc_name=text_enc_name,\n",
    "        text_enc_dim=text_enc_dim,\n",
    "        text_blstm_dim=text_blstm_dim,\n",
    "        speech_enc_name=speech_enc_name,\n",
    "        speech_enc_dim=speech_enc_dim,\n",
    "        speech_blstm_dim=speech_blstm_dim,\n",
    "        rep_dim=rep_dim,\n",
    "        sub_dim=sub_dim,\n",
    "        n_sub=n_sub,  # Number of subspaces, if any\n",
    "        ckpt_pth=ckpt_pth,  # Set your checkpoint path\n",
    "        project_dir=project_dir  # Example project directory\n",
    "    )\n",
    "\n",
    "clap_model, accelerator = load_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iterations: 1000\n",
      "data_size_per_iteration: 1\n",
      "sample_size: 10\n",
      "beta: 0.1\n",
      "learning_rate: 5e-07\n",
      "num_train_epochs: 3\n",
      "ar_checkpoint: lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\n",
      "nar_checkpoint: lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\n",
      "args_predict: namespace(output_path='/work/b0990106x/trl/output/1020-2012/example.wav', seed=42, device='cuda')\n",
      "model_output_dir: /work/b0990106x/trl/model_output/1020-2012\n",
      "agent_output_dir: /work/b0990106x/trl/output/1020-2012\n",
      "base_path: /work/b0990106x/trl\n",
      "device: cuda\n",
      "eval_train_data_len: 1000\n",
      "eval_test_data_len: 5\n",
      "eval_train_indices: [9]\n",
      "eval_test_indices: [4377, 4046, 8174, 5692, 8489]\n",
      "eval_train: True\n",
      "eval_test: False\n",
      "num_eval: 10\n",
      "training idx 9 : Decrease the pitch of the audio by a moderate amount.\n",
      "evaluation idx 9 : Decrease the pitch of the audio by a moderate amount.\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_iterations: {num_iterations}\")\n",
    "print(f\"data_size_per_iteration: {data_size_per_iteration}\")\n",
    "print(f\"sample_size: {sample_size}\")\n",
    "print(f\"beta: {beta}\")\n",
    "print(f\"learning_rate: {learning_rate}\")\n",
    "print(f\"num_train_epochs: {num_train_epochs}\")\n",
    "print(f\"ar_checkpoint: {ar_checkpoint}\")\n",
    "print(f\"nar_checkpoint: {nar_checkpoint}\")\n",
    "print(f\"args_predict: {args_predict}\")\n",
    "print(f\"model_output_dir: {model_output_dir}\")\n",
    "print(f\"agent_output_dir: {agent_output_dir}\")\n",
    "print(f\"base_path: {base_path}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"eval_train_data_len: {eval_train_data_len}\")\n",
    "print(f\"eval_test_data_len: {eval_test_data_len}\")\n",
    "print(f\"eval_train_indices: {eval_train_indices}\")\n",
    "print(f\"eval_test_indices: {eval_test_indices}\")\n",
    "print(f\"eval_train: {eval_train}\")\n",
    "print(f\"eval_test: {eval_test}\")\n",
    "print(f\"num_eval: {num_eval}\")\n",
    "\n",
    "# print training data\n",
    "for i in train_selected_indices:\n",
    "    print('training idx', i,':', selected_instruction[i])\n",
    "    \n",
    "# print evaluation data\n",
    "if eval_test:\n",
    "    for i in eval_test_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "if eval_train:\n",
    "    for i in eval_train_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/work/b0990106x/trl/trl/models/modeling_base.py:328: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = loading_func(filename if not use_safe else safe_filename, **load_kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "# ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: /work/b0990106x/trl/model_output/1020-2012/log_training.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "log_path = f'{model_output_dir}/log_training.log'\n",
    "print(f\"Logging to: {log_path}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=log_path, \n",
    "    filemode='a', \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    f\"Parameters:\\n\"\n",
    "    f\"Prepare Data: sample_size: {sample_size}\\n\"\n",
    "    f\"Training: num_iterations: {num_iterations}\\n\"\n",
    "    f\"Training: data_size_per_iteration: {data_size_per_iteration}\\n\"\n",
    "    f\"Training: train_selected_indices: {train_selected_indices}\\n\"\n",
    "    f\"Training: beta: {beta}\\n\"\n",
    "    f\"Training: learning_rate: {learning_rate}\\n\"\n",
    "    f\"Training: num_train_epochs: {num_train_epochs}\\n\"\n",
    "    f\"Training: max_length: {max_length}\\n\"\n",
    "    f\"Training: max_prompt_length: {max_prompt_length}\\n\"\n",
    "    f\"Training: max_target_length: {max_target_length}\\n\"\n",
    "    f\"Training: per_device_train_batch_size: {per_device_train_batch_size}\\n\"\n",
    "    f\"Training: gradient_accumulation_steps: {gradient_accumulation_steps}\\n\"\n",
    "    f\"Training: seed: {seed}\\n\"\n",
    "    f\"Training: ar_checkpoint: {ar_checkpoint}\\n\"\n",
    "    f\"Training: nar_checkpoint: {nar_checkpoint}\\n\"\n",
    "    f\"Training: args_predict: {args_predict}\\n\"\n",
    "    f\"Training: model_output_dir: {model_output_dir}\\n\"\n",
    "    f\"Training: agent_output_dir: {agent_output_dir}\\n\"\n",
    "    f\"Training: base_path: {base_path}\\n\"\n",
    "    f\"Training: device: {device}\\n\"\n",
    "    f\"Evaluation: eval_train_data_len: {eval_train_data_len}\\n\"\n",
    "    f\"Evaluation: eval_test_data_len: {eval_test_data_len}\\n\"\n",
    "    f\"Evaluation: eval_train_indices: {eval_train_indices}\\n\"\n",
    "    f\"Evaluation: eval_test_indices: {eval_test_indices}\\n\"\n",
    "    f\"Evaluation: eval_train: {eval_train}\\n\"\n",
    "    f\"Evaluation: eval_test: {eval_test}\\n\"\n",
    "    f\"Evaluation: num_eval: {num_eval}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_-1_data_9_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "total_start_time = time.time()\n",
    "if eval_train:\n",
    "    # eval dpo claps\n",
    "    original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_train_data_len,\n",
    "                                                                    selected_indices=eval_train_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator\n",
    "                                                                    )\n",
    "    logging.info(f\"Original Model Train Set Evaluation: \")\n",
    "    logging.info(f\"Original model metrics on training set: {original_model_metrics}\")\n",
    "    logging.info(f\"Original model rewards on training set: {original_model_rewards}\")\n",
    "    \n",
    "    # eval dpo mos\n",
    "    original_model_metrics_mos, original_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_train_data_len,\n",
    "                                                                    selected_indices=eval_train_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    )\n",
    "    logging.info(f\"Original model metrics on training set: {original_model_metrics_mos}\")\n",
    "    logging.info(f\"Original model rewards on training set: {original_model_rewards_mos}\")\n",
    "    \n",
    "    reward_list = []\n",
    "    for rewards in original_model_rewards:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list.append(None)\n",
    "        else:\n",
    "            reward_list.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "    reward_list_mos = []\n",
    "    for rewards in original_model_rewards_mos:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list_mos.append(None)\n",
    "        else:\n",
    "            reward_list_mos.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model MOS score list on training set: {reward_list_mos}\")\n",
    "    \n",
    "    filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    if len(filter_reward_list) != 0:\n",
    "        logging.info(f\"Original model average rewards on training set: {np.mean(filter_reward_list)}\")\n",
    "    else: \n",
    "        logging.info(f\"Original model average rewards on training set: None\")\n",
    "        \n",
    "    filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "    if len(filter_reward_list_mos) != 0:\n",
    "        logging.info(f\"Original model average MOS on training set: {np.mean(filter_reward_list_mos)}\")\n",
    "    else:\n",
    "        logging.info(f\"Original model average MOS on training set: None\")\n",
    "        \n",
    "    weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "    logging.info(f\"Original model weighted average rewards on training set: {weighted_reward}\")\n",
    "    \n",
    "if eval_test:\n",
    "    original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_test_data_len,\n",
    "                                                                    selected_indices=eval_test_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator\n",
    "                                                                    )\n",
    "    logging.info(f\"Original Model Test Set Evaluation: \")\n",
    "    logging.info(f\"Original model metrics on testing set: {original_model_metrics}\")\n",
    "    logging.info(f\"Original model rewards on testing set: {original_model_rewards}\")\n",
    "    reward_list = []\n",
    "    for rewards in original_model_rewards:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list.append(None)\n",
    "        else:\n",
    "            reward_list.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model reward list on testing set: {reward_list}\")\n",
    "    filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    if len(filter_reward_list) != 0:\n",
    "        logging.info(f\"Original model average rewards on testing set: {np.mean(filter_reward_list)}\")\n",
    "    else: \n",
    "        logging.info(f\"Original model average rewards on testing set: None\")\n",
    "    \n",
    "# If train_selected_indices is not empty, we will use the selected indices for training\n",
    "if train_selected_indices:\n",
    "    batch_src_encodec = [selected_src_encodec[i] for i in train_selected_indices]\n",
    "    batch_instruction = [selected_instruction[i] for i in train_selected_indices]\n",
    "    logging.info(f\"Processing data from selected indices: {train_selected_indices}\")\n",
    "else:\n",
    "    start_idx = 0\n",
    "    end_idx = data_size_per_iteration\n",
    "    batch_src_encodec = selected_src_encodec[start_idx:end_idx] \n",
    "    batch_instruction = selected_instruction[start_idx:end_idx]\n",
    "    logging.info(f\"Processing data from index {start_idx} to {end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 73.09 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 154.97 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mb09901066\u001b[0m (\u001b[33mb09901066_alan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/b0990106x/trl/wandb/run-20241020_201450-181ojzpy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/b09901066_alan/huggingface/runs/181ojzpy' target=\"_blank\">snowy-yogurt-98</a></strong> to <a href='https://wandb.ai/b09901066_alan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/b09901066_alan/huggingface' target=\"_blank\">https://wandb.ai/b09901066_alan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/b09901066_alan/huggingface/runs/181ojzpy' target=\"_blank\">https://wandb.ai/b09901066_alan/huggingface/runs/181ojzpy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_0.wav\n",
      "Episode eval_0_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_1.wav\n",
      "Episode eval_0_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_2.wav\n",
      "Episode eval_0_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_3.wav\n",
      "Episode eval_0_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_4.wav\n",
      "Episode eval_0_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_5.wav\n",
      "Episode eval_0_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_6.wav\n",
      "Episode eval_0_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_7.wav\n",
      "Episode eval_0_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_8.wav\n",
      "Episode eval_0_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_0_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 118.76 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 113.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_0.wav\n",
      "Episode eval_1_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_1.wav\n",
      "Episode eval_1_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_2.wav\n",
      "Episode eval_1_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_3.wav\n",
      "Episode eval_1_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_4.wav\n",
      "Episode eval_1_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_5.wav\n",
      "Episode eval_1_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_6.wav\n",
      "Episode eval_1_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_7.wav\n",
      "Episode eval_1_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_8.wav\n",
      "Episode eval_1_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_1_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 137.14 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.67 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_0.wav\n",
      "Episode eval_2_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_1.wav\n",
      "Episode eval_2_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_2.wav\n",
      "Episode eval_2_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_3.wav\n",
      "Episode eval_2_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_4.wav\n",
      "Episode eval_2_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_5.wav\n",
      "Episode eval_2_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_6.wav\n",
      "Episode eval_2_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_7.wav\n",
      "Episode eval_2_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_8.wav\n",
      "Episode eval_2_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_2_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 123.69 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 115.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_0.wav\n",
      "Episode eval_3_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_1.wav\n",
      "Episode eval_3_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_2.wav\n",
      "Episode eval_3_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_3.wav\n",
      "Episode eval_3_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_4.wav\n",
      "Episode eval_3_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_5.wav\n",
      "Episode eval_3_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_6.wav\n",
      "Episode eval_3_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_7.wav\n",
      "Episode eval_3_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_8.wav\n",
      "Episode eval_3_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_3_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 87.18 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 120.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_0.wav\n",
      "Episode eval_4_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_1.wav\n",
      "Episode eval_4_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_2.wav\n",
      "Episode eval_4_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_3.wav\n",
      "Episode eval_4_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_4.wav\n",
      "Episode eval_4_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_5.wav\n",
      "Episode eval_4_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_6.wav\n",
      "Episode eval_4_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_7.wav\n",
      "Episode eval_4_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_8.wav\n",
      "Episode eval_4_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_4_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 148.31 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 96.16 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_0.wav\n",
      "Episode eval_5_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_1.wav\n",
      "Episode eval_5_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_2.wav\n",
      "Episode eval_5_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_3.wav\n",
      "Episode eval_5_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_4.wav\n",
      "Episode eval_5_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_5.wav\n",
      "Episode eval_5_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_6.wav\n",
      "Episode eval_5_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_7.wav\n",
      "Episode eval_5_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_8.wav\n",
      "Episode eval_5_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_5_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 119.76 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 116.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_0.wav\n",
      "Episode eval_6_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_1.wav\n",
      "Episode eval_6_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_2.wav\n",
      "Episode eval_6_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_3.wav\n",
      "Episode eval_6_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_4.wav\n",
      "Episode eval_6_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_5.wav\n",
      "Episode eval_6_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_6.wav\n",
      "Episode eval_6_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_7.wav\n",
      "Episode eval_6_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_8.wav\n",
      "Episode eval_6_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_6_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 86.68 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_0.wav\n",
      "Episode eval_7_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_1.wav\n",
      "Episode eval_7_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_2.wav\n",
      "Episode eval_7_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_3.wav\n",
      "Episode eval_7_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_4.wav\n",
      "Episode eval_7_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_5.wav\n",
      "Episode eval_7_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_6.wav\n",
      "Episode eval_7_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_7.wav\n",
      "Episode eval_7_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_8.wav\n",
      "Episode eval_7_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_7_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 150.96 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 150.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_0.wav\n",
      "Episode eval_8_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_1.wav\n",
      "Episode eval_8_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_2.wav\n",
      "Episode eval_8_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_3.wav\n",
      "Episode eval_8_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_4.wav\n",
      "Episode eval_8_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_5.wav\n",
      "Episode eval_8_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_6.wav\n",
      "Episode eval_8_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_7.wav\n",
      "Episode eval_8_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_8.wav\n",
      "Episode eval_8_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_8_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 148.30 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 121.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_0.wav\n",
      "Episode eval_9_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_1.wav\n",
      "Episode eval_9_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_2.wav\n",
      "Episode eval_9_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_3.wav\n",
      "Episode eval_9_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_4.wav\n",
      "Episode eval_9_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_5.wav\n",
      "Episode eval_9_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_6.wav\n",
      "Episode eval_9_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_7.wav\n",
      "Episode eval_9_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_8.wav\n",
      "Episode eval_9_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_9_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 92.98 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_0.wav\n",
      "Episode eval_10_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_1.wav\n",
      "Episode eval_10_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_2.wav\n",
      "Episode eval_10_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_3.wav\n",
      "Episode eval_10_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_4.wav\n",
      "Episode eval_10_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_5.wav\n",
      "Episode eval_10_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_6.wav\n",
      "Episode eval_10_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_7.wav\n",
      "Episode eval_10_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_8.wav\n",
      "Episode eval_10_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_10_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 121.79 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.67 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_0.wav\n",
      "Episode eval_11_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_1.wav\n",
      "Episode eval_11_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_2.wav\n",
      "Episode eval_11_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_3.wav\n",
      "Episode eval_11_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_4.wav\n",
      "Episode eval_11_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_5.wav\n",
      "Episode eval_11_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_6.wav\n",
      "Episode eval_11_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_7.wav\n",
      "Episode eval_11_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_8.wav\n",
      "Episode eval_11_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_11_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 83.61 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_0.wav\n",
      "Episode eval_12_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_1.wav\n",
      "Episode eval_12_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_2.wav\n",
      "Episode eval_12_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_3.wav\n",
      "Episode eval_12_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_4.wav\n",
      "Episode eval_12_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_5.wav\n",
      "Episode eval_12_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_6.wav\n",
      "Episode eval_12_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_7.wav\n",
      "Episode eval_12_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_8.wav\n",
      "Episode eval_12_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_12_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.33 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 101.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_0.wav\n",
      "Episode eval_13_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_1.wav\n",
      "Episode eval_13_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_2.wav\n",
      "Episode eval_13_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_3.wav\n",
      "Episode eval_13_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_4.wav\n",
      "Episode eval_13_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_5.wav\n",
      "Episode eval_13_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_6.wav\n",
      "Episode eval_13_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_7.wav\n",
      "Episode eval_13_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_8.wav\n",
      "Episode eval_13_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_13_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 130.70 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 151.36 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_0.wav\n",
      "Episode eval_14_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_1.wav\n",
      "Episode eval_14_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_2.wav\n",
      "Episode eval_14_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_3.wav\n",
      "Episode eval_14_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_4.wav\n",
      "Episode eval_14_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_5.wav\n",
      "Episode eval_14_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_6.wav\n",
      "Episode eval_14_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_7.wav\n",
      "Episode eval_14_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_8.wav\n",
      "Episode eval_14_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_14_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 127.08 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 133.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_15_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_0.wav\n",
      "Episode eval_15_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_1.wav\n",
      "Episode eval_15_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_2.wav\n",
      "Episode eval_15_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_3.wav\n",
      "Episode eval_15_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_4.wav\n",
      "Episode eval_15_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_5.wav\n",
      "Episode eval_15_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_6.wav\n",
      "Episode eval_15_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_7.wav\n",
      "Episode eval_15_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_8.wav\n",
      "Episode eval_15_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_15_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.83 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 151.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_16_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_0.wav\n",
      "Episode eval_16_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_1.wav\n",
      "Episode eval_16_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_2.wav\n",
      "Episode eval_16_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_3.wav\n",
      "Episode eval_16_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_4.wav\n",
      "Episode eval_16_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_5.wav\n",
      "Episode eval_16_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_6.wav\n",
      "Episode eval_16_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_7.wav\n",
      "Episode eval_16_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_8.wav\n",
      "Episode eval_16_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_16_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 139.11 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 89.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_17_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_0.wav\n",
      "Episode eval_17_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_1.wav\n",
      "Episode eval_17_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_2.wav\n",
      "Episode eval_17_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_3.wav\n",
      "Episode eval_17_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_4.wav\n",
      "Episode eval_17_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_5.wav\n",
      "Episode eval_17_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_6.wav\n",
      "Episode eval_17_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_7.wav\n",
      "Episode eval_17_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_8.wav\n",
      "Episode eval_17_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_17_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 123.95 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 143.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_18_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_0.wav\n",
      "Episode eval_18_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_1.wav\n",
      "Episode eval_18_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_2.wav\n",
      "Episode eval_18_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_3.wav\n",
      "Episode eval_18_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_4.wav\n",
      "Episode eval_18_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_5.wav\n",
      "Episode eval_18_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_6.wav\n",
      "Episode eval_18_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_7.wav\n",
      "Episode eval_18_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_8.wav\n",
      "Episode eval_18_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_18_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 140.09 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 143.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_19_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_0.wav\n",
      "Episode eval_19_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_1.wav\n",
      "Episode eval_19_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_2.wav\n",
      "Episode eval_19_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_3.wav\n",
      "Episode eval_19_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_4.wav\n",
      "Episode eval_19_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_5.wav\n",
      "Episode eval_19_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_6.wav\n",
      "Episode eval_19_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_7.wav\n",
      "Episode eval_19_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_8.wav\n",
      "Episode eval_19_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_19_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 104.22 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_20_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_0.wav\n",
      "Episode eval_20_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_1.wav\n",
      "Episode eval_20_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_2.wav\n",
      "Episode eval_20_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_3.wav\n",
      "Episode eval_20_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_4.wav\n",
      "Episode eval_20_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_5.wav\n",
      "Episode eval_20_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_6.wav\n",
      "Episode eval_20_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_7.wav\n",
      "Episode eval_20_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_8.wav\n",
      "Episode eval_20_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_20_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 82.06 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 122.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_21_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_0.wav\n",
      "Episode eval_21_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_1.wav\n",
      "Episode eval_21_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_2.wav\n",
      "Episode eval_21_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_3.wav\n",
      "Episode eval_21_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_4.wav\n",
      "Episode eval_21_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_5.wav\n",
      "Episode eval_21_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_6.wav\n",
      "Episode eval_21_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_7.wav\n",
      "Episode eval_21_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_8.wav\n",
      "Episode eval_21_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_21_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 83.47 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 116.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_22_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_0.wav\n",
      "Episode eval_22_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_1.wav\n",
      "Episode eval_22_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_2.wav\n",
      "Episode eval_22_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_3.wav\n",
      "Episode eval_22_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_4.wav\n",
      "Episode eval_22_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_5.wav\n",
      "Episode eval_22_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_6.wav\n",
      "Episode eval_22_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_7.wav\n",
      "Episode eval_22_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_8.wav\n",
      "Episode eval_22_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_22_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 139.91 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 143.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_23_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_0.wav\n",
      "Episode eval_23_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_1.wav\n",
      "Episode eval_23_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_2.wav\n",
      "Episode eval_23_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_3.wav\n",
      "Episode eval_23_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_4.wav\n",
      "Episode eval_23_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_5.wav\n",
      "Episode eval_23_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_6.wav\n",
      "Episode eval_23_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_7.wav\n",
      "Episode eval_23_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_8.wav\n",
      "Episode eval_23_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_23_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 95.92 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_24_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_0.wav\n",
      "Episode eval_24_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_1.wav\n",
      "Episode eval_24_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_2.wav\n",
      "Episode eval_24_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_3.wav\n",
      "Episode eval_24_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_4.wav\n",
      "Episode eval_24_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_5.wav\n",
      "Episode eval_24_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_6.wav\n",
      "Episode eval_24_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_7.wav\n",
      "Episode eval_24_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_8.wav\n",
      "Episode eval_24_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_24_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 149.21 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 114.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_25_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_0.wav\n",
      "Episode eval_25_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_1.wav\n",
      "Episode eval_25_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_2.wav\n",
      "Episode eval_25_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_3.wav\n",
      "Episode eval_25_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_4.wav\n",
      "Episode eval_25_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_5.wav\n",
      "Episode eval_25_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_6.wav\n",
      "Episode eval_25_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_7.wav\n",
      "Episode eval_25_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_8.wav\n",
      "Episode eval_25_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_25_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 83.96 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 149.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_26_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_0.wav\n",
      "Episode eval_26_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_1.wav\n",
      "Episode eval_26_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_2.wav\n",
      "Episode eval_26_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_3.wav\n",
      "Episode eval_26_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_4.wav\n",
      "Episode eval_26_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_5.wav\n",
      "Episode eval_26_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_6.wav\n",
      "Episode eval_26_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_7.wav\n",
      "Episode eval_26_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_8.wav\n",
      "Episode eval_26_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_26_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 147.12 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 106.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_27_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_0.wav\n",
      "Episode eval_27_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_1.wav\n",
      "Episode eval_27_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_2.wav\n",
      "Episode eval_27_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_3.wav\n",
      "Episode eval_27_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_4.wav\n",
      "Episode eval_27_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_5.wav\n",
      "Episode eval_27_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_6.wav\n",
      "Episode eval_27_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_7.wav\n",
      "Episode eval_27_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_8.wav\n",
      "Episode eval_27_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_27_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 147.45 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 81.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_28_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_0.wav\n",
      "Episode eval_28_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_1.wav\n",
      "Episode eval_28_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_2.wav\n",
      "Episode eval_28_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_3.wav\n",
      "Episode eval_28_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_4.wav\n",
      "Episode eval_28_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_5.wav\n",
      "Episode eval_28_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_6.wav\n",
      "Episode eval_28_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_7.wav\n",
      "Episode eval_28_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_8.wav\n",
      "Episode eval_28_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_28_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 141.80 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 76.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_29_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_0.wav\n",
      "Episode eval_29_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_1.wav\n",
      "Episode eval_29_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_2.wav\n",
      "Episode eval_29_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_3.wav\n",
      "Episode eval_29_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_4.wav\n",
      "Episode eval_29_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_5.wav\n",
      "Episode eval_29_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_6.wav\n",
      "Episode eval_29_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_7.wav\n",
      "Episode eval_29_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_8.wav\n",
      "Episode eval_29_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_29_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 101.99 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 100.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_30_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_0.wav\n",
      "Episode eval_30_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_1.wav\n",
      "Episode eval_30_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_2.wav\n",
      "Episode eval_30_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_3.wav\n",
      "Episode eval_30_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_4.wav\n",
      "Episode eval_30_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_5.wav\n",
      "Episode eval_30_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_6.wav\n",
      "Episode eval_30_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_7.wav\n",
      "Episode eval_30_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_8.wav\n",
      "Episode eval_30_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_30_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.99 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 151.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_31_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_0.wav\n",
      "Episode eval_31_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_1.wav\n",
      "Episode eval_31_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_2.wav\n",
      "Episode eval_31_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_3.wav\n",
      "Episode eval_31_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_4.wav\n",
      "Episode eval_31_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_5.wav\n",
      "Episode eval_31_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_6.wav\n",
      "Episode eval_31_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_7.wav\n",
      "Episode eval_31_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_8.wav\n",
      "Episode eval_31_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_31_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 107.09 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 147.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_32_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_0.wav\n",
      "Episode eval_32_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_1.wav\n",
      "Episode eval_32_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_2.wav\n",
      "Episode eval_32_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_3.wav\n",
      "Episode eval_32_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_4.wav\n",
      "Episode eval_32_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_5.wav\n",
      "Episode eval_32_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_6.wav\n",
      "Episode eval_32_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_7.wav\n",
      "Episode eval_32_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_8.wav\n",
      "Episode eval_32_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_32_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.12 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 85.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_33_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_0.wav\n",
      "Episode eval_33_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_1.wav\n",
      "Episode eval_33_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_2.wav\n",
      "Episode eval_33_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_3.wav\n",
      "Episode eval_33_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_4.wav\n",
      "Episode eval_33_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_5.wav\n",
      "Episode eval_33_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_6.wav\n",
      "Episode eval_33_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_7.wav\n",
      "Episode eval_33_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_8.wav\n",
      "Episode eval_33_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_33_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.18 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 104.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_34_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_0.wav\n",
      "Episode eval_34_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_1.wav\n",
      "Episode eval_34_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_2.wav\n",
      "Episode eval_34_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_3.wav\n",
      "Episode eval_34_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_4.wav\n",
      "Episode eval_34_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_5.wav\n",
      "Episode eval_34_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_6.wav\n",
      "Episode eval_34_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_7.wav\n",
      "Episode eval_34_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_8.wav\n",
      "Episode eval_34_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_34_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 125.88 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 153.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_35_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_0.wav\n",
      "Episode eval_35_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_1.wav\n",
      "Episode eval_35_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_2.wav\n",
      "Episode eval_35_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_3.wav\n",
      "Episode eval_35_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_4.wav\n",
      "Episode eval_35_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_5.wav\n",
      "Episode eval_35_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_6.wav\n",
      "Episode eval_35_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_7.wav\n",
      "Episode eval_35_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_8.wav\n",
      "Episode eval_35_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_35_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 108.57 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 84.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_36_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_0.wav\n",
      "Episode eval_36_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_1.wav\n",
      "Episode eval_36_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_2.wav\n",
      "Episode eval_36_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_3.wav\n",
      "Episode eval_36_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_4.wav\n",
      "Episode eval_36_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_5.wav\n",
      "Episode eval_36_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_6.wav\n",
      "Episode eval_36_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_7.wav\n",
      "Episode eval_36_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_8.wav\n",
      "Episode eval_36_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_36_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 144.38 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 86.60 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_37_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_0.wav\n",
      "Episode eval_37_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_1.wav\n",
      "Episode eval_37_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_2.wav\n",
      "Episode eval_37_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_3.wav\n",
      "Episode eval_37_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_4.wav\n",
      "Episode eval_37_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_5.wav\n",
      "Episode eval_37_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_6.wav\n",
      "Episode eval_37_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_7.wav\n",
      "Episode eval_37_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_8.wav\n",
      "Episode eval_37_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_37_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 144.43 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 139.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_38_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_0.wav\n",
      "Episode eval_38_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_1.wav\n",
      "Episode eval_38_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_2.wav\n",
      "Episode eval_38_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_3.wav\n",
      "Episode eval_38_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_4.wav\n",
      "Episode eval_38_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_5.wav\n",
      "Episode eval_38_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_6.wav\n",
      "Episode eval_38_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_7.wav\n",
      "Episode eval_38_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_8.wav\n",
      "Episode eval_38_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_38_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 124.53 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 105.45 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_39_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_0.wav\n",
      "Episode eval_39_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_1.wav\n",
      "Episode eval_39_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_2.wav\n",
      "Episode eval_39_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_3.wav\n",
      "Episode eval_39_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_4.wav\n",
      "Episode eval_39_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_5.wav\n",
      "Episode eval_39_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_6.wav\n",
      "Episode eval_39_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_7.wav\n",
      "Episode eval_39_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_8.wav\n",
      "Episode eval_39_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_39_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 141.34 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_40_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_0.wav\n",
      "Episode eval_40_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_1.wav\n",
      "Episode eval_40_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_2.wav\n",
      "Episode eval_40_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_3.wav\n",
      "Episode eval_40_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_4.wav\n",
      "Episode eval_40_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_5.wav\n",
      "Episode eval_40_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_6.wav\n",
      "Episode eval_40_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_7.wav\n",
      "Episode eval_40_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_8.wav\n",
      "Episode eval_40_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_40_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 127.30 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_41_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_0.wav\n",
      "Episode eval_41_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_1.wav\n",
      "Episode eval_41_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_2.wav\n",
      "Episode eval_41_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_3.wav\n",
      "Episode eval_41_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_4.wav\n",
      "Episode eval_41_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_5.wav\n",
      "Episode eval_41_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_6.wav\n",
      "Episode eval_41_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_7.wav\n",
      "Episode eval_41_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_8.wav\n",
      "Episode eval_41_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_41_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.27 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 136.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_42_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_0.wav\n",
      "Episode eval_42_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_1.wav\n",
      "Episode eval_42_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_2.wav\n",
      "Episode eval_42_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_3.wav\n",
      "Episode eval_42_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_4.wav\n",
      "Episode eval_42_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_5.wav\n",
      "Episode eval_42_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_6.wav\n",
      "Episode eval_42_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_7.wav\n",
      "Episode eval_42_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_8.wav\n",
      "Episode eval_42_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_42_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 139.85 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 134.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_43_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_0.wav\n",
      "Episode eval_43_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_1.wav\n",
      "Episode eval_43_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_2.wav\n",
      "Episode eval_43_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_3.wav\n",
      "Episode eval_43_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_4.wav\n",
      "Episode eval_43_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_5.wav\n",
      "Episode eval_43_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_6.wav\n",
      "Episode eval_43_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_7.wav\n",
      "Episode eval_43_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_8.wav\n",
      "Episode eval_43_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_43_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.21 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 99.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_44_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_0.wav\n",
      "Episode eval_44_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_1.wav\n",
      "Episode eval_44_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_2.wav\n",
      "Episode eval_44_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_3.wav\n",
      "Episode eval_44_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_4.wav\n",
      "Episode eval_44_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_5.wav\n",
      "Episode eval_44_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_6.wav\n",
      "Episode eval_44_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_7.wav\n",
      "Episode eval_44_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_8.wav\n",
      "Episode eval_44_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_44_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 88.08 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_45_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_0.wav\n",
      "Episode eval_45_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_1.wav\n",
      "Episode eval_45_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_2.wav\n",
      "Episode eval_45_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_3.wav\n",
      "Episode eval_45_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_4.wav\n",
      "Episode eval_45_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_5.wav\n",
      "Episode eval_45_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_6.wav\n",
      "Episode eval_45_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_7.wav\n",
      "Episode eval_45_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_8.wav\n",
      "Episode eval_45_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_45_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 146.38 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 100.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_46_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_0.wav\n",
      "Episode eval_46_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_1.wav\n",
      "Episode eval_46_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_2.wav\n",
      "Episode eval_46_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_3.wav\n",
      "Episode eval_46_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_4.wav\n",
      "Episode eval_46_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_5.wav\n",
      "Episode eval_46_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_6.wav\n",
      "Episode eval_46_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_7.wav\n",
      "Episode eval_46_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_8.wav\n",
      "Episode eval_46_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_46_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 102.38 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 92.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_47_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_0.wav\n",
      "Episode eval_47_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_1.wav\n",
      "Episode eval_47_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_2.wav\n",
      "Episode eval_47_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_3.wav\n",
      "Episode eval_47_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_4.wav\n",
      "Episode eval_47_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_5.wav\n",
      "Episode eval_47_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_6.wav\n",
      "Episode eval_47_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_7.wav\n",
      "Episode eval_47_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_8.wav\n",
      "Episode eval_47_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_47_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.69 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 138.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_48_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_0.wav\n",
      "Episode eval_48_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_1.wav\n",
      "Episode eval_48_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_2.wav\n",
      "Episode eval_48_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_3.wav\n",
      "Episode eval_48_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_4.wav\n",
      "Episode eval_48_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_5.wav\n",
      "Episode eval_48_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_6.wav\n",
      "Episode eval_48_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_7.wav\n",
      "Episode eval_48_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_8.wav\n",
      "Episode eval_48_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_48_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.14 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_49_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_0.wav\n",
      "Episode eval_49_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_1.wav\n",
      "Episode eval_49_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_2.wav\n",
      "Episode eval_49_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_3.wav\n",
      "Episode eval_49_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_4.wav\n",
      "Episode eval_49_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_5.wav\n",
      "Episode eval_49_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_6.wav\n",
      "Episode eval_49_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_7.wav\n",
      "Episode eval_49_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_8.wav\n",
      "Episode eval_49_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_49_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 136.80 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_50_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_0.wav\n",
      "Episode eval_50_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_1.wav\n",
      "Episode eval_50_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_2.wav\n",
      "Episode eval_50_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_3.wav\n",
      "Episode eval_50_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_4.wav\n",
      "Episode eval_50_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_5.wav\n",
      "Episode eval_50_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_6.wav\n",
      "Episode eval_50_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_7.wav\n",
      "Episode eval_50_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_8.wav\n",
      "Episode eval_50_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_50_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 145.46 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 97.54 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_51_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_0.wav\n",
      "Episode eval_51_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_1.wav\n",
      "Episode eval_51_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_2.wav\n",
      "Episode eval_51_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_3.wav\n",
      "Episode eval_51_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_4.wav\n",
      "Episode eval_51_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_5.wav\n",
      "Episode eval_51_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_6.wav\n",
      "Episode eval_51_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_7.wav\n",
      "Episode eval_51_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_8.wav\n",
      "Episode eval_51_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_51_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 89.15 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 114.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_52_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_0.wav\n",
      "Episode eval_52_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_1.wav\n",
      "Episode eval_52_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_2.wav\n",
      "Episode eval_52_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_3.wav\n",
      "Episode eval_52_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_4.wav\n",
      "Episode eval_52_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_5.wav\n",
      "Episode eval_52_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_6.wav\n",
      "Episode eval_52_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_7.wav\n",
      "Episode eval_52_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_8.wav\n",
      "Episode eval_52_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_52_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 94.81 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 87.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_53_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_0.wav\n",
      "Episode eval_53_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_1.wav\n",
      "Episode eval_53_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_2.wav\n",
      "Episode eval_53_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_3.wav\n",
      "Episode eval_53_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_4.wav\n",
      "Episode eval_53_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_5.wav\n",
      "Episode eval_53_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_6.wav\n",
      "Episode eval_53_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_7.wav\n",
      "Episode eval_53_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_8.wav\n",
      "Episode eval_53_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_53_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 97.41 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 133.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_54_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_0.wav\n",
      "Episode eval_54_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_1.wav\n",
      "Episode eval_54_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_2.wav\n",
      "Episode eval_54_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_3.wav\n",
      "Episode eval_54_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_4.wav\n",
      "Episode eval_54_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_5.wav\n",
      "Episode eval_54_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_6.wav\n",
      "Episode eval_54_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_7.wav\n",
      "Episode eval_54_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_8.wav\n",
      "Episode eval_54_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_54_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 150.36 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 151.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_55_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_0.wav\n",
      "Episode eval_55_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_1.wav\n",
      "Episode eval_55_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_2.wav\n",
      "Episode eval_55_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_3.wav\n",
      "Episode eval_55_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_4.wav\n",
      "Episode eval_55_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_5.wav\n",
      "Episode eval_55_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_6.wav\n",
      "Episode eval_55_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_7.wav\n",
      "Episode eval_55_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_8.wav\n",
      "Episode eval_55_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_55_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 146.23 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 132.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_56_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_0.wav\n",
      "Episode eval_56_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_1.wav\n",
      "Episode eval_56_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_2.wav\n",
      "Episode eval_56_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_3.wav\n",
      "Episode eval_56_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_4.wav\n",
      "Episode eval_56_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_5.wav\n",
      "Episode eval_56_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_6.wav\n",
      "Episode eval_56_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_7.wav\n",
      "Episode eval_56_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_8.wav\n",
      "Episode eval_56_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_56_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.40 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 153.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_57_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_0.wav\n",
      "Episode eval_57_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_1.wav\n",
      "Episode eval_57_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_2.wav\n",
      "Episode eval_57_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_3.wav\n",
      "Episode eval_57_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_4.wav\n",
      "Episode eval_57_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_5.wav\n",
      "Episode eval_57_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_6.wav\n",
      "Episode eval_57_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_7.wav\n",
      "Episode eval_57_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_8.wav\n",
      "Episode eval_57_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_57_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 123.27 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 96.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_58_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_0.wav\n",
      "Episode eval_58_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_1.wav\n",
      "Episode eval_58_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_2.wav\n",
      "Episode eval_58_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_3.wav\n",
      "Episode eval_58_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_4.wav\n",
      "Episode eval_58_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_5.wav\n",
      "Episode eval_58_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_6.wav\n",
      "Episode eval_58_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_7.wav\n",
      "Episode eval_58_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_8.wav\n",
      "Episode eval_58_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_58_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 145.87 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 97.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_59_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_0.wav\n",
      "Episode eval_59_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_1.wav\n",
      "Episode eval_59_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_2.wav\n",
      "Episode eval_59_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_3.wav\n",
      "Episode eval_59_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_4.wav\n",
      "Episode eval_59_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_5.wav\n",
      "Episode eval_59_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_6.wav\n",
      "Episode eval_59_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_7.wav\n",
      "Episode eval_59_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_8.wav\n",
      "Episode eval_59_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_59_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 148.76 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 114.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_60_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_0.wav\n",
      "Episode eval_60_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_1.wav\n",
      "Episode eval_60_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_2.wav\n",
      "Episode eval_60_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_3.wav\n",
      "Episode eval_60_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_4.wav\n",
      "Episode eval_60_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_5.wav\n",
      "Episode eval_60_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_6.wav\n",
      "Episode eval_60_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_7.wav\n",
      "Episode eval_60_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_8.wav\n",
      "Episode eval_60_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_60_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.50 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 130.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_61_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_0.wav\n",
      "Episode eval_61_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_1.wav\n",
      "Episode eval_61_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_2.wav\n",
      "Episode eval_61_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_3.wav\n",
      "Episode eval_61_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_4.wav\n",
      "Episode eval_61_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_5.wav\n",
      "Episode eval_61_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_6.wav\n",
      "Episode eval_61_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_7.wav\n",
      "Episode eval_61_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_8.wav\n",
      "Episode eval_61_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_61_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.23 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_62_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_0.wav\n",
      "Episode eval_62_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_1.wav\n",
      "Episode eval_62_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_2.wav\n",
      "Episode eval_62_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_3.wav\n",
      "Episode eval_62_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_4.wav\n",
      "Episode eval_62_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_5.wav\n",
      "Episode eval_62_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_6.wav\n",
      "Episode eval_62_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_7.wav\n",
      "Episode eval_62_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_8.wav\n",
      "Episode eval_62_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_62_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 136.45 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 126.97 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_63_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_0.wav\n",
      "Episode eval_63_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_1.wav\n",
      "Episode eval_63_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_2.wav\n",
      "Episode eval_63_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_3.wav\n",
      "Episode eval_63_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_4.wav\n",
      "Episode eval_63_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_5.wav\n",
      "Episode eval_63_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_6.wav\n",
      "Episode eval_63_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_7.wav\n",
      "Episode eval_63_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_8.wav\n",
      "Episode eval_63_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_63_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 124.89 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_64_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_0.wav\n",
      "Episode eval_64_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_1.wav\n",
      "Episode eval_64_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_2.wav\n",
      "Episode eval_64_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_3.wav\n",
      "Episode eval_64_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_4.wav\n",
      "Episode eval_64_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_5.wav\n",
      "Episode eval_64_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_6.wav\n",
      "Episode eval_64_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_7.wav\n",
      "Episode eval_64_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_8.wav\n",
      "Episode eval_64_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_64_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 94.39 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 89.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_65_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_0.wav\n",
      "Episode eval_65_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_1.wav\n",
      "Episode eval_65_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_2.wav\n",
      "Episode eval_65_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_3.wav\n",
      "Episode eval_65_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_4.wav\n",
      "Episode eval_65_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_5.wav\n",
      "Episode eval_65_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_6.wav\n",
      "Episode eval_65_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_7.wav\n",
      "Episode eval_65_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_8.wav\n",
      "Episode eval_65_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_65_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 108.74 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 132.64 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_66_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_0.wav\n",
      "Episode eval_66_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_1.wav\n",
      "Episode eval_66_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_2.wav\n",
      "Episode eval_66_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_3.wav\n",
      "Episode eval_66_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_4.wav\n",
      "Episode eval_66_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_5.wav\n",
      "Episode eval_66_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_6.wav\n",
      "Episode eval_66_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_7.wav\n",
      "Episode eval_66_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_8.wav\n",
      "Episode eval_66_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_66_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.98 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.57 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_67_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_0.wav\n",
      "Episode eval_67_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_1.wav\n",
      "Episode eval_67_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_2.wav\n",
      "Episode eval_67_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_3.wav\n",
      "Episode eval_67_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_4.wav\n",
      "Episode eval_67_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_5.wav\n",
      "Episode eval_67_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_6.wav\n",
      "Episode eval_67_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_7.wav\n",
      "Episode eval_67_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_8.wav\n",
      "Episode eval_67_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_67_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 148.30 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 107.65 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_68_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_0.wav\n",
      "Episode eval_68_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_1.wav\n",
      "Episode eval_68_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_2.wav\n",
      "Episode eval_68_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_3.wav\n",
      "Episode eval_68_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_4.wav\n",
      "Episode eval_68_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_5.wav\n",
      "Episode eval_68_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_6.wav\n",
      "Episode eval_68_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_7.wav\n",
      "Episode eval_68_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_8.wav\n",
      "Episode eval_68_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_68_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 131.10 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 86.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_69_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_0.wav\n",
      "Episode eval_69_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_1.wav\n",
      "Episode eval_69_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_2.wav\n",
      "Episode eval_69_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_3.wav\n",
      "Episode eval_69_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_4.wav\n",
      "Episode eval_69_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_5.wav\n",
      "Episode eval_69_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_6.wav\n",
      "Episode eval_69_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_7.wav\n",
      "Episode eval_69_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_8.wav\n",
      "Episode eval_69_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_69_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.44 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 79.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_70_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_0.wav\n",
      "Episode eval_70_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_1.wav\n",
      "Episode eval_70_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_2.wav\n",
      "Episode eval_70_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_3.wav\n",
      "Episode eval_70_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_4.wav\n",
      "Episode eval_70_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_5.wav\n",
      "Episode eval_70_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_6.wav\n",
      "Episode eval_70_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_7.wav\n",
      "Episode eval_70_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_8.wav\n",
      "Episode eval_70_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_70_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 147.49 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 128.32 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_71_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_0.wav\n",
      "Episode eval_71_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_1.wav\n",
      "Episode eval_71_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_2.wav\n",
      "Episode eval_71_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_3.wav\n",
      "Episode eval_71_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_4.wav\n",
      "Episode eval_71_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_5.wav\n",
      "Episode eval_71_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_6.wav\n",
      "Episode eval_71_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_7.wav\n",
      "Episode eval_71_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_8.wav\n",
      "Episode eval_71_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_71_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 85.51 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_72_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_0.wav\n",
      "Episode eval_72_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_1.wav\n",
      "Episode eval_72_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_2.wav\n",
      "Episode eval_72_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_3.wav\n",
      "Episode eval_72_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_4.wav\n",
      "Episode eval_72_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_5.wav\n",
      "Episode eval_72_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_6.wav\n",
      "Episode eval_72_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_7.wav\n",
      "Episode eval_72_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_8.wav\n",
      "Episode eval_72_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_72_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 116.37 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_73_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_0.wav\n",
      "Episode eval_73_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_1.wav\n",
      "Episode eval_73_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_2.wav\n",
      "Episode eval_73_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_3.wav\n",
      "Episode eval_73_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_4.wav\n",
      "Episode eval_73_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_5.wav\n",
      "Episode eval_73_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_6.wav\n",
      "Episode eval_73_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_7.wav\n",
      "Episode eval_73_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_8.wav\n",
      "Episode eval_73_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_73_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 103.10 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_74_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_0.wav\n",
      "Episode eval_74_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_1.wav\n",
      "Episode eval_74_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_2.wav\n",
      "Episode eval_74_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_3.wav\n",
      "Episode eval_74_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_4.wav\n",
      "Episode eval_74_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_5.wav\n",
      "Episode eval_74_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_6.wav\n",
      "Episode eval_74_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_7.wav\n",
      "Episode eval_74_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_8.wav\n",
      "Episode eval_74_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_74_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 95.81 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 98.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_75_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_0.wav\n",
      "Episode eval_75_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_1.wav\n",
      "Episode eval_75_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_2.wav\n",
      "Episode eval_75_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_3.wav\n",
      "Episode eval_75_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_4.wav\n",
      "Episode eval_75_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_5.wav\n",
      "Episode eval_75_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_6.wav\n",
      "Episode eval_75_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_7.wav\n",
      "Episode eval_75_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_8.wav\n",
      "Episode eval_75_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_75_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 124.12 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 147.95 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_76_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_0.wav\n",
      "Episode eval_76_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_1.wav\n",
      "Episode eval_76_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_2.wav\n",
      "Episode eval_76_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_3.wav\n",
      "Episode eval_76_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_4.wav\n",
      "Episode eval_76_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_5.wav\n",
      "Episode eval_76_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_6.wav\n",
      "Episode eval_76_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_7.wav\n",
      "Episode eval_76_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_8.wav\n",
      "Episode eval_76_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_76_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 122.35 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 89.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_77_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_0.wav\n",
      "Episode eval_77_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_1.wav\n",
      "Episode eval_77_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_2.wav\n",
      "Episode eval_77_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_3.wav\n",
      "Episode eval_77_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_4.wav\n",
      "Episode eval_77_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_5.wav\n",
      "Episode eval_77_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_6.wav\n",
      "Episode eval_77_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_7.wav\n",
      "Episode eval_77_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_8.wav\n",
      "Episode eval_77_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_77_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 136.81 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 97.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_78_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_0.wav\n",
      "Episode eval_78_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_1.wav\n",
      "Episode eval_78_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_2.wav\n",
      "Episode eval_78_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_3.wav\n",
      "Episode eval_78_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_4.wav\n",
      "Episode eval_78_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_5.wav\n",
      "Episode eval_78_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_6.wav\n",
      "Episode eval_78_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_7.wav\n",
      "Episode eval_78_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_8.wav\n",
      "Episode eval_78_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_78_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 106.15 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 126.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_79_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_0.wav\n",
      "Episode eval_79_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_1.wav\n",
      "Episode eval_79_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_2.wav\n",
      "Episode eval_79_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_3.wav\n",
      "Episode eval_79_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_4.wav\n",
      "Episode eval_79_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_5.wav\n",
      "Episode eval_79_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_6.wav\n",
      "Episode eval_79_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_7.wav\n",
      "Episode eval_79_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_8.wav\n",
      "Episode eval_79_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_79_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 110.21 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_80_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_0.wav\n",
      "Episode eval_80_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_1.wav\n",
      "Episode eval_80_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_2.wav\n",
      "Episode eval_80_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_3.wav\n",
      "Episode eval_80_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_4.wav\n",
      "Episode eval_80_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_5.wav\n",
      "Episode eval_80_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_6.wav\n",
      "Episode eval_80_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_7.wav\n",
      "Episode eval_80_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_8.wav\n",
      "Episode eval_80_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_80_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.81 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_81_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_0.wav\n",
      "Episode eval_81_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_1.wav\n",
      "Episode eval_81_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_2.wav\n",
      "Episode eval_81_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_3.wav\n",
      "Episode eval_81_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_4.wav\n",
      "Episode eval_81_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_5.wav\n",
      "Episode eval_81_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_6.wav\n",
      "Episode eval_81_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_7.wav\n",
      "Episode eval_81_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_8.wav\n",
      "Episode eval_81_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_81_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 84.40 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 141.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_82_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_0.wav\n",
      "Episode eval_82_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_1.wav\n",
      "Episode eval_82_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_2.wav\n",
      "Episode eval_82_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_3.wav\n",
      "Episode eval_82_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_4.wav\n",
      "Episode eval_82_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_5.wav\n",
      "Episode eval_82_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_6.wav\n",
      "Episode eval_82_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_7.wav\n",
      "Episode eval_82_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_8.wav\n",
      "Episode eval_82_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_82_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 110.63 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_83_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_0.wav\n",
      "Episode eval_83_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_1.wav\n",
      "Episode eval_83_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_2.wav\n",
      "Episode eval_83_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_3.wav\n",
      "Episode eval_83_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_4.wav\n",
      "Episode eval_83_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_5.wav\n",
      "Episode eval_83_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_6.wav\n",
      "Episode eval_83_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_7.wav\n",
      "Episode eval_83_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_8.wav\n",
      "Episode eval_83_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_83_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 101.50 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 122.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_84_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_0.wav\n",
      "Episode eval_84_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_1.wav\n",
      "Episode eval_84_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_2.wav\n",
      "Episode eval_84_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_3.wav\n",
      "Episode eval_84_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_4.wav\n",
      "Episode eval_84_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_5.wav\n",
      "Episode eval_84_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_6.wav\n",
      "Episode eval_84_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_7.wav\n",
      "Episode eval_84_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_8.wav\n",
      "Episode eval_84_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_84_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 117.30 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_85_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_0.wav\n",
      "Episode eval_85_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_1.wav\n",
      "Episode eval_85_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_2.wav\n",
      "Episode eval_85_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_3.wav\n",
      "Episode eval_85_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_4.wav\n",
      "Episode eval_85_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_5.wav\n",
      "Episode eval_85_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_6.wav\n",
      "Episode eval_85_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_7.wav\n",
      "Episode eval_85_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_8.wav\n",
      "Episode eval_85_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_85_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 68.90 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_86_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_0.wav\n",
      "Episode eval_86_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_1.wav\n",
      "Episode eval_86_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_2.wav\n",
      "Episode eval_86_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_3.wav\n",
      "Episode eval_86_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_4.wav\n",
      "Episode eval_86_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_5.wav\n",
      "Episode eval_86_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_6.wav\n",
      "Episode eval_86_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_7.wav\n",
      "Episode eval_86_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_8.wav\n",
      "Episode eval_86_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_86_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 140.83 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 149.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_87_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_0.wav\n",
      "Episode eval_87_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_1.wav\n",
      "Episode eval_87_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_2.wav\n",
      "Episode eval_87_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_3.wav\n",
      "Episode eval_87_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_4.wav\n",
      "Episode eval_87_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_5.wav\n",
      "Episode eval_87_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_6.wav\n",
      "Episode eval_87_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_7.wav\n",
      "Episode eval_87_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_8.wav\n",
      "Episode eval_87_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_87_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 145.21 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_88_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_0.wav\n",
      "Episode eval_88_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_1.wav\n",
      "Episode eval_88_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_2.wav\n",
      "Episode eval_88_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_3.wav\n",
      "Episode eval_88_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_4.wav\n",
      "Episode eval_88_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_5.wav\n",
      "Episode eval_88_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_6.wav\n",
      "Episode eval_88_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_7.wav\n",
      "Episode eval_88_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_8.wav\n",
      "Episode eval_88_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_88_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.34 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_89_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_0.wav\n",
      "Episode eval_89_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_1.wav\n",
      "Episode eval_89_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_2.wav\n",
      "Episode eval_89_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_3.wav\n",
      "Episode eval_89_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_4.wav\n",
      "Episode eval_89_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_5.wav\n",
      "Episode eval_89_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_6.wav\n",
      "Episode eval_89_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_7.wav\n",
      "Episode eval_89_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_8.wav\n",
      "Episode eval_89_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_89_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 132.49 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.39 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_90_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_0.wav\n",
      "Episode eval_90_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_1.wav\n",
      "Episode eval_90_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_2.wav\n",
      "Episode eval_90_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_3.wav\n",
      "Episode eval_90_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_4.wav\n",
      "Episode eval_90_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_5.wav\n",
      "Episode eval_90_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_6.wav\n",
      "Episode eval_90_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_7.wav\n",
      "Episode eval_90_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_8.wav\n",
      "Episode eval_90_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_90_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 90.68 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 150.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_91_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_0.wav\n",
      "Episode eval_91_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_1.wav\n",
      "Episode eval_91_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_2.wav\n",
      "Episode eval_91_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_3.wav\n",
      "Episode eval_91_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_4.wav\n",
      "Episode eval_91_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_5.wav\n",
      "Episode eval_91_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_6.wav\n",
      "Episode eval_91_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_7.wav\n",
      "Episode eval_91_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_8.wav\n",
      "Episode eval_91_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_91_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 141.43 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_92_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_0.wav\n",
      "Episode eval_92_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_1.wav\n",
      "Episode eval_92_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_2.wav\n",
      "Episode eval_92_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_3.wav\n",
      "Episode eval_92_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_4.wav\n",
      "Episode eval_92_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_5.wav\n",
      "Episode eval_92_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_6.wav\n",
      "Episode eval_92_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_7.wav\n",
      "Episode eval_92_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_8.wav\n",
      "Episode eval_92_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_92_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 100.21 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_93_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_0.wav\n",
      "Episode eval_93_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_1.wav\n",
      "Episode eval_93_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_2.wav\n",
      "Episode eval_93_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_3.wav\n",
      "Episode eval_93_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_4.wav\n",
      "Episode eval_93_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_5.wav\n",
      "Episode eval_93_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_6.wav\n",
      "Episode eval_93_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_7.wav\n",
      "Episode eval_93_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_8.wav\n",
      "Episode eval_93_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_93_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 141.51 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_94_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_0.wav\n",
      "Episode eval_94_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_1.wav\n",
      "Episode eval_94_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_2.wav\n",
      "Episode eval_94_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_3.wav\n",
      "Episode eval_94_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_4.wav\n",
      "Episode eval_94_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_5.wav\n",
      "Episode eval_94_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_6.wav\n",
      "Episode eval_94_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_7.wav\n",
      "Episode eval_94_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_8.wav\n",
      "Episode eval_94_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_94_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 144.34 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 139.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_95_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_0.wav\n",
      "Episode eval_95_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_1.wav\n",
      "Episode eval_95_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_2.wav\n",
      "Episode eval_95_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_3.wav\n",
      "Episode eval_95_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_4.wav\n",
      "Episode eval_95_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_5.wav\n",
      "Episode eval_95_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_6.wav\n",
      "Episode eval_95_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_7.wav\n",
      "Episode eval_95_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_8.wav\n",
      "Episode eval_95_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_95_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 148.74 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_96_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_0.wav\n",
      "Episode eval_96_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_1.wav\n",
      "Episode eval_96_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_2.wav\n",
      "Episode eval_96_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_3.wav\n",
      "Episode eval_96_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_4.wav\n",
      "Episode eval_96_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_5.wav\n",
      "Episode eval_96_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_6.wav\n",
      "Episode eval_96_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_7.wav\n",
      "Episode eval_96_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_8.wav\n",
      "Episode eval_96_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_96_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 144.76 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 128.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_97_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_0.wav\n",
      "Episode eval_97_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_1.wav\n",
      "Episode eval_97_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_2.wav\n",
      "Episode eval_97_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_3.wav\n",
      "Episode eval_97_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_4.wav\n",
      "Episode eval_97_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_5.wav\n",
      "Episode eval_97_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_6.wav\n",
      "Episode eval_97_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_7.wav\n",
      "Episode eval_97_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_8.wav\n",
      "Episode eval_97_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_97_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 126.43 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 86.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_98_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_0.wav\n",
      "Episode eval_98_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_1.wav\n",
      "Episode eval_98_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_2.wav\n",
      "Episode eval_98_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_3.wav\n",
      "Episode eval_98_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_4.wav\n",
      "Episode eval_98_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_5.wav\n",
      "Episode eval_98_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_6.wav\n",
      "Episode eval_98_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_7.wav\n",
      "Episode eval_98_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_8.wav\n",
      "Episode eval_98_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_98_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 89.43 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_99_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_0.wav\n",
      "Episode eval_99_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_1.wav\n",
      "Episode eval_99_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_2.wav\n",
      "Episode eval_99_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_3.wav\n",
      "Episode eval_99_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_4.wav\n",
      "Episode eval_99_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_5.wav\n",
      "Episode eval_99_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_6.wav\n",
      "Episode eval_99_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_7.wav\n",
      "Episode eval_99_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_8.wav\n",
      "Episode eval_99_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_99_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 144.03 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 141.74 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_100_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_0.wav\n",
      "Episode eval_100_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_1.wav\n",
      "Episode eval_100_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_2.wav\n",
      "Episode eval_100_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_3.wav\n",
      "Episode eval_100_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_4.wav\n",
      "Episode eval_100_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_5.wav\n",
      "Episode eval_100_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_6.wav\n",
      "Episode eval_100_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_7.wav\n",
      "Episode eval_100_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_8.wav\n",
      "Episode eval_100_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_100_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 146.74 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 149.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_101_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_0.wav\n",
      "Episode eval_101_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_1.wav\n",
      "Episode eval_101_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_2.wav\n",
      "Episode eval_101_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_3.wav\n",
      "Episode eval_101_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_4.wav\n",
      "Episode eval_101_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_5.wav\n",
      "Episode eval_101_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_6.wav\n",
      "Episode eval_101_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_7.wav\n",
      "Episode eval_101_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_8.wav\n",
      "Episode eval_101_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_101_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 132.10 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 92.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_102_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_0.wav\n",
      "Episode eval_102_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_1.wav\n",
      "Episode eval_102_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_2.wav\n",
      "Episode eval_102_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_3.wav\n",
      "Episode eval_102_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_4.wav\n",
      "Episode eval_102_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_5.wav\n",
      "Episode eval_102_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_6.wav\n",
      "Episode eval_102_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_7.wav\n",
      "Episode eval_102_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_8.wav\n",
      "Episode eval_102_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_102_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 151.12 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 144.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_103_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_0.wav\n",
      "Episode eval_103_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_1.wav\n",
      "Episode eval_103_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_2.wav\n",
      "Episode eval_103_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_3.wav\n",
      "Episode eval_103_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_4.wav\n",
      "Episode eval_103_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_5.wav\n",
      "Episode eval_103_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_6.wav\n",
      "Episode eval_103_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_7.wav\n",
      "Episode eval_103_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_8.wav\n",
      "Episode eval_103_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_103_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 125.61 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_104_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_0.wav\n",
      "Episode eval_104_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_1.wav\n",
      "Episode eval_104_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_2.wav\n",
      "Episode eval_104_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_3.wav\n",
      "Episode eval_104_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_4.wav\n",
      "Episode eval_104_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_5.wav\n",
      "Episode eval_104_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_6.wav\n",
      "Episode eval_104_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_7.wav\n",
      "Episode eval_104_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_8.wav\n",
      "Episode eval_104_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_104_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 112.07 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 87.32 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_105_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_0.wav\n",
      "Episode eval_105_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_1.wav\n",
      "Episode eval_105_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_2.wav\n",
      "Episode eval_105_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_3.wav\n",
      "Episode eval_105_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_4.wav\n",
      "Episode eval_105_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_5.wav\n",
      "Episode eval_105_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_6.wav\n",
      "Episode eval_105_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_7.wav\n",
      "Episode eval_105_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_8.wav\n",
      "Episode eval_105_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_105_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.24 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 145.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_106_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_0.wav\n",
      "Episode eval_106_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_1.wav\n",
      "Episode eval_106_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_2.wav\n",
      "Episode eval_106_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_3.wav\n",
      "Episode eval_106_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_4.wav\n",
      "Episode eval_106_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_5.wav\n",
      "Episode eval_106_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_6.wav\n",
      "Episode eval_106_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_7.wav\n",
      "Episode eval_106_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_8.wav\n",
      "Episode eval_106_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_106_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 88.44 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 148.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_107_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_0.wav\n",
      "Episode eval_107_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_1.wav\n",
      "Episode eval_107_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_2.wav\n",
      "Episode eval_107_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_3.wav\n",
      "Episode eval_107_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_4.wav\n",
      "Episode eval_107_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_5.wav\n",
      "Episode eval_107_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_6.wav\n",
      "Episode eval_107_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_7.wav\n",
      "Episode eval_107_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_8.wav\n",
      "Episode eval_107_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_107_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 137.23 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 78.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_108_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_0.wav\n",
      "Episode eval_108_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_1.wav\n",
      "Episode eval_108_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_2.wav\n",
      "Episode eval_108_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_3.wav\n",
      "Episode eval_108_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_4.wav\n",
      "Episode eval_108_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_5.wav\n",
      "Episode eval_108_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_6.wav\n",
      "Episode eval_108_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_7.wav\n",
      "Episode eval_108_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_8.wav\n",
      "Episode eval_108_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_108_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.16 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 139.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_109_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_0.wav\n",
      "Episode eval_109_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_1.wav\n",
      "Episode eval_109_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_2.wav\n",
      "Episode eval_109_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_3.wav\n",
      "Episode eval_109_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_4.wav\n",
      "Episode eval_109_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_5.wav\n",
      "Episode eval_109_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_6.wav\n",
      "Episode eval_109_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_7.wav\n",
      "Episode eval_109_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_8.wav\n",
      "Episode eval_109_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_109_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 137.03 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_110_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_0.wav\n",
      "Episode eval_110_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_1.wav\n",
      "Episode eval_110_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_2.wav\n",
      "Episode eval_110_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_3.wav\n",
      "Episode eval_110_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_4.wav\n",
      "Episode eval_110_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_5.wav\n",
      "Episode eval_110_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_6.wav\n",
      "Episode eval_110_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_7.wav\n",
      "Episode eval_110_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_8.wav\n",
      "Episode eval_110_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_110_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 132.08 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 136.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_111_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_0.wav\n",
      "Episode eval_111_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_1.wav\n",
      "Episode eval_111_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_2.wav\n",
      "Episode eval_111_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_3.wav\n",
      "Episode eval_111_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_4.wav\n",
      "Episode eval_111_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_5.wav\n",
      "Episode eval_111_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_6.wav\n",
      "Episode eval_111_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_7.wav\n",
      "Episode eval_111_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_8.wav\n",
      "Episode eval_111_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_111_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 130.72 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 142.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_112_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_0.wav\n",
      "Episode eval_112_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_1.wav\n",
      "Episode eval_112_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_2.wav\n",
      "Episode eval_112_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_3.wav\n",
      "Episode eval_112_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_4.wav\n",
      "Episode eval_112_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_5.wav\n",
      "Episode eval_112_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_6.wav\n",
      "Episode eval_112_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_7.wav\n",
      "Episode eval_112_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_8.wav\n",
      "Episode eval_112_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_112_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 82.70 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 105.57 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_113_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_0.wav\n",
      "Episode eval_113_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_1.wav\n",
      "Episode eval_113_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_2.wav\n",
      "Episode eval_113_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_3.wav\n",
      "Episode eval_113_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_4.wav\n",
      "Episode eval_113_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_5.wav\n",
      "Episode eval_113_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_6.wav\n",
      "Episode eval_113_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_7.wav\n",
      "Episode eval_113_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_8.wav\n",
      "Episode eval_113_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_113_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 95.62 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 98.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_114_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_0.wav\n",
      "Episode eval_114_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_1.wav\n",
      "Episode eval_114_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_2.wav\n",
      "Episode eval_114_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_3.wav\n",
      "Episode eval_114_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_4.wav\n",
      "Episode eval_114_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_5.wav\n",
      "Episode eval_114_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_6.wav\n",
      "Episode eval_114_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_7.wav\n",
      "Episode eval_114_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_8.wav\n",
      "Episode eval_114_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_114_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 105.79 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 133.94 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_115_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_0.wav\n",
      "Episode eval_115_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_1.wav\n",
      "Episode eval_115_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_2.wav\n",
      "Episode eval_115_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_3.wav\n",
      "Episode eval_115_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_4.wav\n",
      "Episode eval_115_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_5.wav\n",
      "Episode eval_115_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_6.wav\n",
      "Episode eval_115_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_7.wav\n",
      "Episode eval_115_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_8.wav\n",
      "Episode eval_115_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_115_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 128.39 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 121.84 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_116_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_0.wav\n",
      "Episode eval_116_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_1.wav\n",
      "Episode eval_116_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_2.wav\n",
      "Episode eval_116_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_3.wav\n",
      "Episode eval_116_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_4.wav\n",
      "Episode eval_116_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_5.wav\n",
      "Episode eval_116_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_6.wav\n",
      "Episode eval_116_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_7.wav\n",
      "Episode eval_116_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_8.wav\n",
      "Episode eval_116_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_116_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 105.25 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 151.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_117_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_0.wav\n",
      "Episode eval_117_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_1.wav\n",
      "Episode eval_117_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_2.wav\n",
      "Episode eval_117_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_3.wav\n",
      "Episode eval_117_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_4.wav\n",
      "Episode eval_117_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_5.wav\n",
      "Episode eval_117_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_6.wav\n",
      "Episode eval_117_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_7.wav\n",
      "Episode eval_117_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_8.wav\n",
      "Episode eval_117_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_117_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 122.68 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 115.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_118_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_0.wav\n",
      "Episode eval_118_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_1.wav\n",
      "Episode eval_118_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_2.wav\n",
      "Episode eval_118_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_3.wav\n",
      "Episode eval_118_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_4.wav\n",
      "Episode eval_118_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_5.wav\n",
      "Episode eval_118_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_6.wav\n",
      "Episode eval_118_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_7.wav\n",
      "Episode eval_118_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_8.wav\n",
      "Episode eval_118_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_118_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 89.85 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 122.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_119_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_0.wav\n",
      "Episode eval_119_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_1.wav\n",
      "Episode eval_119_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_2.wav\n",
      "Episode eval_119_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_3.wav\n",
      "Episode eval_119_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_4.wav\n",
      "Episode eval_119_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_5.wav\n",
      "Episode eval_119_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_6.wav\n",
      "Episode eval_119_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_7.wav\n",
      "Episode eval_119_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_8.wav\n",
      "Episode eval_119_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_119_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 132.38 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 137.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_120_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_0.wav\n",
      "Episode eval_120_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_1.wav\n",
      "Episode eval_120_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_2.wav\n",
      "Episode eval_120_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_3.wav\n",
      "Episode eval_120_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_4.wav\n",
      "Episode eval_120_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_5.wav\n",
      "Episode eval_120_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_6.wav\n",
      "Episode eval_120_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_7.wav\n",
      "Episode eval_120_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_8.wav\n",
      "Episode eval_120_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_120_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.29 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 98.16 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_121_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_0.wav\n",
      "Episode eval_121_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_1.wav\n",
      "Episode eval_121_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_2.wav\n",
      "Episode eval_121_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_3.wav\n",
      "Episode eval_121_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_4.wav\n",
      "Episode eval_121_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_5.wav\n",
      "Episode eval_121_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_6.wav\n",
      "Episode eval_121_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_7.wav\n",
      "Episode eval_121_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_8.wav\n",
      "Episode eval_121_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_121_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 140.26 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_122_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_0.wav\n",
      "Episode eval_122_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_1.wav\n",
      "Episode eval_122_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_2.wav\n",
      "Episode eval_122_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_3.wav\n",
      "Episode eval_122_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_4.wav\n",
      "Episode eval_122_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_5.wav\n",
      "Episode eval_122_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_6.wav\n",
      "Episode eval_122_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_7.wav\n",
      "Episode eval_122_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_8.wav\n",
      "Episode eval_122_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_122_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 145.43 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 112.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_123_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_0.wav\n",
      "Episode eval_123_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_1.wav\n",
      "Episode eval_123_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_2.wav\n",
      "Episode eval_123_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_3.wav\n",
      "Episode eval_123_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_4.wav\n",
      "Episode eval_123_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_5.wav\n",
      "Episode eval_123_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_6.wav\n",
      "Episode eval_123_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_7.wav\n",
      "Episode eval_123_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_8.wav\n",
      "Episode eval_123_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_123_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 87.13 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 75.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_124_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_0.wav\n",
      "Episode eval_124_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_1.wav\n",
      "Episode eval_124_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_2.wav\n",
      "Episode eval_124_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_3.wav\n",
      "Episode eval_124_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_4.wav\n",
      "Episode eval_124_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_5.wav\n",
      "Episode eval_124_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_6.wav\n",
      "Episode eval_124_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_7.wav\n",
      "Episode eval_124_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_8.wav\n",
      "Episode eval_124_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_124_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 87.66 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 143.73 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_125_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_0.wav\n",
      "Episode eval_125_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_1.wav\n",
      "Episode eval_125_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_2.wav\n",
      "Episode eval_125_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_3.wav\n",
      "Episode eval_125_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_4.wav\n",
      "Episode eval_125_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_5.wav\n",
      "Episode eval_125_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_6.wav\n",
      "Episode eval_125_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_7.wav\n",
      "Episode eval_125_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_8.wav\n",
      "Episode eval_125_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_125_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.58 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 113.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_126_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_0.wav\n",
      "Episode eval_126_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_1.wav\n",
      "Episode eval_126_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_2.wav\n",
      "Episode eval_126_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_3.wav\n",
      "Episode eval_126_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_4.wav\n",
      "Episode eval_126_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_5.wav\n",
      "Episode eval_126_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_6.wav\n",
      "Episode eval_126_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_7.wav\n",
      "Episode eval_126_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_8.wav\n",
      "Episode eval_126_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_126_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 95.95 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 141.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_127_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_0.wav\n",
      "Episode eval_127_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_1.wav\n",
      "Episode eval_127_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_2.wav\n",
      "Episode eval_127_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_3.wav\n",
      "Episode eval_127_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_4.wav\n",
      "Episode eval_127_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_5.wav\n",
      "Episode eval_127_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_6.wav\n",
      "Episode eval_127_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_7.wav\n",
      "Episode eval_127_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_8.wav\n",
      "Episode eval_127_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_127_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 100.40 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 126.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_128_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_0.wav\n",
      "Episode eval_128_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_1.wav\n",
      "Episode eval_128_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_2.wav\n",
      "Episode eval_128_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_3.wav\n",
      "Episode eval_128_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_4.wav\n",
      "Episode eval_128_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_5.wav\n",
      "Episode eval_128_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_6.wav\n",
      "Episode eval_128_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_7.wav\n",
      "Episode eval_128_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_8.wav\n",
      "Episode eval_128_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_128_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 128.05 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_129_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_0.wav\n",
      "Episode eval_129_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_1.wav\n",
      "Episode eval_129_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_2.wav\n",
      "Episode eval_129_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_3.wav\n",
      "Episode eval_129_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_4.wav\n",
      "Episode eval_129_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_5.wav\n",
      "Episode eval_129_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_6.wav\n",
      "Episode eval_129_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_7.wav\n",
      "Episode eval_129_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_8.wav\n",
      "Episode eval_129_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_129_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 132.29 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 147.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_130_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_0.wav\n",
      "Episode eval_130_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_1.wav\n",
      "Episode eval_130_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_2.wav\n",
      "Episode eval_130_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_3.wav\n",
      "Episode eval_130_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_4.wav\n",
      "Episode eval_130_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_5.wav\n",
      "Episode eval_130_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_6.wav\n",
      "Episode eval_130_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_7.wav\n",
      "Episode eval_130_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_8.wav\n",
      "Episode eval_130_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_130_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 143.97 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 112.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_131_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_0.wav\n",
      "Episode eval_131_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_1.wav\n",
      "Episode eval_131_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_2.wav\n",
      "Episode eval_131_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_3.wav\n",
      "Episode eval_131_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_4.wav\n",
      "Episode eval_131_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_5.wav\n",
      "Episode eval_131_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_6.wav\n",
      "Episode eval_131_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_7.wav\n",
      "Episode eval_131_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_8.wav\n",
      "Episode eval_131_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_131_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 127.08 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 95.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_132_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_0.wav\n",
      "Episode eval_132_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_1.wav\n",
      "Episode eval_132_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_2.wav\n",
      "Episode eval_132_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_3.wav\n",
      "Episode eval_132_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_4.wav\n",
      "Episode eval_132_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_5.wav\n",
      "Episode eval_132_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_6.wav\n",
      "Episode eval_132_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_7.wav\n",
      "Episode eval_132_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_8.wav\n",
      "Episode eval_132_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_132_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 79.47 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 143.96 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_133_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_0.wav\n",
      "Episode eval_133_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_1.wav\n",
      "Episode eval_133_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_2.wav\n",
      "Episode eval_133_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_3.wav\n",
      "Episode eval_133_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_4.wav\n",
      "Episode eval_133_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_5.wav\n",
      "Episode eval_133_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_6.wav\n",
      "Episode eval_133_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_7.wav\n",
      "Episode eval_133_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_8.wav\n",
      "Episode eval_133_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_133_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 142.26 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 109.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_134_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_0.wav\n",
      "Episode eval_134_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_1.wav\n",
      "Episode eval_134_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_2.wav\n",
      "Episode eval_134_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_3.wav\n",
      "Episode eval_134_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_4.wav\n",
      "Episode eval_134_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_5.wav\n",
      "Episode eval_134_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_6.wav\n",
      "Episode eval_134_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_7.wav\n",
      "Episode eval_134_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_8.wav\n",
      "Episode eval_134_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_134_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 137.95 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 83.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_135_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_0.wav\n",
      "Episode eval_135_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_1.wav\n",
      "Episode eval_135_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_2.wav\n",
      "Episode eval_135_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_3.wav\n",
      "Episode eval_135_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_4.wav\n",
      "Episode eval_135_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_5.wav\n",
      "Episode eval_135_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_6.wav\n",
      "Episode eval_135_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_7.wav\n",
      "Episode eval_135_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_8.wav\n",
      "Episode eval_135_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_135_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 130.61 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 141.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_136_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_0.wav\n",
      "Episode eval_136_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_1.wav\n",
      "Episode eval_136_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_2.wav\n",
      "Episode eval_136_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_3.wav\n",
      "Episode eval_136_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_4.wav\n",
      "Episode eval_136_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_5.wav\n",
      "Episode eval_136_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_6.wav\n",
      "Episode eval_136_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_7.wav\n",
      "Episode eval_136_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_8.wav\n",
      "Episode eval_136_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_136_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 90.77 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 110.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_137_data_9_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_0.wav\n",
      "Episode eval_137_data_9_1 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_1.wav\n",
      "Episode eval_137_data_9_2 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_2.wav\n",
      "Episode eval_137_data_9_3 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_3.wav\n",
      "Episode eval_137_data_9_4 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_4.wav\n",
      "Episode eval_137_data_9_5 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_5.wav\n",
      "Episode eval_137_data_9_6 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_6.wav\n",
      "Episode eval_137_data_9_7 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_7.wav\n",
      "Episode eval_137_data_9_8 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_8.wav\n",
      "Episode eval_137_data_9_9 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_eval_137_data_9_9.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n",
      "Episode data_0 : audio saved to  /work/b0990106x/trl/output/1020-2012/example_save_data_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1/1 [00:00<00:00, 99.52 examples/s]\n",
      "Map: 100%|| 1/1 [00:00<00:00, 146.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disable_tqdm = not os.isatty(1)\n",
    "for iteration in tqdm(range(num_iterations), desc=\"Training Iterations\", disable=disable_tqdm):\n",
    "    logging.info(f\"-----------Starting iteration {iteration}-----------\")\n",
    "    \n",
    "    # resume = iteration > 0 # resume from the previous checkpoint when iteration > 0\n",
    "    resume = False\n",
    "    \n",
    "    # model_checkpoint is the model checkpoint from the previous iteration\n",
    "    # chosen_rewards and rejected_rewards are the rewards of the data\n",
    "    model_checkpoint, chosen_rewards, rejected_rewards = train_iteration(model,\n",
    "                                model_checkpoint,\n",
    "                                iteration=iteration,\n",
    "                                data_size=data_size_per_iteration,\n",
    "                                sample_size=sample_size,\n",
    "                                ar_model=ar_model,\n",
    "                                ar_tokenizer=ar_tokenizer,\n",
    "                                nar_model=nar_model,\n",
    "                                nar_tokenizer=nar_tokenizer,\n",
    "                                all_src_encodec=batch_src_encodec,\n",
    "                                all_instruction=batch_instruction,\n",
    "                                args_predict=args_predict,\n",
    "                                agent_output_dir=agent_output_dir,\n",
    "                                model_output_dir_base=model_output_dir,\n",
    "                                temperature = 1.0,\n",
    "                                beta=beta,\n",
    "                                base_path=base_path,\n",
    "                                resume_from_checkpoint=resume, \n",
    "                                learning_rate=learning_rate,\n",
    "                                num_train_epochs=num_train_epochs,\n",
    "                                max_length=max_length,\n",
    "                                max_prompt_length=max_prompt_length,\n",
    "                                max_target_length=max_target_length,\n",
    "                                per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                                seed=seed,\n",
    "                                clap_model=clap_model,\n",
    "                                accelerator=accelerator\n",
    "                                )       \n",
    "\n",
    "    logging.info(f\"Chosen rewards for iteration {iteration}: {chosen_rewards}\")\n",
    "    logging.info(f\"Rejected rewards for iteration {iteration}: {rejected_rewards}\")\n",
    "    logging.info(f\"Finished training iteration {iteration}\")\n",
    "\n",
    "    if (iteration+1) % eval_frequency == 0:\n",
    "    # Evaluate the result of the current iteration\n",
    "        if eval_train:\n",
    "            # eval dpo claps\n",
    "            trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_train_data_len,\n",
    "                                                                        selected_indices=eval_train_indices,\n",
    "                                                                        device=device,\n",
    "                                                                        clap_model=clap_model,\n",
    "                                                                        accelerator=accelerator\n",
    "                                                                        )\n",
    "            logging.info(f\"Trained Model Iteration {iteration} Train Set Evaluation: \")\n",
    "            logging.info(f\"EVAL: Cosine_Sim metrics Training Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            logging.info(f\"EVAL: Cosine_Sim score Training Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "            \n",
    "            # eval dpo mos\n",
    "            trained_model_metrics_mos, trained_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_train_data_len,\n",
    "                                                                        selected_indices=eval_train_indices,\n",
    "                                                                        device=device\n",
    "                                                                        )\n",
    "            logging.info(f\"EVAL: MOS metrics Training Set for iteration {iteration}: {trained_model_metrics_mos}\")\n",
    "            logging.info(f\"EVAL: MOS score Training Set for iteration {iteration}: {trained_model_rewards_mos}\")\n",
    "            \n",
    "            reward_list = []\n",
    "            for rewards in trained_model_rewards:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list.append(None)\n",
    "                else:\n",
    "                    reward_list.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "            reward_list_mos = []\n",
    "            for rewards in trained_model_rewards_mos:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list_mos.append(None)\n",
    "                else:\n",
    "                    reward_list_mos.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model MOS score list on training set: {reward_list_mos}\")\n",
    "            \n",
    "            filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            if len(filter_reward_list) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: {np.mean(filter_reward_list)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: None\")\n",
    "            \n",
    "            filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "            if len(filter_reward_list_mos) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: {np.mean(filter_reward_list_mos)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: None\")\n",
    "                \n",
    "            weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "            logging.info(f\"EVAL: Trained model weighted average score on training set for iteration {iteration}: {weighted_reward}\")\n",
    "\n",
    "        if eval_test:\n",
    "            trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_test_data_len,\n",
    "                                                                        selected_indices=eval_test_indices,\n",
    "                                                                        device=device,\n",
    "                                                                        clap_model=clap_model,\n",
    "                                                                        accelerator=accelerator\n",
    "                                                                        )\n",
    "            logging.info(f\"Trained Model Iteration {iteration} Test Set Evaluation: \")\n",
    "            logging.info(f\"EVAL: Cosine_Sim metrics Testing Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            logging.info(f\"EVAL: Cosine_Sim score Testing Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "\n",
    "            reward_list = []\n",
    "            for rewards in trained_model_rewards:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list.append(None)\n",
    "                else:\n",
    "                    reward_list.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model Cosine_Sim score list on testing set: {reward_list}\")\n",
    "            filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            if len(filter_reward_list) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: {np.mean(filter_reward_list)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: None\")\n",
    "\n",
    "    logging.info(f\"-----------Finished iteration {iteration}-----------\")\n",
    "total_end_time = time.time()\n",
    "\n",
    "# Calculate total time taken\n",
    "total_time_taken = total_end_time - total_start_time\n",
    "logging.info(f\"Total time taken for the entire process: {total_time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Function to parse the log file for both EVAL and Original model metrics\n",
    "def parse_log_file(log_path):\n",
    "    eval_pattern = re.compile(\n",
    "        r\"EVAL: Cosine_Sim metrics Training Set for iteration (\\d+): (.+)\"\n",
    "    )\n",
    "    original_model_pattern = re.compile(\n",
    "        r\"Original model metrics on training set: (.+)\"\n",
    "    )\n",
    "    \n",
    "    data = {\"EVAL\": {}, \"Original\": []}\n",
    "\n",
    "    # Read the log file line by line\n",
    "    with open(log_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            eval_match = eval_pattern.search(line)\n",
    "            original_match = original_model_pattern.search(line)\n",
    "\n",
    "            # If it's an EVAL line\n",
    "            if eval_match:\n",
    "                iteration = int(eval_match.group(1)) + 1  # Adding 1 to iteration as requested\n",
    "                metrics_list = eval_match.group(2).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                # Store means and std_devs for this iteration\n",
    "                means = []\n",
    "                std_devs = []\n",
    "                counts = []\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    count = len(metrics['metrics']['rewards'])  # Number of rewards is the sample size\n",
    "\n",
    "                    means.append(mean)\n",
    "                    std_devs.append(std_dev)\n",
    "                    counts.append(count)\n",
    "\n",
    "                # Store mean, std_dev, and count for each iteration\n",
    "                data[\"EVAL\"][iteration] = {\n",
    "                    \"means\": means,\n",
    "                    \"std_devs\": std_devs,\n",
    "                    \"counts\": counts\n",
    "                }\n",
    "\n",
    "            # If it's an Original Model Metrics line\n",
    "            elif original_match:\n",
    "                metrics_list = original_match.group(1).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    data[\"Original\"].append((mean, std_dev))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to calculate the pooled standard deviation\n",
    "def pooled_std_dev(std_devs, counts):\n",
    "    # Pooled variance formula\n",
    "    numerator = sum((counts[i] - 1) * (std_devs[i] ** 2) for i in range(len(std_devs)))\n",
    "    denominator = sum(counts[i] - 1 for i in range(len(counts)))\n",
    "\n",
    "    if denominator > 0:\n",
    "        pooled_variance = numerator / denominator\n",
    "        return np.sqrt(pooled_variance)\n",
    "    else:\n",
    "        return 0  # In case of single value or no variance\n",
    "\n",
    "# Function to plot iteration vs the average mean and pooled std_dev\n",
    "def plot_metrics(data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot EVAL data (average across all idx)\n",
    "    iterations = sorted(data[\"EVAL\"].keys())\n",
    "    avg_means = []\n",
    "    pooled_std_devs = []\n",
    "\n",
    "    for iteration in iterations:\n",
    "        means = data[\"EVAL\"][iteration][\"means\"]\n",
    "        std_devs = data[\"EVAL\"][iteration][\"std_devs\"]\n",
    "        counts = data[\"EVAL\"][iteration][\"counts\"]\n",
    "\n",
    "        # Calculate the average mean for the iteration\n",
    "        avg_mean = sum(means) / len(means)\n",
    "        avg_means.append(avg_mean)\n",
    "\n",
    "        # Calculate the pooled standard deviation for the iteration\n",
    "        pooled_std_dev_value = pooled_std_dev(std_devs, counts)\n",
    "        pooled_std_devs.append(pooled_std_dev_value)\n",
    "\n",
    "    # Plot the average means with pooled std_dev as error bars\n",
    "    plt.errorbar(iterations, avg_means, yerr=pooled_std_devs, fmt='o-', capsize=5, label='Average Mean with Pooled Std Dev')\n",
    "\n",
    "    # Plot Original Model data (if available)\n",
    "    if \"Original\" in data and len(data[\"Original\"]) > 0:\n",
    "        original_means = [item[0] for item in data[\"Original\"]]\n",
    "        original_std_devs = [item[1] for item in data[\"Original\"]]\n",
    "        avg_original_mean = np.mean(original_means)\n",
    "        pooled_original_std_dev = pooled_std_dev(original_std_devs, [10] * len(original_std_devs))  # Assuming 10 samples per idx\n",
    "\n",
    "        plt.errorbar([0], [avg_original_mean], yerr=[pooled_original_std_dev], fmt='x', color='r', label='Original Model Average Mean')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Mean')\n",
    "    plt.title('Iteration vs Average Mean with Pooled Std Dev')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parse the log file\n",
    "data = parse_log_file(log_path)\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
