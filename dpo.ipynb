{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\")\n",
    "import importlib\n",
    "import vc\n",
    "importlib.reload(vc)\n",
    "import torch\n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction_v3\n",
    "from types import SimpleNamespace\n",
    "from transformers import BartForConditionalGeneration, AutoModelForCausalLM, AutoTokenizer\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "from datasets import load_from_disk\n",
    "from trl import DPOTrainer, DPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 0620-1700\n"
     ]
    }
   ],
   "source": [
    "# Define paths and device\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "model_output_dir = f\"{base_path}/model_output/{ts}\"\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "if not os.path.exists(model_output_dir):\n",
    "    os.makedirs(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(ar_checkpoint, return_dict=True)\n",
    "model_ref = create_reference_model(model)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "ar_tokenizer.pad_token = ar_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'chosen', 'rejected'],\n",
      "    num_rows: 9254\n",
      "})\n",
      "train_dataset Dataset({\n",
      "    features: ['prompt', 'chosen', 'rejected'],\n",
      "    num_rows: 8328\n",
      "})\n",
      "val_dataset Dataset({\n",
      "    features: ['prompt', 'chosen', 'rejected'],\n",
      "    num_rows: 926\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "# load the dpo_data.json file\n",
    "with open(\"dpo_data_all.json\") as f:\n",
    "    dpo_data = json.load(f)\n",
    "\n",
    "# load the dataset\n",
    "dataset = Dataset.from_dict(dpo_data)\n",
    "print(dataset)\n",
    "\n",
    "## TODO: Split the dataset into training and validation sets\n",
    "dataset_dict = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# load the training and validation datasets\n",
    "train_dataset = dataset_dict[\"train\"]\n",
    "val_dataset = dataset_dict[\"test\"]\n",
    "print(\"train_dataset\", train_dataset)\n",
    "print(\"val_dataset\", val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mb09901066\u001b[0m (\u001b[33mb09901066_alan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/b0990106x/trl/wandb/run-20240620_170046-zwk8uuqs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/b09901066_alan/trl/runs/zwk8uuqs' target=\"_blank\">polar-mountain-9</a></strong> to <a href='https://wandb.ai/b09901066_alan/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/b09901066_alan/trl' target=\"_blank\">https://wandb.ai/b09901066_alan/trl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/b09901066_alan/trl/runs/zwk8uuqs' target=\"_blank\">https://wandb.ai/b09901066_alan/trl/runs/zwk8uuqs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/b09901066_alan/trl/runs/zwk8uuqs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe20daa18d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"trl\"\n",
    "wandb.init(project=\"trl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/trl/trainer/dpo_trainer.py:362: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/work/b0990106x/trl/trl/trainer/dpo_trainer.py:375: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/work/b0990106x/trl/trl/trainer/dpo_trainer.py:388: UserWarning: When using an encoder decoder architecture, you should set `max_target_length` in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "/work/b0990106x/trl/trl/trainer/dpo_trainer.py:410: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 8328/8328 [00:17<00:00, 474.91 examples/s]\n",
      "Map: 100%|██████████| 926/926 [00:01<00:00, 480.38 examples/s]\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3123' max='3123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3123/3123 13:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/work/b0990106x/trl/model_output/0620-1700/dpo_model/tokenizer_config.json',\n",
       " '/work/b0990106x/trl/model_output/0620-1700/dpo_model/special_tokens_map.json',\n",
       " '/work/b0990106x/trl/model_output/0620-1700/dpo_model/vocab.json',\n",
       " '/work/b0990106x/trl/model_output/0620-1700/dpo_model/merges.txt',\n",
       " '/work/b0990106x/trl/model_output/0620-1700/dpo_model/added_tokens.json',\n",
       " '/work/b0990106x/trl/model_output/0620-1700/dpo_model/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = DPOConfig(\n",
    "    beta=0.02,\n",
    "    output_dir=f\"{model_output_dir}\",\n",
    "    generate_during_eval = True,\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=model_ref,\n",
    "    args=training_args,\n",
    "    tokenizer=ar_tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()\n",
    "\n",
    "# save the model\n",
    "trainer.save_model(f\"{model_output_dir}/dpo_model\")\n",
    "\n",
    "model.config.to_json_file(f\"{model_output_dir}/dpo_model/config.json\")\n",
    "ar_tokenizer.save_pretrained(f\"{model_output_dir}/dpo_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\")\n",
    "import importlib\n",
    "import vc\n",
    "importlib.reload(vc)\n",
    "import torch\n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction_v3\n",
    "from types import SimpleNamespace\n",
    "from transformers import BartForConditionalGeneration, AutoModelForCausalLM, AutoTokenizer\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "from datasets import load_from_disk\n",
    "from trl import DPOTrainer, DPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and device\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# now = datetime.now()\n",
    "# ts = now.strftime(\"%m%d-%H%M\")\n",
    "# print(\"timestamp:\", ts)\n",
    "ts = \"beta2_v2\"\n",
    "\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "\n",
    "if not os.path.exists(agent_output_dir):\n",
    "    os.makedirs(agent_output_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len: 9957\n"
     ]
    }
   ],
   "source": [
    "# Prepare Model\n",
    "\n",
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "\n",
    "layer_len = 8\n",
    "# data_len = len(dataset)\n",
    "\n",
    "\n",
    "args_predict = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=0, device=device)\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "test_dataset = load_from_disk(agent_input_dir)\n",
    "data_len = len(test_dataset)\n",
    "print(\"data_len:\", data_len)\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(test_dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):\n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "    all_instruction.append(test_dataset[\"instruction\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "ar_tokenizer.pad_token = ar_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate reward\n",
    "import time\n",
    "def get_reward(output_path):\n",
    "    args_nisqa = {\n",
    "        \"mode\": \"predict_file\",\n",
    "        \"pretrained_model\": f\"{base_path}/NISQA/weights/nisqa.tar\",\n",
    "        \"deg\": output_path,\n",
    "        \"data_dir\": None,\n",
    "        \"output_dir\": f\"{base_path}/NISQA/result/\",\n",
    "        \"csv_file\": None,\n",
    "        \"csv_deg\": None,\n",
    "        \"num_workers\": 0,\n",
    "        \"bs\": 1,\n",
    "        \"ms_channel\": None,\n",
    "    }\n",
    "    args_nisqa[\"tr_bs_val\"] = args_nisqa[\"bs\"]\n",
    "    args_nisqa[\"tr_num_workers\"] = args_nisqa[\"num_workers\"]\n",
    "    nisqa = nisqaModel(args_nisqa)\n",
    "    try:\n",
    "        prediction = nisqa.predict()\n",
    "        reward = float(prediction[\"mos_pred\"].iloc[0])\n",
    "        print(\"Reward:\", reward)\n",
    "        return reward\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        print(\"get_reward function end ___________________________\")\n",
    "        return None\n",
    "    \n",
    "def process_and_get_scores(model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter=0):\n",
    "    temp, decode_ar,output_path_ckpt = get_ar_prediction_v3(args_predict, model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter)\n",
    "    list_decode_ar = decode_ar.flatten().tolist()\n",
    "    time.sleep(0.5)\n",
    "    reward = get_reward(output_path_ckpt)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /work/b0990106x/trl/model_output/beta2/dpo_model were not used when initializing BartForConditionalGeneration: ['v_head.summary.weight', 'v_head.summary.bias']\n",
      "- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "trained_model = BartForConditionalGeneration.from_pretrained(f\"{base_path}/model_output/beta2/dpo_model\")\n",
    "model = BartForConditionalGeneration.from_pretrained(ar_checkpoint, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store rewards\n",
    "old_model_rewards = []\n",
    "trained_model_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 2.3696582317352295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_0.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 1 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_1.wav\n",
      "Reward: 1.8643907308578491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_1.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 2 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_2.wav\n",
      "Reward: 2.1817805767059326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_2.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 3 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_3.wav\n",
      "Reward: 2.3666038513183594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_3.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 4 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_4.wav\n",
      "Reward: 1.5610311031341553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.9144290685653687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 2.140477180480957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1.6554147005081177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 2.562260389328003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1.4340027570724487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 2.781407117843628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1.9595450162887573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 3.0084025859832764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 8 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_8.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 9 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_9.wav\n",
      "Reward: 2.990460157394409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_9.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 10 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_10.wav\n",
      "Reward: 2.2922699451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_10.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 11 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_11.wav\n",
      "Reward: 3.2622463703155518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 11 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta2_v2/example_save_11.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "Episode 12 : audio saved to  /work/b0990106x/trl/output/beta2_v2/example_save_12.wav\n",
      "Reward: 1.8696385622024536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Process with trained model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m trained_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 21\u001b[0m trained_model_reward \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_and_get_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_encodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_counter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m trained_model_rewards\u001b[38;5;241m.\u001b[39mappend(trained_model_reward)\n\u001b[1;32m     24\u001b[0m count_rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mprocess_and_get_scores\u001b[0;34m(model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_get_scores\u001b[39m(model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     temp, decode_ar,output_path_ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mget_ar_prediction_v3\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_encodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_counter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     list_decode_ar \u001b[38;5;241m=\u001b[39m decode_ar\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     32\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/work/b0990106x/trl/vc/trainer_encodec_vc_inference.py:290\u001b[0m, in \u001b[0;36mget_ar_prediction_v3\u001b[0;34m(args, ar_model, nar_model, ar_tokenizer, nar_tokenizer, single_src_encodec, single_instruction, episode_counter)\u001b[0m\n\u001b[1;32m    288\u001b[0m ar_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    289\u001b[0m nar_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 290\u001b[0m layer_list, decode_ar \u001b[38;5;241m=\u001b[39m \u001b[43mcascade_ar_nar_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_src_encodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_instruction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m encodec_code \u001b[38;5;241m=\u001b[39m convert_to_encode_code(nar_tokenizer, layer_list) \n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# print(\"encodec_code[0](get_ar_prediction): \", encodec_code[0])   \u001b[39;00m\n",
      "File \u001b[0;32m/work/b0990106x/trl/vc/trainer_encodec_vc_inference.py:171\u001b[0m, in \u001b[0;36mcascade_ar_nar_v2\u001b[0;34m(ar_model, nar_model, ar_tokenizer, nar_tokenizer, device, single_src_encodec, single_instruction)\u001b[0m\n\u001b[1;32m    169\u001b[0m bad_words_ids\u001b[38;5;241m.\u001b[39mextend(vocab_ids)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# 50265 to 59480 is the range of good words\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m decode_ar \u001b[38;5;241m=\u001b[39m \u001b[43mar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbad_words_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# print(\"-- decode_ar: \", decode_ar)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# print(\"-- decode_ar shape: \", decode_ar.shape)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m layer_list\u001b[38;5;241m.\u001b[39mappend(decode_ar[:, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/generation/utils.py:1588\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1581\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1582\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1583\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1585\u001b[0m     )\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/generation/utils.py:2642\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2639\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2642\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1380\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1377\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1378\u001b[0m         )\n\u001b[0;32m-> 1380\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1398\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1399\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1266\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1260\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1261\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1266\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1124\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   1114\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m   1115\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1122\u001b[0m     )\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:463\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    462\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 463\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    464\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    465\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trl/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "count_rewards = 0\n",
    "target_rewards = 1000\n",
    "\n",
    "while count_rewards < target_rewards:\n",
    "    if i >= data_len:\n",
    "        print(\"Exceeded initial data length.\")\n",
    "        break\n",
    "    instruction = all_instruction[i]\n",
    "    src_encodec = all_src_encodec[i]\n",
    "    size_of_packed_input = (len(src_encodec[0]) + len(ar_tokenizer(instruction)[\"input_ids\"][1:-1]) + 3)\n",
    "    \n",
    "    if size_of_packed_input <= 1024 and size_of_packed_input > 4:\n",
    "        # Process with old model\n",
    "        model.to(device)\n",
    "        old_model_reward = process_and_get_scores(model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter=i)\n",
    "        old_model_rewards.append(old_model_reward)\n",
    "\n",
    "        # Process with trained model\n",
    "        trained_model.to(device)\n",
    "        trained_model_reward = process_and_get_scores(trained_model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter=i)\n",
    "        trained_model_rewards.append(trained_model_reward)\n",
    "\n",
    "        count_rewards += 1\n",
    "    else:\n",
    "        print(f\"Skipping data point {i} due to insufficient packed input size.\")\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Model Rewards: [None, 1.8717782497406006, None, 2.757830858230591, 1.6322604417800903, None, None, 2.7113113403320312, None, 2.6343016624450684, 2.1417410373687744, None, 1.6103763580322266, 1.5146719217300415, None, None, 2.137955665588379, 2.2793071269989014, 1.9043837785720825, 2.251277446746826, None, 2.208383321762085, 2.401906967163086, 2.4635074138641357, 2.303755044937134, 2.552902936935425, 2.5948641300201416, None, 2.0390915870666504, 2.6507956981658936, None, None, 2.429182291030884, None, 1.006941318511963, 3.001690626144409, 2.018461227416992, 2.4022371768951416, None, 2.87459659576416, 1.7149690389633179, None, 2.4751648902893066, 2.767028570175171, None, 2.1119844913482666, None, None, None, None, 1.8746711015701294, None, 2.250643014907837, 2.07224702835083, 2.6481125354766846, 1.292348027229309, 2.2126989364624023, None, 1.932268738746643, 2.022994041442871, None, None, None, None, 2.479299306869507, 2.460249423980713, 2.8040478229522705, None, 1.8452807664871216, 2.698622941970825, 1.4511569738388062, 2.339092493057251, None, None, 2.7808375358581543, 2.2024786472320557, 2.6199629306793213, 2.3698909282684326, 3.087576150894165, None, 2.516688108444214, None, None, 2.603034734725952, None, 2.8190555572509766, 2.512160062789917, 2.321502923965454, 1.9147075414657593, 2.1016576290130615, None, 2.3917696475982666, 2.231346368789673, 2.59100341796875, 2.107889413833618, 3.493964433670044, None, 1.6760021448135376, None, 2.947801351547241, 1.776427149772644, 2.044395923614502, 1.2437347173690796, 2.6421988010406494, None, None, None, None, 1.6375943422317505, None, None, 2.962815523147583, None, None, 1.1537154912948608, 2.7644455432891846, None, None, 1.8909300565719604, 2.068174123764038, 2.4823639392852783, 3.6689844131469727, 2.4112884998321533, 1.9805880784988403, 2.756356954574585, 2.4178459644317627, None, None, 2.343496561050415, None, 2.1202940940856934, 1.6322604417800903, None, 2.87587571144104, 1.5425348281860352, None, None, 1.5922611951828003, None, None, 3.190599203109741, None, 1.6575795412063599, 2.1286327838897705, 1.3710272312164307, 3.236826181411743, 2.285385847091675, None, 2.0920376777648926, None, 2.07487416267395, 2.6924757957458496, 2.4678423404693604, 2.6507132053375244, None, 2.6448256969451904, 2.8129260540008545, 2.5297417640686035, 2.1030073165893555, None, None, 1.5639011859893799, 2.048419713973999, 2.5761091709136963, None, 1.404265284538269, None, None, 1.9823824167251587, 2.026893138885498, 2.8469417095184326, None, 1.6555310487747192, 2.3684499263763428, None, 1.8104654550552368, 2.0898501873016357, 2.0835015773773193, 2.720669984817505, None, 2.5338308811187744, 2.4068825244903564, 2.29646635055542, None, 1.3923648595809937, 2.9863412380218506, None, None, 2.8286068439483643, None, None, 3.0477020740509033, 2.5755088329315186, None, None, 1.0068262815475464, 3.4454376697540283, None, 2.665567636489868, 3.883965253829956, 1.5050253868103027, 2.3372249603271484, None, 2.9270272254943848, 2.523075819015503, 2.0387396812438965, 2.341818332672119, 2.0358691215515137, 2.1952948570251465, 2.168802499771118, None, 2.31009840965271, 1.1614253520965576, 2.025080680847168, None, 2.31886625289917, 2.256460666656494, None, None, 1.6570839881896973, 2.601050615310669, None, 2.651803731918335, 1.730347990989685, 1.3710272312164307, 1.4591292142868042, None, 3.1942296028137207, 2.56734299659729, 2.3212549686431885, None, 2.0081241130828857, 1.5285930633544922, 1.3710272312164307, 1.8919204473495483, 2.4469125270843506, 2.943326711654663, 2.193479061126709, 1.4770299196243286, None, 2.6430184841156006, 1.255906581878662, 1.4936314821243286, 2.7199790477752686, 1.9386265277862549, 2.672511577606201, 1.3556759357452393, 2.599682569503784, 1.032417893409729, 2.383347272872925, 1.8230003118515015, 2.292229413986206, 2.0938405990600586, 2.959522008895874, 3.1814229488372803, None, None, 2.281994104385376, 1.3124016523361206, 2.7794806957244873, 1.9043176174163818, 2.0639281272888184, 2.1093432903289795, 2.5165669918060303, 1.7293329238891602, 1.7405900955200195, 1.3971948623657227, 2.3726582527160645, 2.418955087661743, 2.078580379486084, 1.5169636011123657, 1.6036401987075806, 2.3113110065460205, 1.0687755346298218, 2.206247091293335, 2.0562937259674072, 1.4340204000473022, 2.8489420413970947, 2.4085371494293213, 1.3895183801651, 2.9852280616760254, 2.328359842300415, 3.022338628768921, 2.3579189777374268, None, 2.4043853282928467, 3.310737371444702, 3.3779985904693604, 1.862688422203064, 2.771615982055664, 2.4996354579925537, 3.0541746616363525, 2.6573050022125244, 1.8618097305297852, 3.376441240310669, 2.669022560119629, 2.3871452808380127, 2.48999285697937, 2.48622727394104, 2.3766047954559326, 2.741546392440796, None, 2.9346420764923096, 1.6329892873764038, 2.37945818901062, 2.026599884033203, 2.317471742630005, 2.171926736831665, 2.719663143157959, 2.232825517654419, 2.6277148723602295, 2.694892168045044, 1.9879230260849, 1.831404685974121, 2.23919415473938, 3.0927765369415283, 2.0289828777313232, 1.7457855939865112, 3.5378944873809814, 1.3740025758743286, 2.300405979156494, 3.069761037826538, 1.6892529726028442, 1.1927286386489868, 2.508389711380005, 3.0809595584869385, 2.8025081157684326, 2.0144612789154053, 0.7593159079551697, 1.9118810892105103, 1.6075974702835083, 1.536049723625183, 2.1111929416656494, 3.2714788913726807, 2.289193868637085, 1.7649210691452026, 2.410515069961548, 3.969744920730591, 2.03043532371521, 1.985979676246643, 2.3821218013763428, 1.736535906791687, 1.9677648544311523, 2.043104410171509, None, 1.3762418031692505, 2.8419034481048584, 2.725860357284546, 2.115105390548706, 1.475523829460144, 2.329984426498413, 2.9295222759246826, 2.410552740097046, 2.0280849933624268, 3.1015231609344482, None, 2.9401357173919678, 1.582777500152588, 2.2957217693328857, 2.841144323348999, 2.656947374343872, 1.9615745544433594, 2.706698179244995, 1.7151540517807007, 1.6319481134414673, 1.5767439603805542, 2.1699931621551514, 2.7077701091766357, 1.998646855354309, 1.88521409034729, 2.920163869857788, 3.0847575664520264, 3.317228317260742, 2.3130123615264893, 2.2435944080352783, 1.9161107540130615, 1.481632113456726, 2.608253002166748, 2.5899808406829834, 2.4129226207733154, 2.3366081714630127, 1.9658485651016235, 3.4411871433258057, 2.188171148300171, 2.5631158351898193, 3.4560234546661377, 4.034017086029053, 3.0834367275238037, 1.4801123142242432, 3.3636105060577393, 2.6270930767059326, 2.3848252296447754, 2.8083436489105225, 3.5212249755859375, None, 1.4780771732330322, 1.4425731897354126, 1.5191082954406738, 4.175898551940918, 1.7466843128204346, 2.2043919563293457, 2.3868885040283203, 2.467486619949341, 2.706982374191284, None, 2.170905113220215, 2.3755929470062256, 2.557828426361084, 1.4117472171783447, 3.2042598724365234, 2.5720112323760986, 2.3797011375427246, 1.989800214767456, 2.573925495147705, 2.4138152599334717, 2.1650283336639404, 2.511486053466797, 2.768951177597046, 2.419602155685425, 2.9209506511688232, 2.1550753116607666, 2.5436012744903564, 2.7374494075775146, 1.7779921293258667, 1.81680166721344, 2.072009325027466, 3.110823154449463, 2.051192045211792, 2.3116400241851807, 2.2276718616485596, 2.998593330383301, 2.4398553371429443, 2.4678618907928467, 3.023536205291748, 2.4033896923065186, 2.0981576442718506, 1.880090594291687, 2.1916861534118652, 1.0408333539962769, 3.2885138988494873, 3.1972439289093018, 3.1619346141815186, 1.6581807136535645, 2.424471855163574, 2.4401566982269287, 2.5174400806427, 2.43683123588562, 2.679474115371704, 2.4858741760253906, 2.8626062870025635, 2.904435157775879, 3.193873167037964, 2.7799947261810303, 2.71271014213562, 2.601428270339966, 2.9969546794891357, 2.8914687633514404, 1.8278685808181763, 2.0210933685302734, 1.8359568119049072, 2.845134973526001, 2.0016427040100098, 2.19450044631958, 3.1226046085357666, 2.3691937923431396, 2.3325998783111572, 1.8846611976623535, 2.641270875930786, 2.794548749923706, 2.7365787029266357, 2.8191068172454834, 2.555755853652954, 2.646799325942993, None, 2.712843179702759, 2.4444503784179688, 2.51269268989563, 2.1893296241760254, 3.0836684703826904, 2.4395978450775146, 2.9303996562957764, 2.2007970809936523, 2.9859631061553955, 3.548921585083008, None, 2.8485939502716064, 2.3570637702941895, 1.788997769355774, 2.7084672451019287, 2.3971760272979736, 2.5796449184417725, 1.3538899421691895, 2.8778936862945557, 1.8989824056625366, 2.0813543796539307, 1.4538021087646484, 1.7982393503189087, 2.4208524227142334, 2.3413655757904053, 2.58546781539917, 2.04949688911438, 3.0103952884674072, None, 2.164384603500366, 2.769413948059082, 2.7220141887664795, 1.796612024307251, 2.2484095096588135, 2.015486240386963, 2.6478075981140137, 2.6875040531158447, 2.830770492553711, 2.310347318649292, 2.431185483932495, 2.6692569255828857, 2.4901926517486572, 2.4869863986968994, 2.087719202041626, 2.0882084369659424, 2.2698495388031006, 2.2847037315368652, 2.5923571586608887, 2.48980975151062, 2.638763904571533, 2.3164126873016357, 2.166184663772583, 2.4756968021392822, 3.073168992996216, 2.9919657707214355, 2.503772497177124, 2.5363118648529053, 2.0372307300567627, 2.671358585357666, 2.6414794921875, 2.485487937927246, 2.281264305114746, 2.746079206466675, 2.693028688430786, 2.3447487354278564, 2.1895110607147217, None, 2.591355562210083, 2.03454327583313, 2.7076900005340576, 1.7801662683486938, None, 2.375460386276245, 3.113323450088501, 2.6125495433807373, 2.1686785221099854, 1.9046603441238403, 2.152831792831421, 2.135559320449829, 2.1468465328216553, 2.1224992275238037, 2.400761365890503, 2.166041851043701, 1.6322604417800903, 2.6741738319396973, 2.2311737537384033, 2.2227299213409424, 2.434339761734009, 2.326038360595703, 2.0090317726135254, 2.744239091873169, 2.3891255855560303, 2.1915667057037354, 2.1166927814483643, 2.0734498500823975, 2.547435760498047, 2.205061197280884, 2.2372913360595703, 2.4853968620300293, 2.3840789794921875, 1.570180058479309, 2.801050901412964, 2.137969493865967, 2.106255531311035, 2.114617109298706, 2.120500087738037, 2.8898138999938965, 2.369318962097168, 2.5193464756011963, 1.6992820501327515, 2.055027961730957, 2.563127279281616, 2.9839799404144287, 2.6097376346588135, 2.147165536880493, 2.228238344192505, 1.7708717584609985, 2.2224678993225098, 2.124988317489624, 1.8041335344314575, 2.1195623874664307, 2.225114107131958, 2.070518970489502, 2.653069257736206, 1.762148380279541, 1.707647442817688, 1.632675290107727, 1.9502685070037842, 2.15920090675354, 2.6581852436065674, 2.1927826404571533, None, 2.1383450031280518, 2.1648576259613037, None, 1.9762409925460815, None, 2.005207061767578, 3.1852316856384277, 2.2290260791778564, 2.1530349254608154, 1.5294851064682007, None, 2.123053789138794, 2.342629909515381, 2.0933220386505127, 2.603320360183716, 1.5243216753005981, 1.8944405317306519, 2.02435564994812, 2.118971586227417, 1.5622740983963013, 2.4882571697235107, 2.1146440505981445, 1.8889117240905762, 2.761016607284546, 2.275127410888672, 1.7993113994598389, 2.963599443435669, 2.0227954387664795, 2.798454999923706, 2.272639036178589, 2.0888569355010986, 2.432864189147949, 2.4774158000946045, 1.5992127656936646, 2.5647807121276855, 2.8742053508758545, 2.0388877391815186, 2.217184066772461, 1.5622740983963013, 2.0638115406036377, 2.3449277877807617, 2.143902063369751, 2.2395801544189453, 2.228433132171631, 2.639659881591797, 3.158825635910034, 1.783442497253418, 2.0234062671661377, 2.317080497741699, 2.6284451484680176, 2.2152206897735596, 2.4833927154541016, 2.6925880908966064, 1.7775564193725586, 2.9360158443450928, 3.0502474308013916, 1.9036312103271484, 2.50685715675354, 1.5304447412490845, 2.412550210952759, 2.5643699169158936, 2.3151776790618896, 2.534291982650757, 1.310474157333374, 1.9262609481811523, 2.601041078567505, 2.3204917907714844, 2.5263020992279053, 2.206515073776245, 3.6126792430877686, 2.3588597774505615, None, 2.492818593978882, 1.7910972833633423, 1.5665489435195923, 2.0507853031158447, 2.3903310298919678, 2.1887319087982178, 3.3287675380706787, 1.944541096687317, 1.4904760122299194, 2.5614635944366455, 2.63782000541687, 2.534703254699707, 2.0390427112579346, 2.549452304840088, 2.0810739994049072, 2.2765815258026123, 3.2765586376190186, 1.9828956127166748, 2.9490368366241455, 2.5090487003326416, 3.4798905849456787, 2.3122308254241943, 2.2045958042144775, 2.4853873252868652, 2.321082353591919, 2.3099894523620605, None, 1.9092363119125366, 2.3514020442962646, 1.9292881488800049, 3.0814788341522217, 2.4602038860321045, 2.0575101375579834, 2.211104154586792, 2.309723377227783, 2.4564712047576904, 2.7234933376312256, 2.431180477142334, 2.5397651195526123, 1.3791553974151611, 1.9592657089233398, None, 2.5743696689605713, 1.7929167747497559, 2.2069520950317383, 2.210371971130371, None, 2.31705641746521, 3.06710147857666, 2.7485859394073486, 2.8240318298339844, 2.86065673828125, 3.787534475326538, 2.673917531967163, 2.093001127243042, 3.004077672958374, 3.487748146057129, 3.0002715587615967, 2.9401638507843018, 2.5355567932128906, 3.586517333984375, 1.8319534063339233, 3.382044553756714, 3.250676393508911, 1.6811261177062988, 3.376490354537964, 3.1855523586273193, 2.533991813659668, 3.1790711879730225, 2.6122756004333496, 4.112078666687012, 1.666873812675476, 3.0183913707733154, 3.1954360008239746, 2.464104652404785, None, 2.3331992626190186, 2.285372495651245, 2.437974214553833, 2.7577710151672363, 3.5800564289093018, 3.7521636486053467, 2.673835039138794, 2.131438970565796, 2.8038761615753174, 2.656691789627075, 2.3980236053466797, 1.9035634994506836, 2.23909330368042, 2.4448907375335693, 2.451279878616333, 2.9010350704193115, 2.3639156818389893, 2.969817876815796, 3.2384684085845947, 2.775618553161621, 3.339543104171753, 1.8195892572402954, 3.702958583831787, 2.586254835128784, 2.8902952671051025, 1.515220046043396, 2.1804990768432617, 2.2874104976654053, 3.259997606277466, 3.2957470417022705, 2.347918748855591, 1.846213698387146, 2.6035218238830566, 2.4723641872406006, 2.768359899520874, 2.204369068145752, 2.550791025161743, 2.1175754070281982, 3.184162139892578, 1.5931907892227173, 2.78791880607605, None, 1.9986300468444824, 2.5003318786621094, 3.4291422367095947, 2.9127490520477295, 2.978630781173706, 2.3026084899902344, 3.5055689811706543, 3.0797617435455322, 3.0475339889526367, 1.9999083280563354, 2.519273281097412, 3.211902141571045, 3.164705514907837, 1.9745312929153442, None, 2.5313518047332764, 2.2491328716278076, 3.3459794521331787, 3.437180280685425, 2.4597394466400146, 3.0197384357452393, 2.2331035137176514, 3.0449798107147217, 1.9798396825790405, 1.6968892812728882, 2.307715654373169, 1.982599139213562, 2.5330874919891357, 2.3539106845855713, 2.56048583984375, 2.1090705394744873, 2.4117324352264404, 3.1358816623687744, 2.744936227798462, 2.24462628364563, 2.7608821392059326, 1.3870046138763428, 2.9285247325897217, 2.569971799850464, 2.1689653396606445, 2.475419759750366, 2.183626890182495, 2.2934210300445557, 1.96312415599823, 2.9264535903930664, 1.9168365001678467, 2.404770612716675, 3.1198556423187256, 1.7380683422088623, 3.31805157661438, 2.627359390258789, 2.3858015537261963, 2.8150923252105713, 2.4980621337890625, 2.4205422401428223, 2.110595464706421, 3.19575834274292, 1.9882818460464478, 2.5492794513702393, 1.6597015857696533, 3.1765530109405518, None, 1.5366110801696777, 2.6716666221618652, 2.204411745071411, 1.5042147636413574, 2.8940963745117188, 2.174823045730591, 1.752718448638916, 1.7652102708816528, 2.2869131565093994, 2.53105092048645, 1.9763902425765991, 3.4246020317077637, 1.757248044013977, 2.3435111045837402, 1.6322604417800903, 2.434964179992676, 2.708425998687744, 2.83829665184021, 2.729220390319824, 2.9474496841430664, 2.462484121322632, 4.652859687805176, 2.623948574066162, 2.5380859375, 1.9167391061782837, 2.20894718170166, 2.3629515171051025, 3.1735680103302, None, 1.9824445247650146, 2.1277883052825928, 2.477102518081665, 2.5392510890960693, 2.3773958683013916, 2.5720458030700684, 2.654400110244751, 2.724382162094116, 2.3902387619018555, 3.811673164367676, 2.356139898300171, 2.733193874359131, 2.3188223838806152, 2.069767475128174, 2.31783127784729, 2.108172655105591, 2.1285059452056885, 2.2781341075897217, 2.199758768081665, 2.406313180923462, 1.9949712753295898, 2.404489517211914, 2.5008270740509033, 2.5872347354888916, 2.204806327819824, 2.228961229324341, 1.8916743993759155, 2.1069414615631104, 2.157305955886841, 2.381875514984131, 2.5488297939300537, 2.3539044857025146, 2.385592222213745, 2.3515846729278564, 1.4922550916671753, 2.4722232818603516, 2.2812612056732178, 2.1800217628479004, 2.204411745071411, 2.7536213397979736, 2.1505863666534424, 2.1538257598876953, 2.3147192001342773, 2.3821001052856445, 2.1202306747436523, 1.9789899587631226, 2.0668981075286865, 1.9689987897872925, 1.8049405813217163, 2.1057307720184326, 1.5614614486694336, 2.1262450218200684, 2.138371229171753, 1.7618027925491333, 2.217686891555786, 2.009791851043701, 1.5262351036071777, 1.4363573789596558, 1.9250214099884033, 1.4617048501968384, 1.3163560628890991, 1.5363150835037231, 1.9027976989746094, 1.9519788026809692, 2.0072648525238037, 2.052063226699829, None, 1.5866167545318604, 1.8207334280014038, 1.8657037019729614, 1.763156771659851, 1.337638258934021, 1.4446407556533813, 1.8551335334777832, 1.9201842546463013, 2.1889290809631348, 1.5702390670776367, 1.974364995956421, 1.9860254526138306, 1.944398283958435, 1.6654402017593384, 1.889586329460144, 1.6991006135940552, None, 2.093111753463745, 2.1930582523345947, 1.8466352224349976, 1.1218591928482056, None, 1.4774062633514404, 1.850157618522644, 1.6284946203231812, 2.110841751098633, 1.5420218706130981, 1.8175404071807861, 1.98516047000885, 1.6322604417800903, 1.8795355558395386, 1.604375958442688, 2.2141172885894775, 1.9642325639724731, None, 1.3962470293045044, 1.8612847328186035, 1.607923984527588, 2.776597261428833, 2.063523769378662, 1.4040849208831787, 1.7998660802841187, 2.4950287342071533, 1.2181512117385864, 2.3118724822998047, 1.5072733163833618]\n",
      "Trained Model Rewards: [None, None, 1.7989503145217896, None, 1.205755352973938, 1.7636826038360596, 1.7234973907470703, 2.2962896823883057, None, None, None, None, None, 1.6440011262893677, 1.4013606309890747, None, None, None, 1.8603092432022095, None, 2.235137701034546, None, 1.596622347831726, None, 1.2404009103775024, None, None, 1.671353816986084, None, None, 1.9360212087631226, 1.1637099981307983, None, None, 1.8763214349746704, None, None, 1.5728034973144531, 2.0856213569641113, None, 1.5220588445663452, None, None, None, 1.5025399923324585, None, None, None, None, None, None, 1.2943974733352661, 1.7308777570724487, None, None, None, None, None, 1.1475807428359985, None, 2.4092042446136475, None, 1.3376299142837524, 1.6028112173080444, 1.710464596748352, 1.5655797719955444, 1.7615809440612793, 1.5501708984375, 1.301103115081787, 1.2375777959823608, 1.45962393283844, None, None, None, None, None, None, None, None, None, 1.9754894971847534, None, None, 1.1933053731918335, 1.1149593591690063, 1.8638811111450195, None, None, None, 1.30073082447052, None, None, None, None, None, None, None, None, None, None, None, 1.2386244535446167, 1.4315718412399292, None, None, 1.873953938484192, None, None, None, None, None, None, 1.4253369569778442, None, None, None, None, 1.3588320016860962, None, None, None, None, None, None, None, 1.572509765625, None, None, 2.0287230014801025, None, None, 1.027483344078064, 1.7056379318237305, 2.712622880935669, None, None, None, None, 1.4348808526992798, None, None, None, None, 1.1394418478012085, 1.399696707725525, None, 1.5814437866210938, None, None, None, None, None, 1.4147742986679077, None, 1.557937741279602, None, None, None, None, 1.8230925798416138, 2.499277114868164, 1.2845555543899536, None, None, None, 1.255761742591858, None, None, None, None, 2.3380606174468994, None, None, None, None, 1.2277520895004272, None, 1.8458541631698608, 1.1541520357131958, None, None, 1.9016820192337036, 1.4274911880493164, None, None, None, None, 1.5661890506744385, 1.2806373834609985, None, None, 1.384533166885376, None, None, 1.656517744064331, 0.9449492692947388, 1.4242180585861206, 1.790842890739441, None, None, 1.3470619916915894, None, None, 1.8671809434890747, None, None, None, None, 0.9398660063743591, None, 1.2528132200241089, None, 1.3324987888336182, None, None, None, 1.518633484840393, 1.553012728691101, 1.3199342489242554, None, None, None, None, 1.0655709505081177, None, 1.7772116661071777, 1.071401834487915, 1.0176384449005127, None, None, 1.0812625885009766, None, None, 1.2488527297973633, None, None, 1.5607092380523682, None, None, None, 1.328468680381775, 1.327855110168457, 0.9118182063102722, None, None, 1.78835129737854, None, None, None, 1.1000925302505493, None, None, None, 1.3939968347549438, 1.3642024993896484, None, 1.1536974906921387, None, None, 1.1022614240646362, None, None, 1.2055503129959106, 1.1231377124786377, 1.8834435939788818, None, None, None, None, None, 1.1591936349868774, 2.488002061843872, 1.4660612344741821, 1.153433084487915, None, None, 0.9943742156028748, None, None, None, 1.6527906656265259, None, None, None, None, None, None, 1.99612557888031, 1.9500700235366821, None, None, None, None, 1.6776105165481567, None, 1.5440486669540405, 1.800676703453064, 1.6123851537704468, None, None, None, 1.3086601495742798, 1.607418417930603, 1.1212788820266724, 1.773072361946106, None, None, None, 1.739993929862976, None, 1.6657861471176147, 1.2586371898651123, None, None, None, 1.875296711921692, None, None, None, 1.5522388219833374, 1.089640736579895, None, None, None, 1.4335724115371704, None, None, 2.3698489665985107, 1.7456570863723755, 1.8924983739852905, None, None, None, None, None, None, 1.749027132987976, 1.2340837717056274, None, None, 1.4754456281661987, None, None, None, None, None, 2.33842396736145, None, None, None, 2.220496416091919, None, 1.1735279560089111, None, None, None, 1.2211077213287354, None, None, None, None, None, None, 1.4498294591903687, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 1.3964430093765259, 1.6919671297073364, None, None, 1.6706804037094116, 1.8062539100646973, None, 1.905930519104004, 1.779347538948059, None, None, None, 1.8839222192764282, None, 1.2683656215667725, None, None, 1.0472534894943237, 1.1388685703277588, None, 1.5244450569152832, 1.26615571975708, None, 1.4630687236785889, 1.7368558645248413, None, None, 1.8209258317947388, 1.484039068222046, None, None, 1.3929945230484009, None, None, None, None, None, None, None, None, None, 2.0810110569000244, None, 1.393404483795166, None, 1.3742283582687378, 1.618544578552246, 1.7994402647018433, 1.9662282466888428, None, None, None, None, None, None, None, None, None, None, 0.6328645944595337, 1.9552340507507324, 1.2621158361434937, 2.0832111835479736, None, None, 1.56898033618927, None, None, None, None, 2.2462170124053955, None, 1.293718934059143, None, 1.7069605588912964, 1.3864201307296753, None, 1.6120271682739258, None, None, 1.2385495901107788, 1.477892279624939, None, 1.9529215097427368, 1.4907407760620117, None, 1.1708248853683472, None, 1.5986045598983765, None, None, 1.6533902883529663, 1.925238013267517, 1.3647855520248413, None, 1.1348505020141602, None, None, 1.0014688968658447, 1.4439300298690796, 1.466091275215149, None, 1.4433513879776, 1.5906853675842285, 1.4396530389785767, None, 1.5720077753067017, 2.2002084255218506, None, None, 1.6691733598709106, None, 1.4493783712387085, 1.291179895401001, 1.7490582466125488, None, 1.6242527961730957, None, 1.3722360134124756, None, None, 1.7818201780319214, 1.168643593788147, None, None, None, None, 1.265194296836853, None, 1.9217393398284912, None, None, None, None, None, None, None, None, 1.634017825126648, None, None, 1.660546898841858, None, None, 1.734897494316101, None, None, None, None, None, None, None, None, None, 1.9388104677200317, None, None, 1.248406171798706, None, None, None, None, None, None, None, None, None, None, 1.6912096738815308, 1.15579092502594, None, None, None, 1.5411182641983032, None, None, None, None, None, None, None, None, None, None, 1.380925178527832, 2.414372205734253, 1.4620696306228638, None, None, None, None, None, None, None, None, None, None, 2.0856151580810547, None, None, None, None, None, 2.218302011489868, None, None, None, None, None, None, None, None, None, None, None, None, 2.2304537296295166, None, None, None, None, None, None, None, 2.271925687789917, None, None, 1.7864651679992676, None, 1.4207444190979004, 1.6313278675079346, None, 1.5078003406524658, None, None, None, 1.561980128288269, None, 1.7032757997512817, None, None, 2.1236536502838135, 1.479601263999939, None, 1.1204235553741455, 1.741045594215393, None, 1.217520833015442, 2.233637571334839, None, None, None, None, None, 1.3574310541152954, None, 1.736029028892517, None, None, None, 1.6634448766708374, 1.4906257390975952, None, None, None, 1.4278433322906494, None, None, 1.6670674085617065, None, 2.2162814140319824, 1.5698655843734741, None, 1.6436842679977417, None, 1.1985207796096802, None, 1.4958699941635132, None, None, 2.2325947284698486, None, 1.6646335124969482, None, 1.2329360246658325, None, None, 1.1775795221328735, None, None, None, None, None, None, None, None, 1.8837802410125732, 1.6494683027267456, None, 1.3948193788528442, 1.5447866916656494, None, None, None, 1.604437232017517, 1.8720585107803345, None, 2.487759828567505, 1.859547734260559, None, 2.846909761428833, None, None, None, None, 1.6315377950668335, None, 2.4464938640594482, None, 1.5899879932403564, 1.9797629117965698, 1.5161463022232056, None, None, None, None, None, 1.7002681493759155, 1.48508882522583, None, 1.8562673330307007, 1.8528212308883667, None, 1.707261085510254, None, 1.7293633222579956, 2.2192819118499756, None, 1.062427043914795, 1.535658597946167, None, None, None, 1.4428324699401855, None, None, 2.4371421337127686, 1.8787261247634888, None, None, 2.293882131576538, 3.344425916671753, None, None, 1.5626029968261719, None, 1.5806792974472046, 1.8625776767730713, None, 1.8027987480163574, None, 2.2642178535461426, None, None, 1.7157050371170044, 1.6821266412734985, None, None, None, None, None, None, None, None, None, None, None, 1.793070912361145, None, None, 1.76068913936615, None, None, None, None, 1.8144899606704712, None, None, 1.8202929496765137, 1.8549431562423706, None, None, 1.8872605562210083, None, None, 1.7114630937576294, None, None, None, None, None, 1.7474299669265747, 1.997606635093689, None, None, None, None, None, None, 1.4236294031143188, None, 1.674687147140503, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 2.751441478729248, None, 1.67562735080719, 1.6315584182739258, None, None, None, 1.8208059072494507, None, None, None, None, None, None, 1.3812280893325806, 1.6558233499526978, None, None, None, 1.6196259260177612, None, None, 1.898758888244629, 1.8555232286453247, None, 1.6816831827163696, None, 1.567825436592102, 1.4288543462753296, None, None, 1.527952790260315, 1.3117798566818237, 1.5923949480056763, None, None, 1.2240113019943237, 2.3736250400543213, 1.487159252166748, None, 1.422843098640442, None, 1.5864685773849487, None, None, None, 1.6454702615737915, None, 2.5432937145233154, None, 1.7986245155334473, None, 1.6564334630966187, None, None, None, None, None, 1.4979413747787476, None, None, None, 1.9578851461410522, None, None, None, None, None, 1.841309666633606, 1.3862415552139282, None, None, 1.9768563508987427, 1.807266354560852, None, None, None, 1.521072268486023, 1.4428479671478271, 1.678181529045105, None, None, None, None, None, None, 1.995788812637329, 1.931835651397705, None, None, None, None, None, None, 2.1910507678985596, None, None, None, 1.5829533338546753, None, 1.9273767471313477, None, None, 2.051297187805176, None, None, None, 2.1590569019317627, None, 1.8380310535430908, None, None, None, None, None, None, None, None, None, None, 1.3835431337356567, None, None, None, None, None, None, None, 1.6589183807373047, None, None, None, 1.3994958400726318, 1.3038430213928223, 1.317299246788025, None, 1.33433997631073, None, None, 1.7102612257003784, None, None, None, None, None, None, None, None, None, 1.504325270652771, None, None, None, None, 1.0528841018676758, None, None, None, None, None, None, None, None, None, 1.2993980646133423, 1.0844554901123047, 1.2966899871826172, None, 1.2517932653427124, None, 1.3348273038864136, None, None, None, None, None, 0.8842112421989441, None, None, None, 0.7399247288703918, 0.9325389266014099]\n"
     ]
    }
   ],
   "source": [
    "print(\"Old Model Rewards:\", old_model_rewards)\n",
    "print(\"Trained Model Rewards:\", trained_model_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Model Metrics: {'mean': 2.3333320349555677, 'median': 2.3188223838806152, 'std_dev': 0.5335566019872158, 'variance': 0.28468264752414413, 'min': 0.7593159079551697, 'max': 4.652859687805176, '25th_percentile': 1.9992775917053223, '75th_percentile': 2.650754451751709}\n",
      "Trained Model Metrics: {'mean': 1.611536655905684, 'median': 1.584710955619812, 'std_dev': 0.3741507654929876, 'variance': 0.1399887953189886, 'min': 0.6328645944595337, 'max': 3.344425916671753, '25th_percentile': 1.3577812910079956, '75th_percentile': 1.818842202425003}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "# Filter out None values\n",
    "filtered_old_model_rewards = [r for r in old_model_rewards if r is not None]\n",
    "filtered_trained_model_rewards = [r for r in trained_model_rewards if r is not None]\n",
    "\n",
    "# Calculate and print metrics\n",
    "def calculate_metrics(rewards):\n",
    "    metrics = {\n",
    "        \"mean\": np.mean(rewards),\n",
    "        \"median\": np.median(rewards),\n",
    "        \"std_dev\": np.std(rewards),\n",
    "        \"variance\": np.var(rewards),\n",
    "        \"min\": np.min(rewards),\n",
    "        \"max\": np.max(rewards),\n",
    "        \"25th_percentile\": np.percentile(rewards, 25),\n",
    "        \"75th_percentile\": np.percentile(rewards, 75),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "old_model_metrics = calculate_metrics(filtered_old_model_rewards)\n",
    "trained_model_metrics = calculate_metrics(filtered_trained_model_rewards)\n",
    "\n",
    "# print(\"Old Model Rewards:\", old_model_rewards)\n",
    "print(\"Old Model Metrics:\", old_model_metrics)\n",
    "# print(\"Trained Model Rewards:\", trained_model_rewards)\n",
    "print(\"Trained Model Metrics:\", trained_model_metrics)\n",
    "metrics = {\n",
    "    \"old_model\": old_model_metrics,\n",
    "    \"trained_model\": trained_model_metrics,\n",
    "    \"old_model_rewards\": old_model_rewards,\n",
    "    \"trained_model_rewards\": trained_model_rewards,\n",
    "}\n",
    "\n",
    "with open(f\"{base_path}/output/{ts}/metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n_wins 1348 > max_length 1300 --- /work/b0990106x/trl/output/beta05/example_save_1.wav. Increase max window length ms_max_segments!\n",
      "get_reward function end ___________________________\n",
      "temp_reward: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "temp_reward = get_reward(\"/work/b0990106x/trl/output/beta05/example_save_1.wav\")\n",
    "print(\"temp_reward:\", temp_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
