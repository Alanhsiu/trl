{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from UTMOSv2/models/fusion_stage3/fold0_s42_best_model.pth\n",
      "Start testing UTMOSv2 model\n",
      "Test 1: MOS = 3.9296875, Predict Time = 4.5868 seconds\n",
      "Test 2: MOS = 3.1875, Predict Time = 3.7724 seconds\n",
      "Test 3: MOS = 3.8515625, Predict Time = 5.9410 seconds\n",
      "Test 4: MOS = 4.0078125, Predict Time = 5.5588 seconds\n",
      "Test 5: MOS = 4.1953125, Predict Time = 4.5319 seconds\n",
      "Test 6: MOS = 4.05078125, Predict Time = 2.9490 seconds\n",
      "Test 7: MOS = 4.23046875, Predict Time = 3.3775 seconds\n",
      "Test 8: MOS = 4.1171875, Predict Time = 6.5813 seconds\n",
      "Test 9: MOS = 3.86328125, Predict Time = 9.6967 seconds\n",
      "Test 10: MOS = 4.3046875, Predict Time = 7.3988 seconds\n"
     ]
    }
   ],
   "source": [
    "import utmosv2\n",
    "import time\n",
    "utmos_checkpoint_path = \"UTMOSv2/models/fusion_stage3/fold0_s42_best_model.pth\"\n",
    "model = utmosv2.create_model(pretrained=True, checkpoint_path=utmos_checkpoint_path)\n",
    "\n",
    "print(\"Start testing UTMOSv2 model\")\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    mos = model.predict(input_path=\"CLAPS/angry.wav\", verbose=False)\n",
    "    end_time = time.time()\n",
    "    predict_time = end_time - start_time\n",
    "    print(f\"Test {i+1}: MOS = {mos}, Predict Time = {predict_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/utmosv2/_core/create.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from UTMOSv2/models/fusion_stage3/fold0_s42_best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/dpo/lib/python3.10/site-packages/utmosv2/_core/model/_common.py:205: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.177734375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.205078125}], Predict Time = 16.4963 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.736328125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.55078125}], Predict Time = 7.5118 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.27734375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.27734375}], Predict Time = 4.8083 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.03515625}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.421875}], Predict Time = 6.6799 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.21484375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.38671875}], Predict Time = 8.2229 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.966796875}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.025390625}], Predict Time = 6.4538 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.12890625}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.24609375}], Predict Time = 7.2661 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.5703125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 2.912109375}], Predict Time = 6.4732 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.412109375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.013671875}], Predict Time = 6.2637 seconds\n",
      "Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.1953125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.248046875}], Predict Time = 7.2770 seconds\n",
      "Test with a list of audio files: MOS = 3.525390625, Predict Time = 8.0248 seconds\n",
      "Test with a list of audio files: MOS = 3.421875, Predict Time = 8.1509 seconds\n",
      "Test with a list of audio files: MOS = 3.609375, Predict Time = 8.7970 seconds\n",
      "Test with a list of audio files: MOS = 3.552734375, Predict Time = 8.5570 seconds\n",
      "Test with a list of audio files: MOS = 3.583984375, Predict Time = 7.5400 seconds\n",
      "Test with a list of audio files: MOS = 3.17578125, Predict Time = 9.2791 seconds\n",
      "Test with a list of audio files: MOS = 3.3515625, Predict Time = 10.2031 seconds\n",
      "Test with a list of audio files: MOS = 3.228515625, Predict Time = 6.7367 seconds\n",
      "Test with a list of audio files: MOS = 3.353515625, Predict Time = 8.6569 seconds\n",
      "Test with a list of audio files: MOS = 3.8125, Predict Time = 10.1427 seconds\n",
      "Batch inference results:\n",
      "Batch 1: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.177734375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.205078125}], Predict Time = 16.4963 seconds\n",
      "Batch 2: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.736328125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.55078125}], Predict Time = 7.5118 seconds\n",
      "Batch 3: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.27734375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.27734375}], Predict Time = 4.8083 seconds\n",
      "Batch 4: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.03515625}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.421875}], Predict Time = 6.6799 seconds\n",
      "Batch 5: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.21484375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.38671875}], Predict Time = 8.2229 seconds\n",
      "Batch 6: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.966796875}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.025390625}], Predict Time = 6.4538 seconds\n",
      "Batch 7: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.12890625}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.24609375}], Predict Time = 7.2661 seconds\n",
      "Batch 8: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.5703125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 2.912109375}], Predict Time = 6.4732 seconds\n",
      "Batch 9: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 3.412109375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.013671875}], Predict Time = 6.2637 seconds\n",
      "Batch 10: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.1953125}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.248046875}], Predict Time = 7.2770 seconds\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (mos, predict_time) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_results):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: MOS = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predict Time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredict_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage MOS:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_results\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_results))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndividual inference results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (moses, predict_time) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(individual_results):\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "import utmosv2\n",
    "import time\n",
    "utmos_checkpoint_path = \"UTMOSv2/models/fusion_stage3/fold0_s42_best_model.pth\"\n",
    "model = utmosv2.create_model(pretrained=True, checkpoint_path=utmos_checkpoint_path)\n",
    "\n",
    "# Batch inference\n",
    "batch_results = []\n",
    "for _ in range(10):\n",
    "    start_time = time.time()\n",
    "    mos = model.predict(input_dir=\"CLAPS/test\", verbose=False, batch_size=16)\n",
    "    end_time = time.time()\n",
    "    predict_time = end_time - start_time\n",
    "    batch_results.append((mos, predict_time))\n",
    "    print(f\"Batch inference: MOS = {mos}, Predict Time = {predict_time:.4f} seconds\")\n",
    "\n",
    "# Test with a list of audio files\n",
    "wavs = [\"CLAPS/angry.wav\", \"CLAPS/sad.wav\"]\n",
    "individual_results = []\n",
    "for _ in range(10):\n",
    "    start_time = time.time()\n",
    "    moses = []\n",
    "    for wav in wavs:\n",
    "        mos = model.predict(input_path=wav, verbose=False)\n",
    "        moses.append(mos)\n",
    "    end_time = time.time()\n",
    "    predict_time = end_time - start_time\n",
    "    individual_results.append((moses, predict_time))\n",
    "    print(f\"Test with a list of audio files: MOS = {mos}, Predict Time = {predict_time:.4f} seconds\")\n",
    "        \n",
    "# Compare the results\n",
    "print(\"Batch inference results:\")\n",
    "for i, (mos, predict_time) in enumerate(batch_results):\n",
    "    print(f\"Batch {i+1}: MOS = {mos}, Predict Time = {predict_time:.4f} seconds\")\n",
    "\n",
    "print(\"Individual inference results:\")\n",
    "for i, (moses, predict_time) in enumerate(individual_results):\n",
    "    print(f\"Test {i+1}: MOS = {moses}, Predict Time = {predict_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inference results:\n",
      "Batch 1: MOS = 3.19140625, Predict Time = 16.4963 seconds\n",
      "Batch 2: MOS = 3.6435546875, Predict Time = 7.5118 seconds\n",
      "Batch 3: MOS = 3.27734375, Predict Time = 4.8083 seconds\n",
      "Batch 4: MOS = 3.728515625, Predict Time = 6.6799 seconds\n",
      "Batch 5: MOS = 3.80078125, Predict Time = 8.2229 seconds\n",
      "Batch 6: MOS = 3.49609375, Predict Time = 6.4538 seconds\n",
      "Batch 7: MOS = 3.6875, Predict Time = 7.2661 seconds\n",
      "Batch 8: MOS = 3.2412109375, Predict Time = 6.4732 seconds\n",
      "Batch 9: MOS = 3.212890625, Predict Time = 6.2637 seconds\n",
      "Batch 10: MOS = 3.7216796875, Predict Time = 7.2770 seconds\n",
      "Average Time = 7.7453 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Batch inference results:\")\n",
    "total_time = 0\n",
    "for i, (mos, predict_time) in enumerate(batch_results):\n",
    "    # Batch inference: MOS = [{'file_path': 'CLAPS/test/angry.wav', 'predicted_mos': 4.21484375}, {'file_path': 'CLAPS/test/sad.wav', 'predicted_mos': 3.38671875}], Predict Time = 8.2229 seconds\n",
    "    sum_mos = 0\n",
    "    for item in mos:\n",
    "        sum_mos += item[\"predicted_mos\"]\n",
    "    avg_mos = sum_mos / len(mos)\n",
    "    total_time += predict_time\n",
    "    print(f\"Batch {i+1}: MOS = {avg_mos}, Predict Time = {predict_time:.4f} seconds\")\n",
    "print(f\"Average Time = {total_time/10:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual inference results:\n",
      "Test 1: MOS = [3.947265625, 3.525390625], Predict Time = 8.0248 seconds\n",
      "Test 2: MOS = [4.41015625, 3.421875], Predict Time = 8.1509 seconds\n",
      "Test 3: MOS = [4.35546875, 3.609375], Predict Time = 8.7970 seconds\n",
      "Test 4: MOS = [4.0390625, 3.552734375], Predict Time = 8.5570 seconds\n",
      "Test 5: MOS = [4.1171875, 3.583984375], Predict Time = 7.5400 seconds\n",
      "Test 6: MOS = [3.224609375, 3.17578125], Predict Time = 9.2791 seconds\n",
      "Test 7: MOS = [4.01953125, 3.3515625], Predict Time = 10.2031 seconds\n",
      "Test 8: MOS = [3.48046875, 3.228515625], Predict Time = 6.7367 seconds\n",
      "Test 9: MOS = [4.08203125, 3.353515625], Predict Time = 8.6569 seconds\n",
      "Test 10: MOS = [3.37109375, 3.8125], Predict Time = 10.1427 seconds\n",
      "Average Time = 8.608804368972779\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "print(\"Individual inference results:\")\n",
    "for i, (moses, predict_time) in enumerate(individual_results):\n",
    "    total_time += predict_time\n",
    "    print(f\"Test {i+1}: MOS = {moses}, Predict Time = {predict_time:.4f} seconds\")\n",
    "print(f\"Average Time = {total_time / len(individual_results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
