{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\")\n",
    "import importlib\n",
    "import vc\n",
    "importlib.reload(vc)\n",
    "import torch\n",
    "from vc.trainer_encodec_vc_inference import pack_inputs_v2, get_ar_prediction_get_audio, get_ar_prediction_audio_batch\n",
    "from types import SimpleNamespace\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from trl import DPOTrainer, DPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from dpo_eval import get_reward_claps ,eval_dpo_claps_batch, convert_array_to_tensor_format\n",
    "from dpo_eval import get_reward_mos, process_and_get_mos_reward, eval_dpo_mos\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import argparse\n",
    "import soundfile as sf\n",
    "import math\n",
    "\n",
    "sys.path.append('/work/b0990106x/trl/CLAPS')\n",
    "from CLAPS.inference import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate_output_batch(\n",
    "        model,\n",
    "        ar_model, \n",
    "        nar_model, \n",
    "        ar_tokenizer, \n",
    "        nar_tokenizer, \n",
    "        clap_model,\n",
    "        accelerator,\n",
    "        src_encodec: list, \n",
    "        instruction: list, \n",
    "        args_predict: SimpleNamespace, \n",
    "        episode_counter: int = 0, \n",
    "        base_path: str = \"/work/b0990106x/trl\", \n",
    "        temperature: float = 1.0\n",
    ") -> tuple[float, str]:\n",
    "    '''\n",
    "    Generates output from AR model, synthesize the audio, and evaluate the audio using NISQA.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            reward(float): The reward of the audio.\n",
    "            tokenized_decode_ar(str): The tokenized output of the AR model - first layer.\n",
    "    '''\n",
    "    # Generate predictions using the AR model\n",
    "    audio_list, decode_ar_list = get_ar_prediction_audio_batch(\n",
    "        args_predict, model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter, temperature=temperature\n",
    "    )\n",
    "    # extract the instruction from the list \n",
    "    reward_list,tokenized_decode_ar_list = [], []\n",
    "\n",
    "    for i, audio in enumerate(audio_list): \n",
    "        # audio ---> tensor([])\n",
    "        if audio is not None:\n",
    "            # tensor_audio = convert_array_to_tensor_format(audio)\n",
    "            # if tensor_audio[0].shape[0]==1:\n",
    "            #     tensor_audio[0] = tensor_audio[0].squeeze(0)\n",
    "            # print(tensor_audio)\n",
    "            # reward_claps = get_reward_claps(clap_model=clap_model, accelerator=accelerator, prompts = instruction[i], wavs = tensor_audio)\n",
    "            # reward_mos = process_and_get_mos_reward(model=model, nar_model=nar_model, ar_tokenizer=ar_tokenizer, nar_tokenizer=nar_tokenizer, src_encodec=src_encodec[i], instruction=instruction[i], args_predict=args_predict, episode_counter=episode_counter, base_path=base_path)\n",
    "            output_path_ckpt = args_predict.output_path.replace(\".wav\", f\"_generate_{episode_counter}_item_{i}.wav\")\n",
    "            sf.write(output_path_ckpt, np.ravel(audio), samplerate=24000)\n",
    "            reward_mos = get_reward_mos(output_path=output_path_ckpt, base_path=base_path)\n",
    "            reward = reward_mos / 5\n",
    "        else: \n",
    "            reward = 0\n",
    "        reward_list.append(reward)\n",
    "    \n",
    "    for decode_ar in decode_ar_list:\n",
    "        list_decode_ar = decode_ar.flatten().tolist()   \n",
    "        filtered_decode_ar_list = list_decode_ar[2:-1]\n",
    "        decode_ar_tokens = ar_tokenizer.convert_ids_to_tokens(filtered_decode_ar_list)\n",
    "        tokenized_decode_ar = ar_tokenizer.convert_tokens_to_string(decode_ar_tokens)\n",
    "        tokenized_decode_ar_list.append(tokenized_decode_ar)\n",
    "        \n",
    "    return reward_list, tokenized_decode_ar_list\n",
    "\n",
    "def extract_data_from_json(file_path: str) -> Tuple[List[list], List[str], List[list]]:\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file and extracts 'src_encodec', 'instruction', and 'tgt_encodec'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            all_src_encodec (List[list]): A list containing the 'src_encodec' data from each item in the JSON file.\n",
    "            all_instruction (List[str]): A list containing the 'instruction' data from each item in the JSON file.\n",
    "            all_tgt_encodec (List[list]): A list containing the 'tgt_encodec' data from each item in the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    all_src_encodec = [item[\"src_encodec\"] for item in data]\n",
    "    all_instruction = [item[\"instruction\"] for item in data]\n",
    "\n",
    "    return all_src_encodec, all_instruction\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        model_ref,\n",
    "        ar_tokenizer,\n",
    "        train_dataset: Dataset,\n",
    "        val_dataset: Dataset,\n",
    "        model_output_dir: str,\n",
    "        beta: float,\n",
    "        resume_from_checkpoint: bool,\n",
    "        model_checkpoint: str,\n",
    "        learning_rate: float = 5e-07,\n",
    "        num_train_epochs: int = 200,\n",
    "        max_length: int = 1024*9,\n",
    "        max_prompt_length: int = 1024*9,\n",
    "        max_target_length: int = 1024*9,\n",
    "        per_device_train_batch_size: int = 1,\n",
    "        gradient_accumulation_steps: int = 1,\n",
    "        seed: int = 42\n",
    ") -> None:\n",
    "    '''\n",
    "    Train the DPO model and save the model.\n",
    "\n",
    "    Args:\n",
    "        model(AutoModelForSeq2SeqLMWithValueHead): The DPO model.\n",
    "        model_ref(AutoModelForCausalLM): The reference model.\n",
    "        ar_tokenizer(AutoTokenizer): The tokenizer.\n",
    "        train_dataset(Dataset): The training dataset.\n",
    "        val_dataset(Dataset): The validation dataset.\n",
    "        model_output_dir(str): The output directory for the model.\n",
    "        beta(float): The beta value.\n",
    "        resume_from_checkpoint(bool): Whether to resume from a checkpoint.\n",
    "        model_checkpoint(str): The path to the model\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    training_args = DPOConfig(\n",
    "        beta = beta,\n",
    "        output_dir = model_output_dir,\n",
    "        resume_from_checkpoint = model_checkpoint if resume_from_checkpoint else None,\n",
    "        seed = seed,\n",
    "        per_device_train_batch_size = per_device_train_batch_size,\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        learning_rate = learning_rate,\n",
    "        max_length = max_length,\n",
    "        max_prompt_length = max_prompt_length,\n",
    "        max_target_length = max_target_length,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps = 5000,\n",
    "        logging_dir = f\"{model_output_dir}/logs\"\n",
    "    )\n",
    "    \n",
    "    trainer = DPOTrainer(\n",
    "        model=model,\n",
    "        ref_model=model_ref,\n",
    "        args=training_args,\n",
    "        tokenizer=ar_tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    # trainer.save_model(f\"{model_output_dir}/dpo_model\")\n",
    "    model.config.to_json_file(f\"{model_output_dir}/config.json\")\n",
    "    # ar_tokenizer.save_pretrained(f\"{model_output_dir}/dpo_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_data_batch(sample_size: int, \n",
    "                       model,\n",
    "                        ar_model, \n",
    "                        nar_model, \n",
    "                        ar_tokenizer, \n",
    "                        nar_tokenizer, \n",
    "                        clap_model,\n",
    "                        accelerator,\n",
    "                        selected_src_encodec: List[list], \n",
    "                        selected_instruction: List[str],\n",
    "                        args_predict: SimpleNamespace, \n",
    "                        base_path: str = \"/work/b0990106x/trl\", \n",
    "                        temperature: float = 1.0, \n",
    "                        iteration: int = 0\n",
    ") -> Tuple[List[str], List[str], List[str], List[float], List[float], List[float]]:\n",
    "    # If sample size is 1, we cannot choose the best and worst outputs\n",
    "    if sample_size < 2:\n",
    "        raise ValueError(\"Parameter 'sample_size' must be greater than 1.\")\n",
    "\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = [], [], [], [], [], []\n",
    "\n",
    "    disable_tqdm = not os.isatty(1)\n",
    "    for i in tqdm(range(len(selected_src_encodec)), desc=\"Processing Data\", disable=disable_tqdm):\n",
    "        rewards, tokenized_outputs = [], []\n",
    "        size_of_packed_input = (\n",
    "            len(selected_src_encodec[i][0]) +\n",
    "            len(ar_tokenizer(selected_instruction[i])[\"input_ids\"][1:-1]) +\n",
    "            3\n",
    "        )\n",
    "        if 4 < size_of_packed_input <= 1024:\n",
    "            selected_src_encodec_list = [selected_src_encodec[i]]*sample_size\n",
    "            selected_instruction_list = [selected_instruction[i]]*sample_size\n",
    "            rewards, tokenized_outputs = generate_output_batch(\n",
    "                model=model,\n",
    "                ar_model=ar_model, \n",
    "                nar_model=nar_model, \n",
    "                ar_tokenizer=ar_tokenizer, \n",
    "                nar_tokenizer=nar_tokenizer,\n",
    "                src_encodec = selected_src_encodec_list,\n",
    "                instruction=selected_instruction_list, \n",
    "                clap_model=clap_model,\n",
    "                accelerator=accelerator,\n",
    "                args_predict=args_predict,\n",
    "                episode_counter=f\"data_{i}\",\n",
    "                base_path=base_path, \n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "        valid_rewards = [r for r in rewards if r is not None]\n",
    "        valid_outputs = [tokenized_outputs[j] for j in range(len(rewards)) if rewards[j] is not None]\n",
    "\n",
    "        if len(valid_rewards) >= 2:\n",
    "            # max_reward_index = np.argmax(valid_rewards)\n",
    "            # min_reward_index = np.argmin(valid_rewards)\n",
    "            \n",
    "            # choose first 20% of the data and last 20% of the data \n",
    "            twenty_percent_num = math.ceil(len(valid_rewards)/2 * 0.2)\n",
    "            max_reward_indexs = np.argsort(valid_rewards)[-twenty_percent_num:]\n",
    "            min_reward_indexs = np.argsort(valid_rewards)[:twenty_percent_num]\n",
    "            \n",
    "            average_reward = np.mean(valid_rewards)\n",
    "            # chosen_output = valid_outputs[max_reward_index]\n",
    "            # rejected_output = valid_outputs[min_reward_index]\n",
    "            \n",
    "            chosen_outputs = [valid_outputs[j] for j in max_reward_indexs]\n",
    "            rejected_outputs = [valid_outputs[j] for j in min_reward_indexs]\n",
    "\n",
    "            obs_input = pack_inputs_v2(ar_tokenizer, selected_src_encodec[i], selected_instruction[i])\n",
    "            tokenize_input = ar_tokenizer.convert_ids_to_tokens(obs_input)\n",
    "            tokenize_input_str = ar_tokenizer.convert_tokens_to_string(tokenize_input)\n",
    "            # prompts.append(tokenize_input_str)\n",
    "            prompts.extend([tokenize_input_str] * len(chosen_outputs))\n",
    "\n",
    "\n",
    "            # chosen.append(chosen_output)\n",
    "            # chosen_rewards.append(valid_rewards[max_reward_index])\n",
    "            # rejected.append(rejected_output)\n",
    "            # rejected_rewards.append(valid_rewards[min_reward_index])\n",
    "            average_rewards.append(average_reward)\n",
    "            \n",
    "            chosen.extend(chosen_outputs)\n",
    "            chosen_rewards.extend([valid_rewards[j] for j in max_reward_indexs])\n",
    "            rejected.extend(rejected_outputs)\n",
    "            rejected_rewards.extend([valid_rewards[j] for j in min_reward_indexs])\n",
    "        else:\n",
    "            print(f\"Not enough valid rewards for data index {i}\")\n",
    "\n",
    "    # If there is only one data, we need to double the data because we need it for training set and validation set\n",
    "    if len(selected_src_encodec) == 1:\n",
    "        chosen *= 2\n",
    "        rejected *= 2\n",
    "        prompts *= 2\n",
    "        chosen_rewards *= 2\n",
    "        rejected_rewards *= 2\n",
    "        average_rewards *= 2    \n",
    "    \n",
    "    return chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards\n",
    "\n",
    "def generate_data(model,\n",
    "                  ar_model, \n",
    "                  ar_tokenizer, \n",
    "                  nar_model, \n",
    "                  nar_tokenizer, \n",
    "                  clap_model,\n",
    "                  accelerator,\n",
    "                  selected_src_encodec: List[list], \n",
    "                  selected_instruction: List[str],\n",
    "                  args_predict: SimpleNamespace, \n",
    "                  sample_size: int, \n",
    "                  iteration: int, \n",
    "                  agent_output_dir: str, \n",
    "                  base_path: str = \"/work/b0990106x/trl\", \n",
    "                  temperature: float = 1.0\n",
    ") -> Tuple[dict, List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Generates data for the dataset and saves info to a JSON file.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            data_for_dataset (dict): A dictionary containing the data for the dataset.\n",
    "            chosen_rewards (List[float]): A list of rewards for the chosen outputs.\n",
    "            rejected_rewards (List[float]): A list of rewards for the rejected outputs.\n",
    "    \"\"\"\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = process_data_batch(\n",
    "        sample_size=sample_size,\n",
    "        model=model,\n",
    "        ar_model=ar_model,\n",
    "        nar_model=nar_model,\n",
    "        ar_tokenizer=ar_tokenizer,\n",
    "        nar_tokenizer=nar_tokenizer,\n",
    "        selected_src_encodec=selected_src_encodec,\n",
    "        selected_instruction=selected_instruction,\n",
    "        args_predict=args_predict,\n",
    "        base_path=base_path,\n",
    "        temperature=temperature,\n",
    "        iteration = iteration,\n",
    "        clap_model=clap_model,\n",
    "        accelerator=accelerator\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompts,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "        \"chosen_rewards\": chosen_rewards,\n",
    "        \"rejected_rewards\": rejected_rewards,\n",
    "        \"average_rewards\": average_rewards\n",
    "    }\n",
    "\n",
    "    with open(f\"{agent_output_dir}/data_iter_{iteration}.json\", \"w\") as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "    data_for_dataset = {key: data[key] for key in [\"prompt\", \"chosen\", \"rejected\"]}\n",
    "\n",
    "    return data_for_dataset, chosen_rewards, rejected_rewards\n",
    "\n",
    "def train_iteration(model, \n",
    "                    model_checkpoint,\n",
    "                    iteration, \n",
    "                    data_size, \n",
    "                    sample_size, \n",
    "                    ar_model, \n",
    "                    ar_tokenizer,\n",
    "                    nar_model, \n",
    "                    nar_tokenizer,\n",
    "                    all_src_encodec, \n",
    "                    all_instruction, \n",
    "                    args_predict, \n",
    "                    agent_output_dir,\n",
    "                    model_output_dir_base, \n",
    "                    clap_model,\n",
    "                    accelerator,\n",
    "                    beta = 0.1, \n",
    "                    temperature = 1.0,\n",
    "                    base_path=\"/work/b0990106x/trl\",\n",
    "                    resume_from_checkpoint = False,\n",
    "                    learning_rate = 5e-07,\n",
    "                    num_train_epochs = 100,\n",
    "                    max_length = 1024*9,\n",
    "                    max_prompt_length = 1024*9,\n",
    "                    max_target_length = 1024*9,\n",
    "                    per_device_train_batch_size = 1,\n",
    "                    gradient_accumulation_steps = 1,\n",
    "                    seed = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes one training iteration: generates data, trains the model, and saves the output.\n",
    "    \"\"\"\n",
    "    # print(f\"Iteration {iteration}\")\n",
    "\n",
    "    # ar_model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "    # ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "    # ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "    # nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "    # nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "\n",
    "    selected_src_encodec = all_src_encodec[:data_size]\n",
    "    selected_instruction = all_instruction[:data_size]\n",
    "\n",
    "    data_for_dataset, chosen_rewards, rejected_rewards = generate_data(model=model, \n",
    "                                                                    ar_model=ar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_model=nar_model,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    selected_src_encodec=selected_src_encodec,\n",
    "                                                                    selected_instruction=selected_instruction,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    sample_size=sample_size,\n",
    "                                                                    iteration=iteration,\n",
    "                                                                    agent_output_dir=agent_output_dir,\n",
    "                                                                    base_path=base_path,\n",
    "                                                                    temperature=temperature,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator)\n",
    "\n",
    "    dataset = Dataset.from_dict(data_for_dataset)\n",
    "    dataset_dict = dataset.train_test_split(test_size=0.1, shuffle=True, seed=seed)\n",
    "    train_dataset = dataset_dict[\"train\"]\n",
    "    val_dataset = dataset_dict[\"test\"]\n",
    "    \n",
    "    # print train_dataset and val_dataset\n",
    "    if iteration < 2:\n",
    "        print(\"train_dataset\", train_dataset.to_dict())\n",
    "        print(\"val_dataset\", val_dataset.to_dict())\n",
    "\n",
    "    model_output_dir = f\"{model_output_dir_base}/iter_{iteration}\"\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    # model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "    model_ref = create_reference_model(model)\n",
    "    \n",
    "    train_model(model=model,\n",
    "                model_ref=model_ref,\n",
    "                ar_tokenizer=ar_tokenizer,\n",
    "                train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                model_output_dir=model_output_dir,\n",
    "                beta=beta,\n",
    "                resume_from_checkpoint=resume_from_checkpoint,\n",
    "                model_checkpoint=model_checkpoint,\n",
    "                learning_rate = learning_rate,\n",
    "                num_train_epochs = num_train_epochs,\n",
    "                max_length = max_length,\n",
    "                max_prompt_length = max_prompt_length,\n",
    "                max_target_length = max_target_length,\n",
    "                per_device_train_batch_size = per_device_train_batch_size,\n",
    "                gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "                seed = seed)\n",
    "\n",
    "    return f\"{model_output_dir}/dpo_model\", chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 1022-1846\n",
      "length of all_src_encodec: 9254\n",
      "length of all_instruction: 9254\n"
     ]
    }
   ],
   "source": [
    "# Load all data\n",
    "selected_src_encodec, selected_instruction = extract_data_from_json('dpo_data/src_encodec.json')\n",
    "\n",
    "# Define paths and device\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define timestamp\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# Define paths\n",
    "model_output_dir = os.path.join(base_path, \"model_output\", ts) # Location where the model are saved\n",
    "agent_output_dir = os.path.join(base_path, \"output\", ts) # Path of saving the generated audio for reward model to evaluate\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(agent_output_dir, exist_ok=True)\n",
    "\n",
    "seed = 42 # Training: seed\n",
    "\n",
    "# Define arguments \n",
    "args_predict = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=seed, device=device)\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "# Models and Iterations\n",
    "model_checkpoint = ar_checkpoint # Prepare: set the initial model checkpoint\n",
    "sample_size = 80 # Prepare Dataset: generate how many outputs to select max and min for chosen and rejected (original: 10)\n",
    "num_iterations = 1000  # Training: train how many iterations (original: 100)\n",
    "train_selected_indices = [8]\n",
    "# train_selected_indices = [9]\n",
    "# train_selected_indices = random.sample(range(len(selected_src_encodec)), 5) # Training: train on selected data indicies from all_src_encodec\n",
    " # Training: train on selected data indicies from all_src_encodec\n",
    "data_size_per_iteration = len(train_selected_indices) # Training: each iteration will train how many data\n",
    "\n",
    "# Define Training Configuration\n",
    "beta = 0.1 # Training: beta value for DPO\n",
    "learning_rate = 5e-07 # Training: learning rate (original: 5e-07)\n",
    "num_train_epochs = 1 # Training: number of training epochs (original: 3)\n",
    "max_length = 1024*9 # Training: max length of the model\n",
    "max_prompt_length = 1024*9 # Training: max length of the prompt\n",
    "max_target_length = 1024*9 # Training: max length of the target\n",
    "per_device_train_batch_size = 8 # Training: batch size (original: 1)\n",
    "gradient_accumulation_steps = 1 # Training: gradient accumulation steps\n",
    "\n",
    "# Evaluation Configuration\n",
    "eval_train = True # Evaluation: evaluate on training data or not\n",
    "eval_test = False # Evaluation: evaluate on testing data or not\n",
    "eval_train_indices = train_selected_indices # Evaluation: evaluate on training data indicies from all_src_encodec\n",
    "eval_test_indices = random.sample(range(len(selected_src_encodec)), 5) # Evaluation: evaluate on testing data indicies from all_src_encodec\n",
    "eval_train_data_len = 1000 # Evaluation: evaluate how many training data\n",
    "eval_test_data_len = len(eval_test_indices) # Evaluation: evaluate how many testing data\n",
    "num_eval = 1 # Evaluation: evaluate how many times per data (original: 10)\n",
    "eval_frequency = 1 # Evaluation: evaluate every how many iterations\n",
    "# Define temperature\n",
    "# eval_selected_indices = random.sample(range(len(all_src_encodec)), eval_data_len) # Evaluation: select 10 data for evaluation\n",
    "print(f\"length of all_src_encodec: {len(selected_src_encodec)}\") # ~ 9000 data\n",
    "print(f\"length of all_instruction: {len(selected_instruction)}\") # ~ 9000 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/s3prl/upstream/wavlm/expert.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/work/b0990106x/trl/CLAPS/inference.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /work/b0990106x/trl/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "sr = 24000\n",
    "text_enc_name = \"google/flan-t5-large\"\n",
    "text_enc_dim = 1024\n",
    "text_blstm_dim = 256\n",
    "speech_enc_name = \"wavlm\"\n",
    "speech_enc_dim = 768\n",
    "speech_blstm_dim = 256\n",
    "rep_dim = 512\n",
    "sub_dim = 0\n",
    "n_sub = 1\n",
    "ckpt_pth=f'{base_path}/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000'\n",
    "project_dir = \"cp_claps\"\n",
    "\n",
    "a = argparse.Namespace(\n",
    "        sr=sr,\n",
    "        text_enc_name=text_enc_name,\n",
    "        text_enc_dim=text_enc_dim,\n",
    "        text_blstm_dim=text_blstm_dim,\n",
    "        speech_enc_name=speech_enc_name,\n",
    "        speech_enc_dim=speech_enc_dim,\n",
    "        speech_blstm_dim=speech_blstm_dim,\n",
    "        rep_dim=rep_dim,\n",
    "        sub_dim=sub_dim,\n",
    "        n_sub=n_sub,  # Number of subspaces, if any\n",
    "        ckpt_pth=ckpt_pth,  # Set your checkpoint path\n",
    "        project_dir=project_dir  # Example project directory\n",
    "    )\n",
    "\n",
    "clap_model, accelerator = load_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iterations: 1000\n",
      "data_size_per_iteration: 1\n",
      "sample_size: 80\n",
      "beta: 0.1\n",
      "learning_rate: 5e-07\n",
      "num_train_epochs: 1\n",
      "ar_checkpoint: lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\n",
      "nar_checkpoint: lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\n",
      "args_predict: namespace(output_path='/work/b0990106x/trl/output/1022-1846/example.wav', seed=42, device='cuda')\n",
      "model_output_dir: /work/b0990106x/trl/model_output/1022-1846\n",
      "agent_output_dir: /work/b0990106x/trl/output/1022-1846\n",
      "base_path: /work/b0990106x/trl\n",
      "device: cuda\n",
      "eval_train_data_len: 1000\n",
      "eval_test_data_len: 5\n",
      "eval_train_indices: [8]\n",
      "eval_test_indices: [7406, 6360, 4762, 786, 6428]\n",
      "eval_train: True\n",
      "eval_test: False\n",
      "num_eval: 1\n",
      "training idx 8 : Significantly dampen the vibrations of the high notes.\n",
      "evaluation idx 8 : Significantly dampen the vibrations of the high notes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_iterations: {num_iterations}\")\n",
    "print(f\"data_size_per_iteration: {data_size_per_iteration}\")\n",
    "print(f\"sample_size: {sample_size}\")\n",
    "print(f\"beta: {beta}\")\n",
    "print(f\"learning_rate: {learning_rate}\")\n",
    "print(f\"num_train_epochs: {num_train_epochs}\")\n",
    "print(f\"ar_checkpoint: {ar_checkpoint}\")\n",
    "print(f\"nar_checkpoint: {nar_checkpoint}\")\n",
    "print(f\"args_predict: {args_predict}\")\n",
    "print(f\"model_output_dir: {model_output_dir}\")\n",
    "print(f\"agent_output_dir: {agent_output_dir}\")\n",
    "print(f\"base_path: {base_path}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"eval_train_data_len: {eval_train_data_len}\")\n",
    "print(f\"eval_test_data_len: {eval_test_data_len}\")\n",
    "print(f\"eval_train_indices: {eval_train_indices}\")\n",
    "print(f\"eval_test_indices: {eval_test_indices}\")\n",
    "print(f\"eval_train: {eval_train}\")\n",
    "print(f\"eval_test: {eval_test}\")\n",
    "print(f\"num_eval: {num_eval}\")\n",
    "\n",
    "# print training data\n",
    "for i in train_selected_indices:\n",
    "    print('training idx', i,':', selected_instruction[i])\n",
    "    \n",
    "# print evaluation data\n",
    "if eval_test:\n",
    "    for i in eval_test_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "if eval_train:\n",
    "    for i in eval_train_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/work/b0990106x/trl/trl/models/modeling_base.py:328: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = loading_func(filename if not use_safe else safe_filename, **load_kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "# ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: /work/b0990106x/trl/model_output/1022-1846/log_training.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "log_path = f'{model_output_dir}/log_training.log'\n",
    "print(f\"Logging to: {log_path}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=log_path, \n",
    "    filemode='a', \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    f\"Parameters:\\n\"\n",
    "    f\"Prepare Data: sample_size: {sample_size}\\n\"\n",
    "    f\"Training: num_iterations: {num_iterations}\\n\"\n",
    "    f\"Training: data_size_per_iteration: {data_size_per_iteration}\\n\"\n",
    "    f\"Training: train_selected_indices: {train_selected_indices}\\n\"\n",
    "    f\"Training: beta: {beta}\\n\"\n",
    "    f\"Training: learning_rate: {learning_rate}\\n\"\n",
    "    f\"Training: num_train_epochs: {num_train_epochs}\\n\"\n",
    "    f\"Training: max_length: {max_length}\\n\"\n",
    "    f\"Training: max_prompt_length: {max_prompt_length}\\n\"\n",
    "    f\"Training: max_target_length: {max_target_length}\\n\"\n",
    "    f\"Training: per_device_train_batch_size: {per_device_train_batch_size}\\n\"\n",
    "    f\"Training: gradient_accumulation_steps: {gradient_accumulation_steps}\\n\"\n",
    "    f\"Training: seed: {seed}\\n\"\n",
    "    f\"Training: ar_checkpoint: {ar_checkpoint}\\n\"\n",
    "    f\"Training: nar_checkpoint: {nar_checkpoint}\\n\"\n",
    "    f\"Training: args_predict: {args_predict}\\n\"\n",
    "    f\"Training: model_output_dir: {model_output_dir}\\n\"\n",
    "    f\"Training: agent_output_dir: {agent_output_dir}\\n\"\n",
    "    f\"Training: base_path: {base_path}\\n\"\n",
    "    f\"Training: device: {device}\\n\"\n",
    "    f\"Evaluation: eval_train_data_len: {eval_train_data_len}\\n\"\n",
    "    f\"Evaluation: eval_test_data_len: {eval_test_data_len}\\n\"\n",
    "    f\"Evaluation: eval_train_indices: {eval_train_indices}\\n\"\n",
    "    f\"Evaluation: eval_test_indices: {eval_test_indices}\\n\"\n",
    "    f\"Evaluation: eval_train: {eval_train}\\n\"\n",
    "    f\"Evaluation: eval_test: {eval_test}\\n\"\n",
    "    f\"Evaluation: num_eval: {num_eval}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-1846/example_save_eval_-1_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:943: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.dev)\n",
      "/home/b0990106x/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/librosa/feature/spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "total_start_time = time.time()\n",
    "if eval_train:\n",
    "    # eval dpo claps\n",
    "    # original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "    #                                                                 ar_tokenizer=ar_tokenizer,\n",
    "    #                                                                 nar_tokenizer=nar_tokenizer,\n",
    "    #                                                                 trained_model=model,\n",
    "    #                                                                 args_predict=args_predict,\n",
    "    #                                                                 all_src_encodec=selected_src_encodec,\n",
    "    #                                                                 all_instruction=selected_instruction,\n",
    "    #                                                                 iteration = -1,\n",
    "    #                                                                 num_evaluations = num_eval,\n",
    "    #                                                                 eval_data_len=eval_train_data_len,\n",
    "    #                                                                 selected_indices=eval_train_indices,\n",
    "    #                                                                 device=device,\n",
    "    #                                                                 clap_model=clap_model,\n",
    "    #                                                                 accelerator=accelerator\n",
    "    #                                                                 )\n",
    "    # logging.info(f\"Original Model Train Set Evaluation: \")\n",
    "    # logging.info(f\"Original model metrics on training set: {original_model_metrics}\")\n",
    "    # logging.info(f\"Original model rewards on training set: {original_model_rewards}\")\n",
    "    \n",
    "    # eval dpo mos\n",
    "    original_model_metrics_mos, original_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_train_data_len,\n",
    "                                                                    selected_indices=eval_train_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    )\n",
    "    logging.info(f\"Original model metrics on training set: {original_model_metrics_mos}\")\n",
    "    logging.info(f\"Original model rewards on training set: {original_model_rewards_mos}\")\n",
    "    \n",
    "    # reward_list = []\n",
    "    # for rewards in original_model_rewards:\n",
    "    #     filter_rewards = [r for r in rewards if r is not None]\n",
    "    #     if len(filter_rewards) == 0:\n",
    "    #         reward_list.append(None)\n",
    "    #     else:\n",
    "    #         reward_list.append(np.mean(filter_rewards))\n",
    "    # logging.info(f\"Original model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "    reward_list_mos = []\n",
    "    for rewards in original_model_rewards_mos:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list_mos.append(None)\n",
    "        else:\n",
    "            reward_list_mos.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model MOS score list on training set: {reward_list_mos}\")\n",
    "    \n",
    "    # filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    # if len(filter_reward_list) != 0:\n",
    "    #     logging.info(f\"Original model average rewards on training set: {np.mean(filter_reward_list)}\")\n",
    "    # else: \n",
    "    #     logging.info(f\"Original model average rewards on training set: None\")\n",
    "        \n",
    "    filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "    if len(filter_reward_list_mos) != 0:\n",
    "        logging.info(f\"Original model average MOS on training set: {np.mean(filter_reward_list_mos)}\")\n",
    "    else:\n",
    "        logging.info(f\"Original model average MOS on training set: None\")\n",
    "        \n",
    "    # weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "    weighted_reward = np.mean(filter_reward_list_mos)/5\n",
    "    logging.info(f\"Original model weighted average rewards on training set: {weighted_reward}\")\n",
    "    \n",
    "if eval_test:\n",
    "    original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_test_data_len,\n",
    "                                                                    selected_indices=eval_test_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator\n",
    "                                                                    )\n",
    "    logging.info(f\"Original Model Test Set Evaluation: \")\n",
    "    logging.info(f\"Original model metrics on testing set: {original_model_metrics}\")\n",
    "    logging.info(f\"Original model rewards on testing set: {original_model_rewards}\")\n",
    "    reward_list = []\n",
    "    for rewards in original_model_rewards:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list.append(None)\n",
    "        else:\n",
    "            reward_list.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model reward list on testing set: {reward_list}\")\n",
    "    filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    if len(filter_reward_list) != 0:\n",
    "        logging.info(f\"Original model average rewards on testing set: {np.mean(filter_reward_list)}\")\n",
    "    else: \n",
    "        logging.info(f\"Original model average rewards on testing set: None\")\n",
    "    \n",
    "# If train_selected_indices is not empty, we will use the selected indices for training\n",
    "if train_selected_indices:\n",
    "    batch_src_encodec = [selected_src_encodec[i] for i in train_selected_indices]\n",
    "    batch_instruction = [selected_instruction[i] for i in train_selected_indices]\n",
    "    logging.info(f\"Processing data from selected indices: {train_selected_indices}\")\n",
    "else:\n",
    "    start_idx = 0\n",
    "    end_idx = data_size_per_iteration\n",
    "    batch_src_encodec = selected_src_encodec[start_idx:end_idx] \n",
    "    batch_instruction = selected_instruction[start_idx:end_idx]\n",
    "    logging.info(f\"Processing data from index {start_idx} to {end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_942v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_59v_tok_233v_tok_796v_tok_928v_tok_457v_tok_865v_tok_835v_tok_835v_tok_876v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_598v_tok_1022v_tok_23v_tok_23v_tok_563v_tok_293v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_835v_tok_855v_tok_835v_tok_738v_tok_475v_tok_602v_tok_906v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_563v_tok_523v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_971v_tok_224v_tok_753v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_738v_tok_935v_tok_463v_tok_463v_tok_463v_tok_25v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_233v_tok_479v_tok_535v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_453v_tok_136v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_402v_tok_942v_tok_901v_tok_505v_tok_901v_tok_875v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_876v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_155v_tok_1022v_tok_457v_tok_495v_tok_185v_tok_983v_tok_155v_tok_323v_tok_565v_tok_523v_tok_699v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_855v_tok_666v_tok_709v_tok_176v_tok_176v_tok_463v_tok_339v_tok_339v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_738v_tok_876v_tok_835v_tok_430v_tok_751v_tok_967v_tok_479v_tok_479v_tok_141v_tok_479v_tok_479v_tok_479v_tok_790v_tok_939v_tok_48v_tok_598v_tok_922v_tok_835v_tok_835v_tok_876v_tok_431v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_690v_tok_563v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_408v_tok_408v_tok_835v_tok_835v_tok_738v_tok_25v_tok_151v_tok_502v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_983v_tok_901v_tok_321v_tok_424v_tok_523v_tok_860v_tok_155v_tok_523v_tok_565v_tok_860v_tok_967v_tok_971v_tok_604v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_738v_tok_738v_tok_876v_tok_325v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_835</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_923v_tok_59v_tok_479v_tok_479v_tok_479v_tok_790v_tok_431v_tok_479v_tok_479v_tok_453v_tok_944v_tok_922v_tok_835v_tok_835v_tok_738v_tok_233v_tok_203v_tok_451v_tok_291v_tok_925v_tok_942v_tok_931v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_855v_tok_738v_tok_835v_tok_738v_tok_738v_tok_133v_tok_940v_tok_727v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_696v_tok_1001v_tok_971v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_666v_tok_709v_tok_709v_tok_709v_tok_819v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_339v_tok_395v_tok_475</s>', 'v_tok_738v_tok_835v_tok_835v_tok_835v_tok_751v_tok_926v_tok_411v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_59v_tok_588v_tok_453v_tok_881v_tok_922v_tok_62v_tok_835v_tok_876v_tok_747v_tok_358v_tok_155v_tok_291v_tok_925v_tok_942v_tok_901v_tok_275v_tok_275v_tok_23v_tok_945v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_491v_tok_208v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_876v_tok_475v_tok_151v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_424v_tok_151v_tok_901v_tok_901v_tok_690v_tok_1008v_tok_155v_tok_982v_tok_155v_tok_323v_tok_565v_tok_753v_tok_967v_tok_971v_tok_604v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_73v_tok_463v_tok_463v_tok_463v_tok_176v_tok_463v_tok_395v_tok_463v_tok_395v_tok_339v_tok_339v_tok_339v_tok_475</s>', 'v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_942v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_59v_tok_233v_tok_796v_tok_928v_tok_457v_tok_865v_tok_835v_tok_835v_tok_876v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_598v_tok_1022v_tok_23v_tok_23v_tok_563v_tok_293v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_835v_tok_855v_tok_835v_tok_738v_tok_475v_tok_602v_tok_906v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_563v_tok_523v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_971v_tok_224v_tok_753v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_738v_tok_935v_tok_463v_tok_463v_tok_463v_tok_25v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_479v_tok_388v_tok_479v_tok_479v_tok_431v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_747v_tok_43v_tok_808v_tok_291v_tok_1010v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_834v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_126v_tok_151v_tok_317v_tok_906v_tok_151v_tok_151v_tok_151v_tok_931v_tok_151v_tok_651v_tok_598v_tok_862v_tok_402v_tok_185v_tok_291v_tok_155v_tok_753v_tok_565v_tok_323v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_475v_tok_783v_tok_709v_tok_176v_tok_25v_tok_176v_tok_819v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>', 'v_tok_738v_tok_106v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_411v_tok_59v_tok_479v_tok_479v_tok_479v_tok_348v_tok_348v_tok_99v_tok_939v_tok_881v_tok_865v_tok_835v_tok_835v_tok_835v_tok_85v_tok_747v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_402v_tok_505v_tok_23v_tok_30v_tok_321v_tok_1001v_tok_224v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_430v_tok_904v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_106v_tok_339v_tok_317v_tok_906v_tok_944v_tok_151v_tok_890v_tok_151v_tok_502v_tok_151v_tok_944v_tok_901v_tok_950v_tok_155v_tok_523v_tok_291v_tok_323v_tok_323v_tok_565v_tok_323v_tok_967v_tok_604v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_457v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_738v_tok_475v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_939v_tok_479v_tok_479v_tok_584v_tok_796v_tok_916v_tok_881v_tok_922v_tok_876v_tok_738v_tok_876v_tok_358v_tok_747v_tok_656v_tok_291v_tok_925v_tok_942v_tok_931v_tok_505v_tok_505v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_1017v_tok_835v_tok_835v_tok_835v_tok_876v_tok_25v_tok_872v_tok_588v_tok_944v_tok_151v_tok_151v_tok_151v_tok_890v_tok_151v_tok_151v_tok_136v_tok_23v_tok_155v_tok_185v_tok_291v_tok_523v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_1019v_tok_738v_tok_738v_tok_835v_tok_475v_tok_935v_tok_463v_tok_463v_tok_25v_tok_25v_tok_339v_tok_819v_tok_709v_tok_339v_tok_25v_tok_339v_tok_339v_tok_339</s>', 'v_tok_408v_tok_835v_tok_835v_tok_855v_tok_751v_tok_1008v_tok_411v_tok_411v_tok_479v_tok_479v_tok_479v_tok_782v_tok_479v_tok_479v_tok_453v_tok_687v_tok_922v_tok_835v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_942v_tok_942v_tok_942v_tok_690v_tok_862v_tok_23v_tok_23v_tok_563v_tok_807v_tok_530v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_25v_tok_465v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_433v_tok_151v_tok_502v_tok_901v_tok_563v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_753v_tok_753v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_876v_tok_876v_tok_499v_tok_709v_tok_395v_tok_709v_tok_176v_tok_463v_tok_661v_tok_339v_tok_709v_tok_133v_tok_339v_tok_126v_tok_126', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_923v_tok_59v_tok_479v_tok_479v_tok_479v_tok_790v_tok_431v_tok_479v_tok_479v_tok_453v_tok_944v_tok_922v_tok_835v_tok_835v_tok_738v_tok_233v_tok_203v_tok_451v_tok_291v_tok_925v_tok_942v_tok_931v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_855v_tok_738v_tok_835v_tok_738v_tok_738v_tok_133v_tok_940v_tok_727v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_696v_tok_1001v_tok_971v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_666v_tok_709v_tok_709v_tok_709v_tok_819v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_339v_tok_395v_tok_475</s>', 'v_tok_738v_tok_876v_tok_738v_tok_834v_tok_751v_tok_1008v_tok_411v_tok_535v_tok_479v_tok_479v_tok_479v_tok_57v_tok_796v_tok_914v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_411v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_881v_tok_291v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_1017v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_339v_tok_835v_tok_835v_tok_835v_tok_843v_tok_479v_tok_642v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_424v_tok_901v_tok_563v_tok_1008v_tok_901v_tok_862v_tok_155v_tok_690v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_408v_tok_408v_tok_835v_tok_666v_tok_709v_tok_176v_tok_339v_tok_463v_tok_339v_tok_339v_tok_339v_tok_395v_tok_339v_tok_339v_tok_779v_tok_133</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_755v_tok_479v_tok_479v_tok_59v_tok_479v_tok_431v_tok_479v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_106v_tok_747v_tok_358v_tok_808v_tok_921v_tok_925v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_395v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_502v_tok_598v_tok_931v_tok_901v_tok_495v_tok_833v_tok_185v_tok_291v_tok_155v_tok_523v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_133v_tok_133v_tok_835v_tok_738v_tok_738v_tok_835v_tok_666v_tok_463v_tok_463v_tok_463v_tok_709v_tok_395v_tok_537v_tok_463v_tok_25v_tok_339v_tok_395v_tok_339v_tok_339</s>', 'v_tok_738v_tok_876v_tok_738v_tok_834v_tok_751v_tok_1008v_tok_411v_tok_535v_tok_479v_tok_479v_tok_479v_tok_57v_tok_796v_tok_914v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_411v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_881v_tok_291v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_1017v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_339v_tok_835v_tok_835v_tok_835v_tok_843v_tok_479v_tok_642v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_424v_tok_901v_tok_563v_tok_1008v_tok_901v_tok_862v_tok_155v_tok_690v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_408v_tok_408v_tok_835v_tok_666v_tok_709v_tok_176v_tok_339v_tok_463v_tok_339v_tok_339v_tok_339v_tok_395v_tok_339v_tok_339v_tok_779v_tok_133</s>', 'v_tok_738v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_796v_tok_846v_tok_479v_tok_479v_tok_479v_tok_939v_tok_584v_tok_796v_tok_939v_tok_699v_tok_922v_tok_835v_tok_106v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_931v_tok_23v_tok_23v_tok_23v_tok_860v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_876v_tok_738v_tok_876v_tok_738v_tok_1017v_tok_25v_tok_151v_tok_479v_tok_317v_tok_890v_tok_890v_tok_890v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_862v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_971v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_393v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_395v_tok_709v_tok_339v_tok_395v_tok_475v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_479v_tok_453v_tok_598v_tok_922v_tok_835v_tok_835v_tok_876v_tok_850v_tok_358v_tok_808v_tok_291v_tok_11v_tok_942v_tok_931v_tok_505v_tok_505v_tok_23v_tok_945v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_738v_tok_1017v_tok_23v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_321v_tok_523v_tok_598v_tok_23v_tok_321v_tok_881v_tok_185v_tok_291v_tok_155v_tok_971v_tok_565v_tok_942v_tok_967v_tok_971v_tok_136v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_738v_tok_738v_tok_835v_tok_835v_tok_676v_tok_176v_tok_176v_tok_176v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_408v_tok_835v_tok_835v_tok_855v_tok_751v_tok_1008v_tok_411v_tok_411v_tok_479v_tok_479v_tok_479v_tok_782v_tok_479v_tok_479v_tok_453v_tok_687v_tok_922v_tok_835v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_942v_tok_942v_tok_942v_tok_690v_tok_862v_tok_23v_tok_23v_tok_563v_tok_807v_tok_530v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_25v_tok_465v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_433v_tok_151v_tok_502v_tok_901v_tok_563v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_753v_tok_753v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_876v_tok_876v_tok_499v_tok_709v_tok_395v_tok_709v_tok_176v_tok_463v_tok_661v_tok_339v_tok_709v_tok_133v_tok_339v_tok_126v_tok_126', 'v_tok_738v_tok_835v_tok_835v_tok_835v_tok_751v_tok_926v_tok_411v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_59v_tok_588v_tok_453v_tok_881v_tok_922v_tok_62v_tok_835v_tok_876v_tok_747v_tok_358v_tok_155v_tok_291v_tok_925v_tok_942v_tok_901v_tok_275v_tok_275v_tok_23v_tok_945v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_491v_tok_208v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_876v_tok_475v_tok_151v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_424v_tok_151v_tok_901v_tok_901v_tok_690v_tok_1008v_tok_155v_tok_982v_tok_155v_tok_323v_tok_565v_tok_753v_tok_967v_tok_971v_tok_604v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_73v_tok_463v_tok_463v_tok_463v_tok_176v_tok_463v_tok_395v_tok_463v_tok_395v_tok_339v_tok_339v_tok_339v_tok_475</s>', 'v_tok_738v_tok_876v_tok_835v_tok_430v_tok_751v_tok_967v_tok_479v_tok_479v_tok_141v_tok_479v_tok_479v_tok_479v_tok_790v_tok_939v_tok_48v_tok_598v_tok_922v_tok_835v_tok_835v_tok_876v_tok_431v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_690v_tok_563v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_408v_tok_408v_tok_835v_tok_835v_tok_738v_tok_25v_tok_151v_tok_502v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_983v_tok_901v_tok_321v_tok_424v_tok_523v_tok_860v_tok_155v_tok_523v_tok_565v_tok_860v_tok_967v_tok_971v_tok_604v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_738v_tok_738v_tok_876v_tok_325v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_835</s>', 'v_tok_835v_tok_835v_tok_408v_tok_835v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_317v_tok_479v_tok_479v_tok_479v_tok_796v_tok_596v_tok_491v_tok_922v_tok_133v_tok_1017v_tok_876v_tok_747v_tok_358v_tok_808v_tok_563v_tok_925v_tok_942v_tok_901v_tok_860v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_1019v_tok_126v_tok_347v_tok_133v_tok_835v_tok_408v_tok_133v_tok_835v_tok_475v_tok_475v_tok_433v_tok_906v_tok_424v_tok_563v_tok_890v_tok_151v_tok_1001v_tok_598v_tok_944v_tok_598v_tok_862v_tok_1022v_tok_523v_tok_291v_tok_1001v_tok_881v_tok_565v_tok_971v_tok_967v_tok_976v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_475v_tok_935v_tok_339v_tok_463v_tok_339v_tok_176v_tok_463v_tok_339v_tok_339v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_835v_tok_835v_tok_835v_tok_126v_tok_751v_tok_967v_tok_906v_tok_479v_tok_479v_tok_479v_tok_790v_tok_317v_tok_479v_tok_584v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_738v_tok_747v_tok_575v_tok_837v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_945v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_523v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_1017v_tok_395v_tok_59v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_690v_tok_151v_tok_690v_tok_901v_tok_155v_tok_862v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_835v_tok_676v_tok_395v_tok_709v_tok_819v_tok_463v_tok_463v_tok_463v_tok_339v_tok_339v_tok_339v_tok_395v_tok_475v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_126v_tok_751v_tok_967v_tok_906v_tok_479v_tok_479v_tok_479v_tok_790v_tok_317v_tok_479v_tok_584v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_738v_tok_747v_tok_575v_tok_837v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_945v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_523v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_1017v_tok_395v_tok_59v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_690v_tok_151v_tok_690v_tok_901v_tok_155v_tok_862v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_835v_tok_676v_tok_395v_tok_709v_tok_819v_tok_463v_tok_463v_tok_463v_tok_339v_tok_339v_tok_339v_tok_395v_tok_475v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_233v_tok_479v_tok_535v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_453v_tok_136v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_402v_tok_942v_tok_901v_tok_505v_tok_901v_tok_875v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_876v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_155v_tok_1022v_tok_457v_tok_495v_tok_185v_tok_983v_tok_155v_tok_323v_tok_565v_tok_523v_tok_699v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_855v_tok_666v_tok_709v_tok_176v_tok_176v_tok_463v_tok_339v_tok_339v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_738v_tok_475v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_939v_tok_479v_tok_479v_tok_584v_tok_796v_tok_916v_tok_881v_tok_922v_tok_876v_tok_738v_tok_876v_tok_358v_tok_747v_tok_656v_tok_291v_tok_925v_tok_942v_tok_931v_tok_505v_tok_505v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_1017v_tok_835v_tok_835v_tok_835v_tok_876v_tok_25v_tok_872v_tok_588v_tok_944v_tok_151v_tok_151v_tok_151v_tok_890v_tok_151v_tok_151v_tok_136v_tok_23v_tok_155v_tok_185v_tok_291v_tok_523v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_1019v_tok_738v_tok_738v_tok_835v_tok_475v_tok_935v_tok_463v_tok_463v_tok_25v_tok_25v_tok_339v_tok_819v_tok_709v_tok_339v_tok_25v_tok_339v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_182v_tok_939v_tok_479v_tok_479v_tok_479v_tok_348v_tok_504v_tok_348v_tok_479v_tok_766v_tok_311v_tok_922v_tok_835v_tok_835v_tok_738v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_155v_tok_921v_tok_415v_tok_942v_tok_563v_tok_1001v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_699v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_133v_tok_151v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_666v_tok_151v_tok_151v_tok_901v_tok_953v_tok_1008v_tok_185v_tok_690v_tok_155v_tok_323v_tok_565v_tok_971v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_408v_tok_106v_tok_408v_tok_475v_tok_73v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_479v_tok_453v_tok_598v_tok_922v_tok_835v_tok_835v_tok_876v_tok_850v_tok_358v_tok_808v_tok_291v_tok_11v_tok_942v_tok_931v_tok_505v_tok_505v_tok_23v_tok_945v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_738v_tok_1017v_tok_23v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_321v_tok_523v_tok_598v_tok_23v_tok_321v_tok_881v_tok_185v_tok_291v_tok_155v_tok_971v_tok_565v_tok_942v_tok_967v_tok_971v_tok_136v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_738v_tok_738v_tok_835v_tok_835v_tok_676v_tok_176v_tok_176v_tok_176v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_182v_tok_939v_tok_479v_tok_479v_tok_479v_tok_348v_tok_504v_tok_348v_tok_479v_tok_766v_tok_311v_tok_922v_tok_835v_tok_835v_tok_738v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_155v_tok_921v_tok_415v_tok_942v_tok_563v_tok_1001v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_699v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_133v_tok_151v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_666v_tok_151v_tok_151v_tok_901v_tok_953v_tok_1008v_tok_185v_tok_690v_tok_155v_tok_323v_tok_565v_tok_971v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_408v_tok_106v_tok_408v_tok_475v_tok_73v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_479v_tok_388v_tok_479v_tok_479v_tok_431v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_747v_tok_43v_tok_808v_tok_291v_tok_1010v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_834v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_126v_tok_151v_tok_317v_tok_906v_tok_151v_tok_151v_tok_151v_tok_931v_tok_151v_tok_651v_tok_598v_tok_862v_tok_402v_tok_185v_tok_291v_tok_155v_tok_753v_tok_565v_tok_323v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_475v_tok_783v_tok_709v_tok_176v_tok_25v_tok_176v_tok_819v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>'], 'rejected': ['v_tok_408v_tok_738v_tok_738v_tok_835v_tok_751v_tok_255v_tok_411v_tok_479v_tok_479v_tok_479v_tok_906v_tok_479v_tok_59v_tok_479v_tok_453v_tok_868v_tok_922v_tok_835v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_457v_tok_415v_tok_23v_tok_495v_tok_563v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_738v_tok_835v_tok_738v_tok_876v_tok_126v_tok_602v_tok_502v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_368v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_523v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_738v_tok_876v_tok_666v_tok_176v_tok_463v_tok_395v_tok_463v_tok_395v_tok_709v_tok_709v_tok_463v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_413v_tok_535v_tok_479v_tok_479v_tok_479v_tok_956v_tok_479v_tok_782v_tok_575v_tok_881v_tok_410v_tok_408v_tok_408v_tok_876v_tok_213v_tok_747v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_1001v_tok_563v_tok_1001v_tok_860v_tok_208v_tok_430v_tok_126v_tok_257v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_738v_tok_475v_tok_151v_tok_388v_tok_317v_tok_151v_tok_931v_tok_931v_tok_931v_tok_151v_tok_502v_tok_901v_tok_690v_tok_690v_tok_901v_tok_291v_tok_155v_tok_323v_tok_565v_tok_1001v_tok_967v_tok_971v_tok_976v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_738v_tok_835v_tok_276v_tok_176v_tok_176v_tok_25v_tok_25v_tok_463v_tok_709v_tok_709v_tok_779v_tok_395v_tok_339v_tok_339v_tok_339</s>', 'v_tok_408v_tok_106v_tok_738v_tok_738v_tok_751v_tok_1008v_tok_411v_tok_980v_tok_479v_tok_479v_tok_730v_tok_730v_tok_479v_tok_411v_tok_453v_tok_881v_tok_922v_tok_738v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_1022v_tok_901v_tok_901v_tok_495v_tok_424v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_133v_tok_559v_tok_906v_tok_151v_tok_151v_tok_151v_tok_598v_tok_901v_tok_563v_tok_495v_tok_23v_tok_275v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_23v_tok_176v_tok_176v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s><pad>', 'v_tok_408v_tok_738v_tok_876v_tok_835v_tok_751v_tok_182v_tok_479v_tok_562v_tok_422v_tok_479v_tok_411v_tok_411v_tok_411v_tok_939v_tok_782v_tok_881v_tok_922v_tok_62v_tok_738v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_1019v_tok_126v_tok_432v_tok_133v_tok_738v_tok_408v_tok_408v_tok_835v_tok_835v_tok_1019v_tok_602v_tok_612v_tok_465v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_944v_tok_598v_tok_690v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_370v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_876v_tok_738v_tok_408v_tok_738v_tok_1019v_tok_499v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_709</s>', 'v_tok_408v_tok_876v_tok_408v_tok_1017v_tok_751v_tok_255v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_233v_tok_479v_tok_584v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_505v_tok_563v_tok_890v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_971v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_738v_tok_738v_tok_738v_tok_876v_tok_276v_tok_23v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_901v_tok_495v_tok_23v_tok_1022v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_871v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_106v_tok_738v_tok_738v_tok_408v_tok_835v_tok_792v_tok_463v_tok_463v_tok_463v_tok_537v_tok_463v_tok_819v_tok_709v_tok_819v_tok_339v_tok_339v_tok_463v_tok_339</s>', 'v_tok_408v_tok_738v_tok_738v_tok_835v_tok_751v_tok_255v_tok_411v_tok_479v_tok_479v_tok_479v_tok_906v_tok_479v_tok_59v_tok_479v_tok_453v_tok_868v_tok_922v_tok_835v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_457v_tok_415v_tok_23v_tok_495v_tok_563v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_738v_tok_835v_tok_738v_tok_876v_tok_126v_tok_602v_tok_502v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_368v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_523v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_738v_tok_876v_tok_666v_tok_176v_tok_463v_tok_395v_tok_463v_tok_395v_tok_709v_tok_709v_tok_463v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_408v_tok_835v_tok_835v_tok_339v_tok_751v_tok_255v_tok_411v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_233v_tok_584v_tok_453v_tok_881v_tok_922v_tok_106v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_699v_tok_430v_tok_126v_tok_126v_tok_133v_tok_1017v_tok_738v_tok_1019v_tok_738v_tok_876v_tok_395v_tok_602v_tok_727v_tok_151v_tok_151v_tok_151v_tok_690v_tok_424v_tok_563v_tok_1001v_tok_901v_tok_321v_tok_424v_tok_185v_tok_291v_tok_155v_tok_323v_tok_971v_tok_323v_tok_967v_tok_971v_tok_604v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_835v_tok_777v_tok_463v_tok_463v_tok_463v_tok_176v_tok_395v_tok_395v_tok_709v_tok_395v_tok_339v_tok_709v_tok_709v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_182v_tok_411v_tok_903v_tok_479v_tok_411v_tok_479v_tok_479v_tok_348v_tok_465v_tok_784v_tok_881v_tok_865v_tok_835v_tok_835v_tok_738v_tok_747v_tok_451v_tok_837v_tok_291v_tok_1010v_tok_942v_tok_944v_tok_505v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_155v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_339v_tok_940v_tok_1021v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_563v_tok_890v_tok_598v_tok_495v_tok_291v_tok_291v_tok_523v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_430v_tok_1019v_tok_1017v_tok_876v_tok_835v_tok_835v_tok_408v_tok_876v_tok_777v_tok_709v_tok_176v_tok_25v_tok_463v_tok_339v_tok_339v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_999v_tok_751v_tok_651v_tok_411v_tok_479v_tok_411v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_796v_tok_881v_tok_922v_tok_738v_tok_738v_tok_876v_tok_372v_tok_43v_tok_808v_tok_881v_tok_925v_tok_942v_tok_901v_tok_505v_tok_505v_tok_860v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_224v_tok_224v_tok_430v_tok_430v_tok_432v_tok_133v_tok_133v_tok_738v_tok_106v_tok_835v_tok_835v_tok_475v_tok_940v_tok_939v_tok_465v_tok_151v_tok_151v_tok_598v_tok_151v_tok_151v_tok_502v_tok_901v_tok_155v_tok_925v_tok_523v_tok_291v_tok_155v_tok_523v_tok_370v_tok_323v_tok_323v_tok_971v_tok_753v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_876v_tok_499v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_133v_tok_751v_tok_255v_tok_378v_tok_980v_tok_479v_tok_479v_tok_479v_tok_939v_tok_479v_tok_1000v_tok_766v_tok_136v_tok_922v_tok_339v_tok_835v_tok_876v_tok_213v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_457v_tok_505v_tok_23v_tok_901v_tok_860v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_1001v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_475v_tok_602v_tok_465v_tok_151v_tok_151v_tok_151v_tok_858v_tok_502v_tok_598v_tok_901v_tok_931v_tok_495v_tok_690v_tok_185v_tok_291v_tok_155v_tok_323v_tok_976v_tok_323v_tok_967v_tok_971v_tok_131v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_835v_tok_835v_tok_339v_tok_499v_tok_463v_tok_463v_tok_463v_tok_537v_tok_463v_tok_463v_tok_798v_tok_709v_tok_395v_tok_339v_tok_835v_tok_339</s>', 'v_tok_408v_tok_738v_tok_876v_tok_835v_tok_751v_tok_182v_tok_479v_tok_562v_tok_422v_tok_479v_tok_411v_tok_411v_tok_411v_tok_939v_tok_782v_tok_881v_tok_922v_tok_62v_tok_738v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_1019v_tok_126v_tok_432v_tok_133v_tok_738v_tok_408v_tok_408v_tok_835v_tok_835v_tok_1019v_tok_602v_tok_612v_tok_465v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_944v_tok_598v_tok_690v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_370v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_876v_tok_738v_tok_408v_tok_738v_tok_1019v_tok_499v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_709</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_1008v_tok_782v_tok_846v_tok_479v_tok_479v_tok_479v_tok_782v_tok_479v_tok_388v_tok_782v_tok_881v_tok_922v_tok_780v_tok_408v_tok_876v_tok_385v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_604v_tok_1019v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_475v_tok_872v_tok_782v_tok_906v_tok_502v_tok_676v_tok_1011v_tok_185v_tok_151v_tok_502v_tok_901v_tok_690v_tok_901v_tok_523v_tok_291v_tok_155v_tok_323v_tok_598v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_835v_tok_835v_tok_499v_tok_709v_tok_463v_tok_25v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>', 'v_tok_738v_tok_738v_tok_738v_tok_1017v_tok_751v_tok_1008v_tok_453v_tok_479v_tok_479v_tok_479v_tok_81v_tok_788v_tok_479v_tok_59v_tok_782v_tok_944v_tok_922v_tok_835v_tok_835v_tok_126v_tok_411v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_523v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_430v_tok_133v_tok_876v_tok_738v_tok_835v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_563v_tok_151v_tok_875v_tok_1001v_tok_151v_tok_151v_tok_502v_tok_901v_tok_890v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_457v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_738v_tok_408v_tok_835v_tok_323v_tok_463v_tok_463v_tok_25v_tok_463v_tok_463v_tok_463v_tok_395v_tok_339v_tok_395v_tok_339v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_1008v_tok_782v_tok_846v_tok_479v_tok_479v_tok_479v_tok_782v_tok_479v_tok_388v_tok_782v_tok_881v_tok_922v_tok_780v_tok_408v_tok_876v_tok_385v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_604v_tok_1019v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_475v_tok_872v_tok_782v_tok_906v_tok_502v_tok_676v_tok_1011v_tok_185v_tok_151v_tok_502v_tok_901v_tok_690v_tok_901v_tok_523v_tok_291v_tok_155v_tok_323v_tok_598v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_835v_tok_835v_tok_499v_tok_709v_tok_463v_tok_25v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_411v_tok_535v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_400v_tok_453v_tok_881v_tok_922v_tok_835v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_807v_tok_598v_tok_505v_tok_23v_tok_23v_tok_321v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_604v_tok_126v_tok_887v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_395v_tok_502v_tok_59v_tok_151v_tok_151v_tok_151v_tok_890v_tok_502v_tok_151v_tok_901v_tok_901v_tok_155v_tok_862v_tok_155v_tok_291v_tok_155v_tok_860v_tok_565v_tok_323v_tok_967v_tok_971v_tok_347v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_835v_tok_935v_tok_463v_tok_25v_tok_463v_tok_463v_tok_25v_tok_395v_tok_709v_tok_25v_tok_339v_tok_709v_tok_835v_tok_339</s>', 'v_tok_738v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_411v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_479v_tok_584v_tok_796v_tok_881v_tok_410v_tok_835v_tok_738v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_136v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_408v_tok_876v_tok_876v_tok_876v_tok_25v_tok_872v_tok_796v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_860v_tok_323v_tok_967v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_666v_tok_176v_tok_463v_tok_463v_tok_463v_tok_339v_tok_25v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_133v_tok_751v_tok_255v_tok_378v_tok_980v_tok_479v_tok_479v_tok_479v_tok_939v_tok_479v_tok_1000v_tok_766v_tok_136v_tok_922v_tok_339v_tok_835v_tok_876v_tok_213v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_457v_tok_505v_tok_23v_tok_901v_tok_860v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_1001v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_475v_tok_602v_tok_465v_tok_151v_tok_151v_tok_151v_tok_858v_tok_502v_tok_598v_tok_901v_tok_931v_tok_495v_tok_690v_tok_185v_tok_291v_tok_155v_tok_323v_tok_976v_tok_323v_tok_967v_tok_971v_tok_131v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_835v_tok_835v_tok_339v_tok_499v_tok_463v_tok_463v_tok_463v_tok_537v_tok_463v_tok_463v_tok_798v_tok_709v_tok_395v_tok_339v_tok_835v_tok_339</s>', 'v_tok_408v_tok_876v_tok_408v_tok_1017v_tok_751v_tok_255v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_233v_tok_479v_tok_584v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_505v_tok_563v_tok_890v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_971v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_738v_tok_738v_tok_738v_tok_876v_tok_276v_tok_23v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_901v_tok_495v_tok_23v_tok_1022v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_871v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_106v_tok_738v_tok_738v_tok_408v_tok_835v_tok_792v_tok_463v_tok_463v_tok_463v_tok_537v_tok_463v_tok_819v_tok_709v_tok_819v_tok_339v_tok_339v_tok_463v_tok_339</s>', 'v_tok_408v_tok_106v_tok_738v_tok_738v_tok_751v_tok_1008v_tok_411v_tok_980v_tok_479v_tok_479v_tok_730v_tok_730v_tok_479v_tok_411v_tok_453v_tok_881v_tok_922v_tok_738v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_1022v_tok_901v_tok_901v_tok_495v_tok_424v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_133v_tok_559v_tok_906v_tok_151v_tok_151v_tok_151v_tok_598v_tok_901v_tok_563v_tok_495v_tok_23v_tok_275v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_23v_tok_176v_tok_176v_tok_709v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s><pad>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_479v_tok_479v_tok_730v_tok_141v_tok_479v_tok_411v_tok_939v_tok_197v_tok_796v_tok_881v_tok_922v_tok_835v_tok_835v_tok_834v_tok_233v_tok_203v_tok_936v_tok_881v_tok_881v_tok_942v_tok_881v_tok_505v_tok_415v_tok_23v_tok_860v_tok_807v_tok_1001v_tok_1001v_tok_523v_tok_1001v_tok_890v_tok_224v_tok_430v_tok_876v_tok_724v_tok_133v_tok_133v_tok_133v_tok_835v_tok_835v_tok_133v_tok_904v_tok_151v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_860v_tok_23v_tok_598v_tok_890v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_604v_tok_228v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_408v_tok_738v_tok_408v_tok_835v_tok_323v_tok_463v_tok_463v_tok_463v_tok_176v_tok_339v_tok_339v_tok_339v_tok_463v_tok_339v_tok_395v_tok_339v_tok_339</s>', 'v_tok_738v_tok_876v_tok_835v_tok_835v_tok_751v_tok_182v_tok_388v_tok_568v_tok_479v_tok_479v_tok_479v_tok_886v_tok_588v_tok_956v_tok_929v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_1017v_tok_904v_tok_133v_tok_876v_tok_106v_tok_106v_tok_738v_tok_876v_tok_1019v_tok_666v_tok_407v_tok_502v_tok_151v_tok_151v_tok_136v_tok_151v_tok_151v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_738v_tok_876v_tok_738v_tok_738v_tok_777v_tok_709v_tok_463v_tok_463v_tok_819v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_395v_tok_339v_tok_475</s>', 'v_tok_738v_tok_876v_tok_835v_tok_835v_tok_751v_tok_182v_tok_388v_tok_568v_tok_479v_tok_479v_tok_479v_tok_886v_tok_588v_tok_956v_tok_929v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_1017v_tok_904v_tok_133v_tok_876v_tok_106v_tok_106v_tok_738v_tok_876v_tok_1019v_tok_666v_tok_407v_tok_502v_tok_151v_tok_151v_tok_136v_tok_151v_tok_151v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_738v_tok_876v_tok_738v_tok_738v_tok_777v_tok_709v_tok_463v_tok_463v_tok_819v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_395v_tok_339v_tok_475</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_413v_tok_535v_tok_479v_tok_479v_tok_479v_tok_956v_tok_479v_tok_782v_tok_575v_tok_881v_tok_410v_tok_408v_tok_408v_tok_876v_tok_213v_tok_747v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_1001v_tok_563v_tok_1001v_tok_860v_tok_208v_tok_430v_tok_126v_tok_257v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_738v_tok_475v_tok_151v_tok_388v_tok_317v_tok_151v_tok_931v_tok_931v_tok_931v_tok_151v_tok_502v_tok_901v_tok_690v_tok_690v_tok_901v_tok_291v_tok_155v_tok_323v_tok_565v_tok_1001v_tok_967v_tok_971v_tok_976v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_738v_tok_835v_tok_276v_tok_176v_tok_176v_tok_25v_tok_25v_tok_463v_tok_709v_tok_709v_tok_779v_tok_395v_tok_339v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_999v_tok_751v_tok_651v_tok_411v_tok_479v_tok_411v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_796v_tok_881v_tok_922v_tok_738v_tok_738v_tok_876v_tok_372v_tok_43v_tok_808v_tok_881v_tok_925v_tok_942v_tok_901v_tok_505v_tok_505v_tok_860v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_224v_tok_224v_tok_430v_tok_430v_tok_432v_tok_133v_tok_133v_tok_738v_tok_106v_tok_835v_tok_835v_tok_475v_tok_940v_tok_939v_tok_465v_tok_151v_tok_151v_tok_598v_tok_151v_tok_151v_tok_502v_tok_901v_tok_155v_tok_925v_tok_523v_tok_291v_tok_155v_tok_523v_tok_370v_tok_323v_tok_323v_tok_971v_tok_753v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_876v_tok_499v_tok_709v_tok_463v_tok_709v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_479v_tok_939v_tok_59v_tok_431v_tok_782v_tok_939v_tok_881v_tok_922v_tok_475v_tok_738v_tok_738v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_155v_tok_598v_tok_505v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_126v_tok_126v_tok_395v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_25v_tok_843v_tok_796v_tok_317v_tok_151v_tok_151v_tok_890v_tok_151v_tok_151v_tok_321v_tok_598v_tok_875v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_971v_tok_565v_tok_323v_tok_699v_tok_971v_tok_604v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_339v_tok_1011v_tok_463v_tok_463v_tok_463v_tok_339v_tok_339v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_738v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_411v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_479v_tok_584v_tok_796v_tok_881v_tok_410v_tok_835v_tok_738v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_136v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_408v_tok_876v_tok_876v_tok_876v_tok_25v_tok_872v_tok_796v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_860v_tok_323v_tok_967v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_738v_tok_666v_tok_176v_tok_463v_tok_463v_tok_463v_tok_339v_tok_25v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_479v_tok_939v_tok_59v_tok_431v_tok_782v_tok_939v_tok_881v_tok_922v_tok_475v_tok_738v_tok_738v_tok_850v_tok_358v_tok_808v_tok_291v_tok_925v_tok_155v_tok_598v_tok_505v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_126v_tok_126v_tok_395v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_25v_tok_843v_tok_796v_tok_317v_tok_151v_tok_151v_tok_890v_tok_151v_tok_151v_tok_321v_tok_598v_tok_875v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_971v_tok_565v_tok_323v_tok_699v_tok_971v_tok_604v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_339v_tok_1011v_tok_463v_tok_463v_tok_463v_tok_339v_tok_339v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_408v_tok_835v_tok_835v_tok_339v_tok_751v_tok_255v_tok_411v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_233v_tok_584v_tok_453v_tok_881v_tok_922v_tok_106v_tok_835v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_699v_tok_430v_tok_126v_tok_126v_tok_133v_tok_1017v_tok_738v_tok_1019v_tok_738v_tok_876v_tok_395v_tok_602v_tok_727v_tok_151v_tok_151v_tok_151v_tok_690v_tok_424v_tok_563v_tok_1001v_tok_901v_tok_321v_tok_424v_tok_185v_tok_291v_tok_155v_tok_323v_tok_971v_tok_323v_tok_967v_tok_971v_tok_604v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_835v_tok_777v_tok_463v_tok_463v_tok_463v_tok_176v_tok_395v_tok_395v_tok_709v_tok_395v_tok_339v_tok_709v_tok_709v_tok_339</s>']}\n",
      "val_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_738v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_796v_tok_846v_tok_479v_tok_479v_tok_479v_tok_939v_tok_584v_tok_796v_tok_939v_tok_699v_tok_922v_tok_835v_tok_106v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_931v_tok_23v_tok_23v_tok_23v_tok_860v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_876v_tok_738v_tok_876v_tok_738v_tok_1017v_tok_25v_tok_151v_tok_479v_tok_317v_tok_890v_tok_890v_tok_890v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_1008v_tok_185v_tok_862v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_971v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_393v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_395v_tok_709v_tok_339v_tok_395v_tok_475v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_755v_tok_479v_tok_479v_tok_59v_tok_479v_tok_431v_tok_479v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_106v_tok_747v_tok_358v_tok_808v_tok_921v_tok_925v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_395v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_502v_tok_598v_tok_931v_tok_901v_tok_495v_tok_833v_tok_185v_tok_291v_tok_155v_tok_523v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_133v_tok_133v_tok_835v_tok_738v_tok_738v_tok_835v_tok_666v_tok_463v_tok_463v_tok_463v_tok_709v_tok_395v_tok_537v_tok_463v_tok_25v_tok_339v_tok_395v_tok_339v_tok_339</s>', 'v_tok_738v_tok_106v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_411v_tok_59v_tok_479v_tok_479v_tok_479v_tok_348v_tok_348v_tok_99v_tok_939v_tok_881v_tok_865v_tok_835v_tok_835v_tok_835v_tok_85v_tok_747v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_402v_tok_505v_tok_23v_tok_30v_tok_321v_tok_1001v_tok_224v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_430v_tok_904v_tok_133v_tok_835v_tok_738v_tok_835v_tok_835v_tok_106v_tok_339v_tok_317v_tok_906v_tok_944v_tok_151v_tok_890v_tok_151v_tok_502v_tok_151v_tok_944v_tok_901v_tok_950v_tok_155v_tok_523v_tok_291v_tok_323v_tok_323v_tok_565v_tok_323v_tok_967v_tok_604v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_457v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_835v_tok_835v_tok_408v_tok_835v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_317v_tok_479v_tok_479v_tok_479v_tok_796v_tok_596v_tok_491v_tok_922v_tok_133v_tok_1017v_tok_876v_tok_747v_tok_358v_tok_808v_tok_563v_tok_925v_tok_942v_tok_901v_tok_860v_tok_23v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_1019v_tok_126v_tok_347v_tok_133v_tok_835v_tok_408v_tok_133v_tok_835v_tok_475v_tok_475v_tok_433v_tok_906v_tok_424v_tok_563v_tok_890v_tok_151v_tok_1001v_tok_598v_tok_944v_tok_598v_tok_862v_tok_1022v_tok_523v_tok_291v_tok_1001v_tok_881v_tok_565v_tok_971v_tok_967v_tok_976v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_475v_tok_935v_tok_339v_tok_463v_tok_339v_tok_176v_tok_463v_tok_339v_tok_339v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835'], 'rejected': ['v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_411v_tok_535v_tok_479v_tok_479v_tok_479v_tok_431v_tok_479v_tok_400v_tok_453v_tok_881v_tok_922v_tok_835v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_807v_tok_598v_tok_505v_tok_23v_tok_23v_tok_321v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_604v_tok_126v_tok_887v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_395v_tok_502v_tok_59v_tok_151v_tok_151v_tok_151v_tok_890v_tok_502v_tok_151v_tok_901v_tok_901v_tok_155v_tok_862v_tok_155v_tok_291v_tok_155v_tok_860v_tok_565v_tok_323v_tok_967v_tok_971v_tok_347v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_835v_tok_835v_tok_935v_tok_463v_tok_25v_tok_463v_tok_463v_tok_25v_tok_395v_tok_709v_tok_25v_tok_339v_tok_709v_tok_835v_tok_339</s>', 'v_tok_738v_tok_738v_tok_738v_tok_1017v_tok_751v_tok_1008v_tok_453v_tok_479v_tok_479v_tok_479v_tok_81v_tok_788v_tok_479v_tok_59v_tok_782v_tok_944v_tok_922v_tok_835v_tok_835v_tok_126v_tok_411v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_523v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_430v_tok_133v_tok_876v_tok_738v_tok_835v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_563v_tok_151v_tok_875v_tok_1001v_tok_151v_tok_151v_tok_502v_tok_901v_tok_890v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_457v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_738v_tok_408v_tok_835v_tok_323v_tok_463v_tok_463v_tok_25v_tok_463v_tok_463v_tok_463v_tok_395v_tok_339v_tok_395v_tok_339v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_876v_tok_751v_tok_182v_tok_411v_tok_903v_tok_479v_tok_411v_tok_479v_tok_479v_tok_348v_tok_465v_tok_784v_tok_881v_tok_865v_tok_835v_tok_835v_tok_738v_tok_747v_tok_451v_tok_837v_tok_291v_tok_1010v_tok_942v_tok_944v_tok_505v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_155v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_339v_tok_940v_tok_1021v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_563v_tok_890v_tok_598v_tok_495v_tok_291v_tok_291v_tok_523v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_430v_tok_1019v_tok_1017v_tok_876v_tok_835v_tok_835v_tok_408v_tok_876v_tok_777v_tok_709v_tok_176v_tok_25v_tok_463v_tok_339v_tok_339v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s><pad>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_479v_tok_479v_tok_730v_tok_141v_tok_479v_tok_411v_tok_939v_tok_197v_tok_796v_tok_881v_tok_922v_tok_835v_tok_835v_tok_834v_tok_233v_tok_203v_tok_936v_tok_881v_tok_881v_tok_942v_tok_881v_tok_505v_tok_415v_tok_23v_tok_860v_tok_807v_tok_1001v_tok_1001v_tok_523v_tok_1001v_tok_890v_tok_224v_tok_430v_tok_876v_tok_724v_tok_133v_tok_133v_tok_133v_tok_835v_tok_835v_tok_133v_tok_904v_tok_151v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_860v_tok_23v_tok_598v_tok_890v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_604v_tok_228v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_408v_tok_738v_tok_408v_tok_835v_tok_323v_tok_463v_tok_463v_tok_463v_tok_176v_tok_339v_tok_339v_tok_339v_tok_463v_tok_339v_tok_395v_tok_339v_tok_339</s>']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 28/28 [00:00<00:00, 1089.26 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 563.81 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mb09901066\u001b[0m (\u001b[33mb09901066_alan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/b0990106x/trl/wandb/run-20241022_185139-9dumd25n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/b09901066_alan/huggingface/runs/9dumd25n' target=\"_blank\">zany-sunset-109</a></strong> to <a href='https://wandb.ai/b09901066_alan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/b09901066_alan/huggingface' target=\"_blank\">https://wandb.ai/b09901066_alan/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/b09901066_alan/huggingface/runs/9dumd25n' target=\"_blank\">https://wandb.ai/b09901066_alan/huggingface/runs/9dumd25n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-1846/example_save_eval_0_data_8_0.wav\n",
      "train_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_967v_tok_411v_tok_411v_tok_479v_tok_479v_tok_479v_tok_502v_tok_906v_tok_588v_tok_453v_tok_868v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_881v_tok_23v_tok_901v_tok_23v_tok_23v_tok_23v_tok_1001v_tok_23v_tok_1001v_tok_523v_tok_563v_tok_1001v_tok_862v_tok_224v_tok_430v_tok_126v_tok_629v_tok_133v_tok_835v_tok_876v_tok_835v_tok_835v_tok_738v_tok_1019v_tok_151v_tok_465v_tok_502v_tok_151v_tok_151v_tok_151v_tok_502v_tok_563v_tok_151v_tok_901v_tok_495v_tok_1008v_tok_982v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_976v_tok_971v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_835v_tok_409v_tok_176v_tok_176v_tok_176v_tok_709v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>', 'v_tok_738v_tok_126v_tok_835v_tok_126v_tok_967v_tok_561v_tok_584v_tok_479v_tok_479v_tok_479v_tok_99v_tok_59v_tok_502v_tok_479v_tok_453v_tok_881v_tok_922v_tok_876v_tok_835v_tok_126v_tok_411v_tok_358v_tok_112v_tok_561v_tok_942v_tok_942v_tok_901v_tok_901v_tok_495v_tok_565v_tok_890v_tok_598v_tok_530v_tok_530v_tok_860v_tok_1001v_tok_224v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_835v_tok_876v_tok_126v_tok_502v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_890v_tok_151v_tok_136v_tok_155v_tok_967v_tok_402v_tok_291v_tok_155v_tok_971v_tok_565v_tok_879v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_876v_tok_126v_tok_635v_tok_709v_tok_176v_tok_819v_tok_25v_tok_463v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_106v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_944v_tok_479v_tok_479v_tok_479v_tok_790v_tok_479v_tok_479v_tok_755v_tok_233v_tok_575v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_997v_tok_378v_tok_808v_tok_291v_tok_523v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_1001v_tok_1001v_tok_208v_tok_563v_tok_1001v_tok_690v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_339v_tok_339v_tok_635v_tok_479v_tok_151v_tok_151v_tok_871v_tok_151v_tok_651v_tok_151v_tok_502v_tok_901v_tok_950v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_699v_tok_976v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_475v_tok_791v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_463v_tok_463v_tok_475v_tok_339v_tok_339v_tok_709v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_1008v_tok_59v_tok_479v_tok_479v_tok_479v_tok_906v_tok_479v_tok_59v_tok_465v_tok_784v_tok_881v_tok_922v_tok_835v_tok_876v_tok_876v_tok_372v_tok_43v_tok_808v_tok_291v_tok_925v_tok_942v_tok_1001v_tok_1008v_tok_415v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_408v_tok_835v_tok_835v_tok_339v_tok_25v_tok_611v_tok_479v_tok_151v_tok_151v_tok_151v_tok_598v_tok_502v_tok_23v_tok_690v_tok_901v_tok_982v_tok_967v_tok_155v_tok_291v_tok_155v_tok_565v_tok_393v_tok_967v_tok_967v_tok_971v_tok_753v_tok_321v_tok_834v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_835v_tok_935v_tok_709v_tok_463v_tok_709v_tok_176v_tok_463v_tok_819v_tok_709v_tok_709v_tok_339v_tok_395v_tok_339v_tok_395</s>', 'v_tok_738v_tok_475v_tok_835v_tok_133v_tok_751v_tok_1008v_tok_411v_tok_411v_tok_479v_tok_479v_tok_411v_tok_411v_tok_411v_tok_782v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_747v_tok_358v_tok_808v_tok_881v_tok_942v_tok_942v_tok_942v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_347v_tok_133v_tok_133v_tok_738v_tok_835v_tok_738v_tok_835v_tok_339v_tok_602v_tok_906v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_502v_tok_23v_tok_931v_tok_23v_tok_901v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_62v_tok_408v_tok_408v_tok_835v_tok_791v_tok_709v_tok_463v_tok_709v_tok_25v_tok_463v_tok_709v_tok_709v_tok_395v_tok_339v_tok_475v_tok_475v_tok_475</s>', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_967v_tok_411v_tok_411v_tok_479v_tok_479v_tok_479v_tok_502v_tok_906v_tok_588v_tok_453v_tok_868v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_881v_tok_23v_tok_901v_tok_23v_tok_23v_tok_23v_tok_1001v_tok_23v_tok_1001v_tok_523v_tok_563v_tok_1001v_tok_862v_tok_224v_tok_430v_tok_126v_tok_629v_tok_133v_tok_835v_tok_876v_tok_835v_tok_835v_tok_738v_tok_1019v_tok_151v_tok_465v_tok_502v_tok_151v_tok_151v_tok_151v_tok_502v_tok_563v_tok_151v_tok_901v_tok_495v_tok_1008v_tok_982v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_976v_tok_971v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_835v_tok_409v_tok_176v_tok_176v_tok_176v_tok_709v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_411v_tok_535v_tok_535v_tok_790v_tok_479v_tok_479v_tok_479v_tok_588v_tok_796v_tok_881v_tok_922v_tok_835v_tok_106v_tok_876v_tok_233v_tok_850v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_855v_tok_126v_tok_126v_tok_106v_tok_835v_tok_835v_tok_339v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_906v_tok_136v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_155v_tok_185v_tok_291v_tok_155v_tok_598v_tok_565v_tok_860v_tok_967v_tok_971v_tok_604v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_475v_tok_499v_tok_709v_tok_176v_tok_176v_tok_463v_tok_709v_tok_709v_tok_160v_tok_709v_tok_339v_tok_709v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_1017v_tok_876v_tok_751v_tok_1008v_tok_790v_tok_568v_tok_755v_tok_790v_tok_479v_tok_694v_tok_479v_tok_479v_tok_453v_tok_944v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_561v_tok_942v_tok_901v_tok_901v_tok_495v_tok_1001v_tok_23v_tok_563v_tok_1001v_tok_530v_tok_143v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_395v_tok_317v_tok_317v_tok_901v_tok_321v_tok_151v_tok_151v_tok_502v_tok_906v_tok_276v_tok_598v_tok_151v_tok_658v_tok_523v_tok_23v_tok_155v_tok_523v_tok_565v_tok_976v_tok_967v_tok_325v_tok_753v_tok_879v_tok_604v_tok_432v_tok_1019v_tok_339v_tok_475v_tok_835v_tok_738v_tok_835v_tok_835v_tok_1014v_tok_463v_tok_148v_tok_176v_tok_709v_tok_463v_tok_709v_tok_709v_tok_395v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_835v_tok_475v_tok_835v_tok_475v_tok_131v_tok_967v_tok_479v_tok_535v_tok_479v_tok_939v_tok_479v_tok_479v_tok_479v_tok_388v_tok_453v_tok_881v_tok_922v_tok_835v_tok_475v_tok_834v_tok_747v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_942v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_475v_tok_843v_tok_479v_tok_317v_tok_151v_tok_151v_tok_23v_tok_502v_tok_598v_tok_151v_tok_598v_tok_495v_tok_666v_tok_495v_tok_971v_tok_879v_tok_971v_tok_971v_tok_224v_tok_491v_tok_604v_tok_699v_tok_1019v_tok_876v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_835v_tok_835v_tok_499v_tok_709v_tok_176v_tok_537v_tok_176v_tok_339v_tok_25v_tok_709v_tok_819v_tok_339v_tok_339v_tok_339v_tok_395</s><pad><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_479v_tok_479v_tok_504v_tok_411v_tok_479v_tok_479v_tok_730v_tok_57v_tok_453v_tok_868v_tok_922v_tok_408v_tok_835v_tok_876v_tok_782v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_999v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_475v_tok_940v_tok_858v_tok_912v_tok_533v_tok_890v_tok_890v_tok_502v_tok_890v_tok_424v_tok_1001v_tok_321v_tok_80v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_738v_tok_876v_tok_835v_tok_738v_tok_876v_tok_1011v_tok_709v_tok_463v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_709v_tok_339v_tok_835', 'v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_1008v_tok_59v_tok_479v_tok_479v_tok_479v_tok_906v_tok_479v_tok_59v_tok_465v_tok_784v_tok_881v_tok_922v_tok_835v_tok_876v_tok_876v_tok_372v_tok_43v_tok_808v_tok_291v_tok_925v_tok_942v_tok_1001v_tok_1008v_tok_415v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_408v_tok_835v_tok_835v_tok_339v_tok_25v_tok_611v_tok_479v_tok_151v_tok_151v_tok_151v_tok_598v_tok_502v_tok_23v_tok_690v_tok_901v_tok_982v_tok_967v_tok_155v_tok_291v_tok_155v_tok_565v_tok_393v_tok_967v_tok_967v_tok_971v_tok_753v_tok_321v_tok_834v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_835v_tok_935v_tok_709v_tok_463v_tok_709v_tok_176v_tok_463v_tok_819v_tok_709v_tok_709v_tok_339v_tok_395v_tok_339v_tok_395</s>', 'v_tok_408v_tok_835v_tok_408v_tok_1017v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_939v_tok_59v_tok_59v_tok_411v_tok_956v_tok_453v_tok_881v_tok_922v_tok_835v_tok_738v_tok_855v_tok_585v_tok_358v_tok_808v_tok_291v_tok_881v_tok_1001v_tok_931v_tok_925v_tok_901v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_876v_tok_408v_tok_876v_tok_475v_tok_602v_tok_479v_tok_317v_tok_151v_tok_890v_tok_890v_tok_424v_tok_151v_tok_502v_tok_901v_tok_495v_tok_690v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_835v_tok_835v_tok_339v_tok_499v_tok_463v_tok_463v_tok_176v_tok_176v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_339v_tok_709v_tok_835', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_255v_tok_1018v_tok_479v_tok_479v_tok_479v_tok_99v_tok_348v_tok_796v_tok_796v_tok_928v_tok_942v_tok_922v_tok_855v_tok_835v_tok_835v_tok_694v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_890v_tok_505v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_1001v_tok_321v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_133v_tok_835v_tok_835v_tok_738v_tok_876v_tok_779v_tok_502v_tok_479v_tok_151v_tok_151v_tok_151v_tok_136v_tok_651v_tok_136v_tok_926v_tok_901v_tok_155v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_523v_tok_971v_tok_971v_tok_321v_tok_604v_tok_432v_tok_876v_tok_339v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_323v_tok_339v_tok_463v_tok_709v_tok_463v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_709v_tok_339v_tok_835</s>', 'v_tok_408v_tok_835v_tok_408v_tok_1017v_tok_751v_tok_1008v_tok_411v_tok_479v_tok_479v_tok_939v_tok_59v_tok_59v_tok_411v_tok_956v_tok_453v_tok_881v_tok_922v_tok_835v_tok_738v_tok_855v_tok_585v_tok_358v_tok_808v_tok_291v_tok_881v_tok_1001v_tok_931v_tok_925v_tok_901v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_876v_tok_408v_tok_876v_tok_475v_tok_602v_tok_479v_tok_317v_tok_151v_tok_890v_tok_890v_tok_424v_tok_151v_tok_502v_tok_901v_tok_495v_tok_690v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_835v_tok_835v_tok_339v_tok_499v_tok_463v_tok_463v_tok_176v_tok_176v_tok_463v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_339v_tok_709v_tok_835', 'v_tok_408v_tok_835v_tok_835v_tok_430v_tok_751v_tok_255v_tok_584v_tok_846v_tok_479v_tok_479v_tok_479v_tok_141v_tok_584v_tok_57v_tok_796v_tok_881v_tok_922v_tok_835v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_530v_tok_224v_tok_133v_tok_126v_tok_604v_tok_133v_tok_738v_tok_835v_tok_835v_tok_835v_tok_475v_tok_25v_tok_465v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_679v_tok_890v_tok_23v_tok_185v_tok_275v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_228v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_339v_tok_635v_tok_463v_tok_176v_tok_463v_tok_176v_tok_395v_tok_709v_tok_819v_tok_709v_tok_395v_tok_395v_tok_835</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_912v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_388v_tok_59v_tok_782v_tok_931v_tok_922v_tok_1019v_tok_1017v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_598v_tok_505v_tok_415v_tok_1001v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_224v_tok_224v_tok_604v_tok_126v_tok_904v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_475v_tok_25v_tok_317v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_982v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_565v_tok_971v_tok_753v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_666v_tok_709v_tok_148v_tok_176v_tok_463v_tok_819v_tok_463v_tok_709v_tok_709v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_479v_tok_479v_tok_504v_tok_411v_tok_479v_tok_479v_tok_730v_tok_57v_tok_453v_tok_868v_tok_922v_tok_408v_tok_835v_tok_876v_tok_782v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_999v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_475v_tok_940v_tok_858v_tok_912v_tok_533v_tok_890v_tok_890v_tok_502v_tok_890v_tok_424v_tok_1001v_tok_321v_tok_80v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_738v_tok_876v_tok_835v_tok_738v_tok_876v_tok_1011v_tok_709v_tok_463v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_709v_tok_339v_tok_709v_tok_339v_tok_835', 'v_tok_738v_tok_475v_tok_835v_tok_133v_tok_751v_tok_1008v_tok_411v_tok_411v_tok_479v_tok_479v_tok_411v_tok_411v_tok_411v_tok_782v_tok_453v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_747v_tok_358v_tok_808v_tok_881v_tok_942v_tok_942v_tok_942v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_347v_tok_133v_tok_133v_tok_738v_tok_835v_tok_738v_tok_835v_tok_339v_tok_602v_tok_906v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_502v_tok_23v_tok_931v_tok_23v_tok_901v_tok_185v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_62v_tok_408v_tok_408v_tok_835v_tok_791v_tok_709v_tok_463v_tok_709v_tok_25v_tok_463v_tok_709v_tok_709v_tok_395v_tok_339v_tok_475v_tok_475v_tok_475</s>', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_944v_tok_479v_tok_479v_tok_479v_tok_790v_tok_479v_tok_479v_tok_755v_tok_233v_tok_575v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_997v_tok_378v_tok_808v_tok_291v_tok_523v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_23v_tok_1001v_tok_1001v_tok_208v_tok_563v_tok_1001v_tok_690v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_339v_tok_339v_tok_635v_tok_479v_tok_151v_tok_151v_tok_871v_tok_151v_tok_651v_tok_151v_tok_502v_tok_901v_tok_950v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_699v_tok_976v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_475v_tok_791v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_463v_tok_463v_tok_475v_tok_339v_tok_339v_tok_709v_tok_339</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_136v_tok_1008v_tok_411v_tok_479v_tok_846v_tok_479v_tok_479v_tok_479v_tok_411v_tok_1018v_tok_453v_tok_868v_tok_922v_tok_835v_tok_133v_tok_835v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_722v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_432v_tok_904v_tok_133v_tok_133v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_126v_tok_502v_tok_407v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_151v_tok_502v_tok_598v_tok_495v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_565v_tok_967v_tok_224v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_408v_tok_408v_tok_738v_tok_738v_tok_666v_tok_176v_tok_176v_tok_176v_tok_25v_tok_463v_tok_463v_tok_176v_tok_463v_tok_819v_tok_709v_tok_709v_tok_339', 'v_tok_738v_tok_835v_tok_835v_tok_408v_tok_751v_tok_1008v_tok_411v_tok_980v_tok_59v_tok_411v_tok_411v_tok_782v_tok_588v_tok_796v_tok_850v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_747v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_843v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_598v_tok_690v_tok_699v_tok_430v_tok_126v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_395v_tok_465v_tok_465v_tok_465v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_690v_tok_1008v_tok_955v_tok_291v_tok_523v_tok_1022v_tok_565v_tok_323v_tok_967v_tok_432v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_106v_tok_1019v_tok_339v_tok_967v_tok_709v_tok_463v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_126v_tok_126v_tok_395v_tok_855', 'v_tok_738v_tok_835v_tok_835v_tok_408v_tok_751v_tok_1008v_tok_411v_tok_980v_tok_59v_tok_411v_tok_411v_tok_782v_tok_588v_tok_796v_tok_850v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_747v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_843v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_598v_tok_690v_tok_699v_tok_430v_tok_126v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_395v_tok_465v_tok_465v_tok_465v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_690v_tok_1008v_tok_955v_tok_291v_tok_523v_tok_1022v_tok_565v_tok_323v_tok_967v_tok_432v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_835v_tok_106v_tok_1019v_tok_339v_tok_967v_tok_709v_tok_463v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_126v_tok_126v_tok_395v_tok_855', 'v_tok_738v_tok_126v_tok_835v_tok_126v_tok_967v_tok_561v_tok_584v_tok_479v_tok_479v_tok_479v_tok_99v_tok_59v_tok_502v_tok_479v_tok_453v_tok_881v_tok_922v_tok_876v_tok_835v_tok_126v_tok_411v_tok_358v_tok_112v_tok_561v_tok_942v_tok_942v_tok_901v_tok_901v_tok_495v_tok_565v_tok_890v_tok_598v_tok_530v_tok_530v_tok_860v_tok_1001v_tok_224v_tok_604v_tok_430v_tok_126v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_835v_tok_876v_tok_126v_tok_502v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_890v_tok_151v_tok_136v_tok_155v_tok_967v_tok_402v_tok_291v_tok_155v_tok_971v_tok_565v_tok_879v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_876v_tok_126v_tok_635v_tok_709v_tok_176v_tok_819v_tok_25v_tok_463v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_106v_tok_339</s>', 'v_tok_835v_tok_475v_tok_835v_tok_475v_tok_131v_tok_967v_tok_479v_tok_535v_tok_479v_tok_939v_tok_479v_tok_479v_tok_479v_tok_388v_tok_453v_tok_881v_tok_922v_tok_835v_tok_475v_tok_834v_tok_747v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_942v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_475v_tok_843v_tok_479v_tok_317v_tok_151v_tok_151v_tok_23v_tok_502v_tok_598v_tok_151v_tok_598v_tok_495v_tok_666v_tok_495v_tok_971v_tok_879v_tok_971v_tok_971v_tok_224v_tok_491v_tok_604v_tok_699v_tok_1019v_tok_876v_tok_1019v_tok_835v_tok_835v_tok_876v_tok_835v_tok_835v_tok_499v_tok_709v_tok_176v_tok_537v_tok_176v_tok_339v_tok_25v_tok_709v_tok_819v_tok_339v_tok_339v_tok_339v_tok_395</s><pad><pad>', 'v_tok_106v_tok_835v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_465v_tok_479v_tok_479v_tok_479v_tok_411v_tok_939v_tok_939v_tok_465v_tok_453v_tok_871v_tok_865v_tok_835v_tok_106v_tok_876v_tok_411v_tok_796v_tok_808v_tok_291v_tok_925v_tok_942v_tok_925v_tok_505v_tok_415v_tok_23v_tok_890v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_1017v_tok_432v_tok_133v_tok_1017v_tok_835v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_151v_tok_906v_tok_906v_tok_151v_tok_151v_tok_931v_tok_502v_tok_833v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_523v_tok_523v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_738v_tok_835v_tok_499v_tok_463v_tok_160v_tok_463v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_339v_tok_339v_tok_257v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_967v_tok_912v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_388v_tok_59v_tok_782v_tok_931v_tok_922v_tok_1019v_tok_1017v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_598v_tok_505v_tok_415v_tok_1001v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_224v_tok_224v_tok_604v_tok_126v_tok_904v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_475v_tok_25v_tok_317v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_982v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_565v_tok_971v_tok_753v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_666v_tok_709v_tok_148v_tok_176v_tok_463v_tok_819v_tok_463v_tok_709v_tok_709v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_106v_tok_835v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_465v_tok_479v_tok_479v_tok_479v_tok_411v_tok_939v_tok_939v_tok_465v_tok_453v_tok_871v_tok_865v_tok_835v_tok_106v_tok_876v_tok_411v_tok_796v_tok_808v_tok_291v_tok_925v_tok_942v_tok_925v_tok_505v_tok_415v_tok_23v_tok_890v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_1017v_tok_432v_tok_133v_tok_1017v_tok_835v_tok_133v_tok_835v_tok_835v_tok_1017v_tok_151v_tok_906v_tok_906v_tok_151v_tok_151v_tok_931v_tok_502v_tok_833v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_523v_tok_523v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_738v_tok_835v_tok_499v_tok_463v_tok_160v_tok_463v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_339v_tok_339v_tok_257v_tok_835</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_411v_tok_535v_tok_535v_tok_790v_tok_479v_tok_479v_tok_479v_tok_588v_tok_796v_tok_881v_tok_922v_tok_835v_tok_106v_tok_876v_tok_233v_tok_850v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_855v_tok_126v_tok_126v_tok_106v_tok_835v_tok_835v_tok_339v_tok_835v_tok_835v_tok_25v_tok_151v_tok_479v_tok_906v_tok_136v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_155v_tok_185v_tok_291v_tok_155v_tok_598v_tok_565v_tok_860v_tok_967v_tok_971v_tok_604v_tok_321v_tok_604v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_475v_tok_499v_tok_709v_tok_176v_tok_176v_tok_463v_tok_709v_tok_709v_tok_160v_tok_709v_tok_339v_tok_709v_tok_339v_tok_339</s><pad>'], 'rejected': ['v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_411v_tok_479v_tok_479v_tok_479v_tok_782v_tok_730v_tok_884v_tok_939v_tok_881v_tok_865v_tok_475v_tok_835v_tok_876v_tok_213v_tok_203v_tok_808v_tok_291v_tok_881v_tok_942v_tok_598v_tok_505v_tok_415v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_835v_tok_876v_tok_835v_tok_133v_tok_395v_tok_502v_tok_906v_tok_151v_tok_151v_tok_151v_tok_890v_tok_424v_tok_151v_tok_502v_tok_598v_tok_666v_tok_666v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_879v_tok_323v_tok_967v_tok_971v_tok_136v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_835v_tok_276v_tok_709v_tok_463v_tok_709v_tok_176v_tok_463v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_881v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_479v_tok_939v_tok_197v_tok_858v_tok_865v_tok_876v_tok_738v_tok_876v_tok_213v_tok_203v_tok_808v_tok_424v_tok_942v_tok_942v_tok_306v_tok_945v_tok_598v_tok_424v_tok_563v_tok_1001v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_699v_tok_430v_tok_876v_tok_834v_tok_133v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_25v_tok_906v_tok_1000v_tok_151v_tok_151v_tok_151v_tok_321v_tok_931v_tok_457v_tok_967v_tok_598v_tok_563v_tok_155v_tok_690v_tok_136v_tok_598v_tok_323v_tok_967v_tok_971v_tok_604v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_834v_tok_835v_tok_408v_tok_835v_tok_835v_tok_475v_tok_666v_tok_709v_tok_463v_tok_25v_tok_25v_tok_463v_tok_463v_tok_463v_tok_819v_tok_463v_tok_339v_tok_339v_tok_339v_tok_835</s><pad><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_651v_tok_57v_tok_535v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_57v_tok_850v_tok_457v_tok_922v_tok_835v_tok_835v_tok_126v_tok_385v_tok_288v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_505v_tok_495v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_133v_tok_408v_tok_835v_tok_339v_tok_602v_tok_59v_tok_59v_tok_151v_tok_151v_tok_151v_tok_901v_tok_563v_tok_424v_tok_901v_tok_666v_tok_690v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_876v_tok_666v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_395v_tok_709v_tok_709v_tok_25v_tok_339v_tok_339v_tok_835</s>', 'v_tok_1017v_tok_835v_tok_1017v_tok_321v_tok_1008v_tok_796v_tok_479v_tok_479v_tok_479v_tok_914v_tok_388v_tok_317v_tok_431v_tok_59v_tok_453v_tok_881v_tok_922v_tok_1017v_tok_835v_tok_1019v_tok_951v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_563v_tok_23v_tok_495v_tok_151v_tok_1001v_tok_1001v_tok_563v_tok_1001v_tok_971v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_133v_tok_835v_tok_835v_tok_835v_tok_475v_tok_907v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_23v_tok_151v_tok_502v_tok_901v_tok_457v_tok_523v_tok_291v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_753v_tok_325v_tok_224v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_1017v_tok_876v_tok_935v_tok_25v_tok_148v_tok_463v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_106v_tok_835v_tok_835v_tok_133v_tok_751v_tok_1008v_tok_453v_tok_562v_tok_646v_tok_479v_tok_479v_tok_479v_tok_431v_tok_1000v_tok_939v_tok_881v_tok_922v_tok_835v_tok_835v_tok_1017v_tok_747v_tok_358v_tok_808v_tok_291v_tok_690v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_495v_tok_563v_tok_807v_tok_1001v_tok_563v_tok_1001v_tok_860v_tok_208v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_876v_tok_738v_tok_1019v_tok_1019v_tok_843v_tok_1000v_tok_317v_tok_495v_tok_151v_tok_151v_tok_563v_tok_151v_tok_424v_tok_598v_tok_23v_tok_833v_tok_523v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_876v_tok_1019v_tok_876v_tok_106v_tok_738v_tok_738v_tok_1017v_tok_635v_tok_463v_tok_463v_tok_25v_tok_709v_tok_25v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_411v_tok_479v_tok_479v_tok_479v_tok_782v_tok_730v_tok_884v_tok_939v_tok_881v_tok_865v_tok_475v_tok_835v_tok_876v_tok_213v_tok_203v_tok_808v_tok_291v_tok_881v_tok_942v_tok_598v_tok_505v_tok_415v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_228v_tok_133v_tok_835v_tok_835v_tok_876v_tok_835v_tok_133v_tok_395v_tok_502v_tok_906v_tok_151v_tok_151v_tok_151v_tok_890v_tok_424v_tok_151v_tok_502v_tok_598v_tok_666v_tok_666v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_879v_tok_323v_tok_967v_tok_971v_tok_136v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_835v_tok_276v_tok_709v_tok_463v_tok_709v_tok_176v_tok_463v_tok_463v_tok_339v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_747v_tok_846v_tok_479v_tok_59v_tok_59v_tok_479v_tok_479v_tok_59v_tok_796v_tok_881v_tok_922v_tok_1019v_tok_408v_tok_999v_tok_233v_tok_358v_tok_808v_tok_291v_tok_936v_tok_942v_tok_931v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_843v_tok_583v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_876v_tok_347v_tok_133v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_126v_tok_495v_tok_906v_tok_317v_tok_906v_tok_151v_tok_151v_tok_502v_tok_151v_tok_151v_tok_598v_tok_890v_tok_843v_tok_185v_tok_291v_tok_155v_tok_1001v_tok_565v_tok_753v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1019v_tok_738v_tok_835v_tok_835v_tok_935v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_819v_tok_339v_tok_339v_tok_475v_tok_339</s>', 'v_tok_738v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_59v_tok_479v_tok_479v_tok_593v_tok_59v_tok_939v_tok_388v_tok_939v_tok_556v_tok_881v_tok_922v_tok_408v_tok_408v_tok_876v_tok_747v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_690v_tok_505v_tok_23v_tok_23v_tok_23v_tok_530v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_395v_tok_502v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_860v_tok_424v_tok_598v_tok_457v_tok_523v_tok_23v_tok_523v_tok_563v_tok_1001v_tok_323v_tok_860v_tok_91v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_855v_tok_835v_tok_835v_tok_738v_tok_738v_tok_835v_tok_323v_tok_709v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_709v_tok_395v_tok_339v_tok_395v_tok_339v_tok_339</s><pad>', 'v_tok_738v_tok_738v_tok_408v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_411v_tok_233v_tok_431v_tok_730v_tok_912v_tok_936v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_11v_tok_11v_tok_291v_tok_690v_tok_942v_tok_942v_tok_505v_tok_901v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_25v_tok_502v_tok_588v_tok_317v_tok_151v_tok_23v_tok_151v_tok_502v_tok_151v_tok_502v_tok_598v_tok_495v_tok_764v_tok_1022v_tok_523v_tok_860v_tok_323v_tok_565v_tok_323v_tok_971v_tok_753v_tok_971v_tok_699v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_835v_tok_738v_tok_738v_tok_738v_tok_835v_tok_935v_tok_339v_tok_463v_tok_25v_tok_463v_tok_339v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339v_tok_395v_tok_339</s><pad>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_479v_tok_479v_tok_411v_tok_479v_tok_99v_tok_99v_tok_411v_tok_886v_tok_796v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_411v_tok_358v_tok_808v_tok_881v_tok_925v_tok_942v_tok_598v_tok_143v_tok_679v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_155v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_430v_tok_408v_tok_408v_tok_738v_tok_835v_tok_835v_tok_940v_tok_906v_tok_502v_tok_151v_tok_151v_tok_151v_tok_598v_tok_495v_tok_502v_tok_598v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_690v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_738v_tok_835v_tok_408v_tok_835v_tok_876v_tok_777v_tok_339v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s><pad>', 'v_tok_1017v_tok_835v_tok_1017v_tok_321v_tok_1008v_tok_796v_tok_479v_tok_479v_tok_479v_tok_914v_tok_388v_tok_317v_tok_431v_tok_59v_tok_453v_tok_881v_tok_922v_tok_1017v_tok_835v_tok_1019v_tok_951v_tok_358v_tok_185v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_563v_tok_23v_tok_495v_tok_151v_tok_1001v_tok_1001v_tok_563v_tok_1001v_tok_971v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_133v_tok_835v_tok_835v_tok_835v_tok_475v_tok_907v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_23v_tok_151v_tok_502v_tok_901v_tok_457v_tok_523v_tok_291v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_753v_tok_325v_tok_224v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_1017v_tok_876v_tok_935v_tok_25v_tok_148v_tok_463v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_835v_tok_408v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_233v_tok_479v_tok_479v_tok_479v_tok_939v_tok_912v_tok_646v_tok_479v_tok_796v_tok_881v_tok_410v_tok_835v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_523v_tok_505v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_224v_tok_890v_tok_1001v_tok_224v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_602v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_931v_tok_151v_tok_502v_tok_23v_tok_901v_tok_523v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_565v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_339v_tok_565v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_339v_tok_339v_tok_395</s>', 'v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_1018v_tok_411v_tok_479v_tok_479v_tok_782v_tok_958v_tok_922v_tok_835v_tok_835v_tok_876v_tok_189v_tok_358v_tok_808v_tok_291v_tok_936v_tok_942v_tok_11v_tok_505v_tok_23v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_1017v_tok_339v_tok_408v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_958v_tok_479v_tok_151v_tok_151v_tok_151v_tok_875v_tok_502v_tok_151v_tok_944v_tok_901v_tok_523v_tok_155v_tok_1022v_tok_155v_tok_323v_tok_1022v_tok_323v_tok_967v_tok_491v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_62v_tok_835v_tok_835v_tok_738v_tok_499v_tok_709v_tok_25v_tok_709v_tok_176v_tok_339v_tok_176v_tok_709v_tok_395v_tok_339v_tok_339v_tok_709v_tok_475</s><pad><pad>', 'v_tok_835v_tok_408v_tok_835v_tok_835v_tok_751v_tok_1008v_tok_233v_tok_479v_tok_479v_tok_479v_tok_939v_tok_912v_tok_646v_tok_479v_tok_796v_tok_881v_tok_410v_tok_835v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_523v_tok_505v_tok_415v_tok_23v_tok_23v_tok_807v_tok_1001v_tok_224v_tok_890v_tok_1001v_tok_224v_tok_224v_tok_430v_tok_126v_tok_724v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_602v_tok_479v_tok_906v_tok_151v_tok_151v_tok_151v_tok_931v_tok_151v_tok_502v_tok_23v_tok_901v_tok_523v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_565v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_738v_tok_738v_tok_339v_tok_565v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_395v_tok_395v_tok_395v_tok_339v_tok_339v_tok_339v_tok_395</s>', 'v_tok_835v_tok_835v_tok_835v_tok_126v_tok_751v_tok_651v_tok_584v_tok_568v_tok_479v_tok_479v_tok_782v_tok_479v_tok_479v_tok_588v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_213v_tok_451v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_860v_tok_126v_tok_779v_tok_133v_tok_133v_tok_835v_tok_835v_tok_106v_tok_835v_tok_25v_tok_502v_tok_59v_tok_502v_tok_151v_tok_151v_tok_151v_tok_502v_tok_890v_tok_1001v_tok_901v_tok_533v_tok_185v_tok_833v_tok_523v_tok_155v_tok_323v_tok_30v_tok_323v_tok_523v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_791v_tok_176v_tok_463v_tok_537v_tok_176v_tok_463v_tok_176v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_475</s><pad>', 'v_tok_835v_tok_738v_tok_738v_tok_835v_tok_751v_tok_182v_tok_233v_tok_479v_tok_479v_tok_479v_tok_790v_tok_57v_tok_388v_tok_400v_tok_796v_tok_881v_tok_410v_tok_835v_tok_835v_tok_876v_tok_431v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_1001v_tok_495v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_602v_tok_906v_tok_727v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_901v_tok_523v_tok_523v_tok_155v_tok_323v_tok_323v_tok_323v_tok_1011v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_106v_tok_1017v_tok_408v_tok_738v_tok_738v_tok_738v_tok_73v_tok_709v_tok_463v_tok_176v_tok_463v_tok_463v_tok_339v_tok_709v_tok_395v_tok_395v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_751v_tok_255v_tok_479v_tok_479v_tok_411v_tok_479v_tok_99v_tok_99v_tok_411v_tok_886v_tok_796v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_411v_tok_358v_tok_808v_tok_881v_tok_925v_tok_942v_tok_598v_tok_143v_tok_679v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_155v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_430v_tok_408v_tok_408v_tok_738v_tok_835v_tok_835v_tok_940v_tok_906v_tok_502v_tok_151v_tok_151v_tok_151v_tok_598v_tok_495v_tok_502v_tok_598v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_690v_tok_323v_tok_565v_tok_323v_tok_1001v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_738v_tok_835v_tok_408v_tok_835v_tok_876v_tok_777v_tok_339v_tok_463v_tok_176v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_339v_tok_339v_tok_835</s><pad>', 'v_tok_106v_tok_835v_tok_835v_tok_133v_tok_751v_tok_1008v_tok_453v_tok_562v_tok_646v_tok_479v_tok_479v_tok_479v_tok_431v_tok_1000v_tok_939v_tok_881v_tok_922v_tok_835v_tok_835v_tok_1017v_tok_747v_tok_358v_tok_808v_tok_291v_tok_690v_tok_942v_tok_901v_tok_23v_tok_23v_tok_23v_tok_495v_tok_563v_tok_807v_tok_1001v_tok_563v_tok_1001v_tok_860v_tok_208v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_876v_tok_738v_tok_1019v_tok_1019v_tok_843v_tok_1000v_tok_317v_tok_495v_tok_151v_tok_151v_tok_563v_tok_151v_tok_424v_tok_598v_tok_23v_tok_833v_tok_523v_tok_291v_tok_155v_tok_323v_tok_323v_tok_323v_tok_967v_tok_971v_tok_491v_tok_321v_tok_1019v_tok_432v_tok_876v_tok_1019v_tok_876v_tok_106v_tok_738v_tok_738v_tok_1017v_tok_635v_tok_463v_tok_463v_tok_25v_tok_709v_tok_25v_tok_395v_tok_709v_tok_709v_tok_709v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1019v_tok_751v_tok_651v_tok_57v_tok_535v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_57v_tok_850v_tok_457v_tok_922v_tok_835v_tok_835v_tok_126v_tok_385v_tok_288v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_505v_tok_495v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_133v_tok_408v_tok_835v_tok_339v_tok_602v_tok_59v_tok_59v_tok_151v_tok_151v_tok_151v_tok_901v_tok_563v_tok_424v_tok_901v_tok_666v_tok_690v_tok_155v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_432v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_876v_tok_666v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_395v_tok_709v_tok_709v_tok_25v_tok_339v_tok_339v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_59v_tok_502v_tok_431v_tok_411v_tok_788v_tok_453v_tok_881v_tok_865v_tok_738v_tok_835v_tok_876v_tok_358v_tok_203v_tok_808v_tok_291v_tok_936v_tok_942v_tok_921v_tok_495v_tok_942v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_753v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_395v_tok_317v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_523v_tok_523v_tok_901v_tok_690v_tok_1008v_tok_185v_tok_523v_tok_523v_tok_565v_tok_565v_tok_323v_tok_325v_tok_604v_tok_491v_tok_879v_tok_1019v_tok_126v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_738v_tok_835v_tok_666v_tok_709v_tok_463v_tok_395v_tok_709v_tok_463v_tok_25v_tok_463v_tok_819v_tok_339v_tok_709v_tok_339v_tok_339</s>', 'v_tok_738v_tok_835v_tok_738v_tok_876v_tok_751v_tok_967v_tok_358v_tok_411v_tok_479v_tok_479v_tok_479v_tok_688v_tok_317v_tok_479v_tok_453v_tok_881v_tok_922v_tok_738v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_944v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_126v_tok_52v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_677v_tok_479v_tok_23v_tok_151v_tok_860v_tok_871v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_495v_tok_185v_tok_291v_tok_155v_tok_323v_tok_860v_tok_323v_tok_1010v_tok_879v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_738v_tok_738v_tok_835v_tok_339v_tok_666v_tok_395v_tok_176v_tok_395v_tok_395v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_709v_tok_339v_tok_339', 'v_tok_738v_tok_835v_tok_738v_tok_876v_tok_751v_tok_967v_tok_358v_tok_411v_tok_479v_tok_479v_tok_479v_tok_688v_tok_317v_tok_479v_tok_453v_tok_881v_tok_922v_tok_738v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_944v_tok_23v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_126v_tok_52v_tok_133v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_677v_tok_479v_tok_23v_tok_151v_tok_860v_tok_871v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_495v_tok_185v_tok_291v_tok_155v_tok_323v_tok_860v_tok_323v_tok_1010v_tok_879v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_738v_tok_738v_tok_835v_tok_339v_tok_666v_tok_395v_tok_176v_tok_395v_tok_395v_tok_463v_tok_709v_tok_709v_tok_709v_tok_395v_tok_709v_tok_339v_tok_339', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_881v_tok_479v_tok_479v_tok_479v_tok_411v_tok_479v_tok_479v_tok_939v_tok_197v_tok_858v_tok_865v_tok_876v_tok_738v_tok_876v_tok_213v_tok_203v_tok_808v_tok_424v_tok_942v_tok_942v_tok_306v_tok_945v_tok_598v_tok_424v_tok_563v_tok_1001v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_699v_tok_430v_tok_876v_tok_834v_tok_133v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_835v_tok_25v_tok_906v_tok_1000v_tok_151v_tok_151v_tok_151v_tok_321v_tok_931v_tok_457v_tok_967v_tok_598v_tok_563v_tok_155v_tok_690v_tok_136v_tok_598v_tok_323v_tok_967v_tok_971v_tok_604v_tok_879v_tok_1019v_tok_432v_tok_1019v_tok_834v_tok_835v_tok_408v_tok_835v_tok_835v_tok_475v_tok_666v_tok_709v_tok_463v_tok_25v_tok_25v_tok_463v_tok_463v_tok_463v_tok_819v_tok_463v_tok_339v_tok_339v_tok_339v_tok_835</s><pad><pad>', 'v_tok_738v_tok_738v_tok_408v_tok_876v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_411v_tok_233v_tok_431v_tok_730v_tok_912v_tok_936v_tok_922v_tok_835v_tok_835v_tok_876v_tok_951v_tok_11v_tok_11v_tok_291v_tok_690v_tok_942v_tok_942v_tok_505v_tok_901v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_321v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_25v_tok_502v_tok_588v_tok_317v_tok_151v_tok_23v_tok_151v_tok_502v_tok_151v_tok_502v_tok_598v_tok_495v_tok_764v_tok_1022v_tok_523v_tok_860v_tok_323v_tok_565v_tok_323v_tok_971v_tok_753v_tok_971v_tok_699v_tok_1019v_tok_432v_tok_1019v_tok_876v_tok_835v_tok_738v_tok_738v_tok_738v_tok_835v_tok_935v_tok_339v_tok_463v_tok_25v_tok_463v_tok_339v_tok_339v_tok_339v_tok_709v_tok_339v_tok_339v_tok_395v_tok_339</s><pad>', 'v_tok_408v_tok_408v_tok_738v_tok_876v_tok_751v_tok_1008v_tok_886v_tok_846v_tok_846v_tok_479v_tok_479v_tok_755v_tok_479v_tok_782v_tok_796v_tok_751v_tok_922v_tok_876v_tok_738v_tok_876v_tok_431v_tok_358v_tok_808v_tok_291v_tok_881v_tok_942v_tok_925v_tok_505v_tok_23v_tok_23v_tok_945v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_133v_tok_661v_tok_906v_tok_906v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_690v_tok_881v_tok_871v_tok_291v_tok_155v_tok_860v_tok_565v_tok_871v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_738v_tok_835v_tok_565v_tok_463v_tok_463v_tok_709v_tok_463v_tok_25v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_835v_tok_709v_tok_835</s>', 'v_tok_835v_tok_738v_tok_738v_tok_835v_tok_751v_tok_182v_tok_233v_tok_479v_tok_479v_tok_479v_tok_790v_tok_57v_tok_388v_tok_400v_tok_796v_tok_881v_tok_410v_tok_835v_tok_835v_tok_876v_tok_431v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_1001v_tok_495v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_602v_tok_906v_tok_727v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_495v_tok_901v_tok_523v_tok_523v_tok_155v_tok_323v_tok_323v_tok_323v_tok_1011v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_106v_tok_1017v_tok_408v_tok_738v_tok_738v_tok_738v_tok_73v_tok_709v_tok_463v_tok_176v_tok_463v_tok_463v_tok_339v_tok_709v_tok_395v_tok_395v_tok_339v_tok_339v_tok_339v_tok_835', 'v_tok_408v_tok_408v_tok_738v_tok_876v_tok_751v_tok_1008v_tok_886v_tok_846v_tok_846v_tok_479v_tok_479v_tok_755v_tok_479v_tok_782v_tok_796v_tok_751v_tok_922v_tok_876v_tok_738v_tok_876v_tok_431v_tok_358v_tok_808v_tok_291v_tok_881v_tok_942v_tok_925v_tok_505v_tok_23v_tok_23v_tok_945v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_126v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_133v_tok_661v_tok_906v_tok_906v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_690v_tok_881v_tok_871v_tok_291v_tok_155v_tok_860v_tok_565v_tok_871v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_408v_tok_835v_tok_738v_tok_835v_tok_565v_tok_463v_tok_463v_tok_709v_tok_463v_tok_25v_tok_463v_tok_709v_tok_709v_tok_709v_tok_339v_tok_835v_tok_709v_tok_835</s>', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_747v_tok_846v_tok_479v_tok_59v_tok_59v_tok_479v_tok_479v_tok_59v_tok_796v_tok_881v_tok_922v_tok_1019v_tok_408v_tok_999v_tok_233v_tok_358v_tok_808v_tok_291v_tok_936v_tok_942v_tok_931v_tok_505v_tok_415v_tok_23v_tok_495v_tok_598v_tok_843v_tok_583v_tok_860v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_876v_tok_347v_tok_133v_tok_835v_tok_835v_tok_408v_tok_835v_tok_835v_tok_126v_tok_495v_tok_906v_tok_317v_tok_906v_tok_151v_tok_151v_tok_502v_tok_151v_tok_151v_tok_598v_tok_890v_tok_843v_tok_185v_tok_291v_tok_155v_tok_1001v_tok_565v_tok_753v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_1019v_tok_738v_tok_835v_tok_835v_tok_935v_tok_463v_tok_463v_tok_709v_tok_463v_tok_463v_tok_463v_tok_339v_tok_819v_tok_339v_tok_339v_tok_475v_tok_339</s>']}\n",
      "val_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>', '<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_408v_tok_835v_tok_835v_tok_430v_tok_751v_tok_255v_tok_584v_tok_846v_tok_479v_tok_479v_tok_479v_tok_141v_tok_584v_tok_57v_tok_796v_tok_881v_tok_922v_tok_835v_tok_738v_tok_876v_tok_358v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_530v_tok_224v_tok_133v_tok_126v_tok_604v_tok_133v_tok_738v_tok_835v_tok_835v_tok_835v_tok_475v_tok_25v_tok_465v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_679v_tok_890v_tok_23v_tok_185v_tok_275v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_228v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_835v_tok_835v_tok_339v_tok_635v_tok_463v_tok_176v_tok_463v_tok_176v_tok_395v_tok_709v_tok_819v_tok_709v_tok_395v_tok_395v_tok_835</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_339v_tok_751v_tok_255v_tok_1018v_tok_479v_tok_479v_tok_479v_tok_99v_tok_348v_tok_796v_tok_796v_tok_928v_tok_942v_tok_922v_tok_855v_tok_835v_tok_835v_tok_694v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_942v_tok_890v_tok_505v_tok_23v_tok_945v_tok_563v_tok_1001v_tok_1001v_tok_321v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_133v_tok_835v_tok_835v_tok_738v_tok_876v_tok_779v_tok_502v_tok_479v_tok_151v_tok_151v_tok_151v_tok_136v_tok_651v_tok_136v_tok_926v_tok_901v_tok_155v_tok_155v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_523v_tok_971v_tok_971v_tok_321v_tok_604v_tok_432v_tok_876v_tok_339v_tok_835v_tok_835v_tok_106v_tok_835v_tok_835v_tok_323v_tok_339v_tok_463v_tok_709v_tok_463v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_709v_tok_339v_tok_835</s>', 'v_tok_835v_tok_835v_tok_1017v_tok_876v_tok_751v_tok_1008v_tok_790v_tok_568v_tok_755v_tok_790v_tok_479v_tok_694v_tok_479v_tok_479v_tok_453v_tok_944v_tok_922v_tok_835v_tok_835v_tok_876v_tok_372v_tok_358v_tok_808v_tok_291v_tok_561v_tok_942v_tok_901v_tok_901v_tok_495v_tok_1001v_tok_23v_tok_563v_tok_1001v_tok_530v_tok_143v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_835v_tok_835v_tok_475v_tok_835v_tok_835v_tok_395v_tok_317v_tok_317v_tok_901v_tok_321v_tok_151v_tok_151v_tok_502v_tok_906v_tok_276v_tok_598v_tok_151v_tok_658v_tok_523v_tok_23v_tok_155v_tok_523v_tok_565v_tok_976v_tok_967v_tok_325v_tok_753v_tok_879v_tok_604v_tok_432v_tok_1019v_tok_339v_tok_475v_tok_835v_tok_738v_tok_835v_tok_835v_tok_1014v_tok_463v_tok_148v_tok_176v_tok_709v_tok_463v_tok_709v_tok_709v_tok_395v_tok_339v_tok_339v_tok_339v_tok_835</s>', 'v_tok_408v_tok_835v_tok_835v_tok_835v_tok_136v_tok_1008v_tok_411v_tok_479v_tok_846v_tok_479v_tok_479v_tok_479v_tok_411v_tok_1018v_tok_453v_tok_868v_tok_922v_tok_835v_tok_133v_tok_835v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_722v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_432v_tok_904v_tok_133v_tok_133v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_126v_tok_502v_tok_407v_tok_317v_tok_151v_tok_151v_tok_151v_tok_598v_tok_151v_tok_502v_tok_598v_tok_495v_tok_1008v_tok_523v_tok_291v_tok_155v_tok_323v_tok_565v_tok_565v_tok_967v_tok_224v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_408v_tok_835v_tok_408v_tok_408v_tok_738v_tok_738v_tok_666v_tok_176v_tok_176v_tok_176v_tok_25v_tok_463v_tok_463v_tok_176v_tok_463v_tok_819v_tok_709v_tok_709v_tok_339'], 'rejected': ['v_tok_835v_tok_835v_tok_835v_tok_126v_tok_751v_tok_651v_tok_584v_tok_568v_tok_479v_tok_479v_tok_782v_tok_479v_tok_479v_tok_588v_tok_782v_tok_881v_tok_922v_tok_835v_tok_835v_tok_876v_tok_213v_tok_451v_tok_808v_tok_291v_tok_942v_tok_942v_tok_901v_tok_505v_tok_23v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_860v_tok_1001v_tok_860v_tok_860v_tok_126v_tok_779v_tok_133v_tok_133v_tok_835v_tok_835v_tok_106v_tok_835v_tok_25v_tok_502v_tok_59v_tok_502v_tok_151v_tok_151v_tok_151v_tok_502v_tok_890v_tok_1001v_tok_901v_tok_533v_tok_185v_tok_833v_tok_523v_tok_155v_tok_323v_tok_30v_tok_323v_tok_523v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_835v_tok_835v_tok_738v_tok_835v_tok_835v_tok_791v_tok_176v_tok_463v_tok_537v_tok_176v_tok_463v_tok_176v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_475</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_475v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_1018v_tok_411v_tok_479v_tok_479v_tok_782v_tok_958v_tok_922v_tok_835v_tok_835v_tok_876v_tok_189v_tok_358v_tok_808v_tok_291v_tok_936v_tok_942v_tok_11v_tok_505v_tok_23v_tok_23v_tok_563v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_860v_tok_224v_tok_430v_tok_126v_tok_432v_tok_1017v_tok_339v_tok_408v_tok_1019v_tok_835v_tok_835v_tok_1017v_tok_958v_tok_479v_tok_151v_tok_151v_tok_151v_tok_875v_tok_502v_tok_151v_tok_944v_tok_901v_tok_523v_tok_155v_tok_1022v_tok_155v_tok_323v_tok_1022v_tok_323v_tok_967v_tok_491v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_876v_tok_62v_tok_835v_tok_835v_tok_738v_tok_499v_tok_709v_tok_25v_tok_709v_tok_176v_tok_339v_tok_176v_tok_709v_tok_395v_tok_339v_tok_339v_tok_709v_tok_475</s><pad><pad>', 'v_tok_738v_tok_835v_tok_835v_tok_876v_tok_751v_tok_255v_tok_59v_tok_479v_tok_479v_tok_593v_tok_59v_tok_939v_tok_388v_tok_939v_tok_556v_tok_881v_tok_922v_tok_408v_tok_408v_tok_876v_tok_747v_tok_203v_tok_808v_tok_291v_tok_925v_tok_942v_tok_690v_tok_505v_tok_23v_tok_23v_tok_23v_tok_530v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_430v_tok_126v_tok_904v_tok_133v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_395v_tok_502v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_860v_tok_424v_tok_598v_tok_457v_tok_523v_tok_23v_tok_523v_tok_563v_tok_1001v_tok_323v_tok_860v_tok_91v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_855v_tok_835v_tok_835v_tok_738v_tok_738v_tok_835v_tok_323v_tok_709v_tok_463v_tok_339v_tok_463v_tok_339v_tok_339v_tok_709v_tok_395v_tok_339v_tok_395v_tok_339v_tok_339</s><pad>', 'v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_59v_tok_502v_tok_431v_tok_411v_tok_788v_tok_453v_tok_881v_tok_865v_tok_738v_tok_835v_tok_876v_tok_358v_tok_203v_tok_808v_tok_291v_tok_936v_tok_942v_tok_921v_tok_495v_tok_942v_tok_23v_tok_495v_tok_807v_tok_70v_tok_530v_tok_563v_tok_753v_tok_690v_tok_224v_tok_430v_tok_126v_tok_133v_tok_133v_tok_133v_tok_835v_tok_835v_tok_133v_tok_835v_tok_395v_tok_317v_tok_465v_tok_151v_tok_151v_tok_151v_tok_598v_tok_598v_tok_523v_tok_523v_tok_901v_tok_690v_tok_1008v_tok_185v_tok_523v_tok_523v_tok_565v_tok_565v_tok_323v_tok_325v_tok_604v_tok_491v_tok_879v_tok_1019v_tok_126v_tok_1019v_tok_835v_tok_835v_tok_738v_tok_738v_tok_738v_tok_835v_tok_666v_tok_709v_tok_463v_tok_395v_tok_709v_tok_463v_tok_25v_tok_463v_tok_819v_tok_339v_tok_709v_tok_339v_tok_339</s>']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 28/28 [00:00<00:00, 1100.87 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 371.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-1846/example_save_eval_1_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 28/28 [00:00<00:00, 948.06 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 542.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-1846/example_save_eval_2_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 28/28 [00:00<00:00, 1116.23 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 401.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-1846/example_save_eval_3_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f4157bd6d40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/b0990106x/miniconda3/envs/trl/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "disable_tqdm = not os.isatty(1)\n",
    "for iteration in tqdm(range(num_iterations), desc=\"Training Iterations\", disable=disable_tqdm):\n",
    "    logging.info(f\"-----------Starting iteration {iteration}-----------\")\n",
    "    \n",
    "    # resume = iteration > 0 # resume from the previous checkpoint when iteration > 0\n",
    "    resume = False\n",
    "    \n",
    "    # model_checkpoint is the model checkpoint from the previous iteration\n",
    "    # chosen_rewards and rejected_rewards are the rewards of the data\n",
    "    model_checkpoint, chosen_rewards, rejected_rewards = train_iteration(model,\n",
    "                                model_checkpoint,\n",
    "                                iteration=iteration,\n",
    "                                data_size=data_size_per_iteration,\n",
    "                                sample_size=sample_size,\n",
    "                                ar_model=ar_model,\n",
    "                                ar_tokenizer=ar_tokenizer,\n",
    "                                nar_model=nar_model,\n",
    "                                nar_tokenizer=nar_tokenizer,\n",
    "                                all_src_encodec=batch_src_encodec,\n",
    "                                all_instruction=batch_instruction,\n",
    "                                args_predict=args_predict,\n",
    "                                agent_output_dir=agent_output_dir,\n",
    "                                model_output_dir_base=model_output_dir,\n",
    "                                temperature = 1.0,\n",
    "                                beta=beta,\n",
    "                                base_path=base_path,\n",
    "                                resume_from_checkpoint=resume, \n",
    "                                learning_rate=learning_rate,\n",
    "                                num_train_epochs=num_train_epochs,\n",
    "                                max_length=max_length,\n",
    "                                max_prompt_length=max_prompt_length,\n",
    "                                max_target_length=max_target_length,\n",
    "                                per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                                seed=seed,\n",
    "                                clap_model=clap_model,\n",
    "                                accelerator=accelerator\n",
    "                                )       \n",
    "\n",
    "    logging.info(f\"Chosen rewards for iteration {iteration}: {chosen_rewards}\")\n",
    "    logging.info(f\"Rejected rewards for iteration {iteration}: {rejected_rewards}\")\n",
    "    logging.info(f\"Finished training iteration {iteration}\")\n",
    "\n",
    "    if (iteration+1) % eval_frequency == 0:\n",
    "    # Evaluate the result of the current iteration\n",
    "        if eval_train:\n",
    "            # eval dpo claps\n",
    "            # trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "            #                                                             ar_tokenizer=ar_tokenizer,\n",
    "            #                                                             nar_tokenizer=nar_tokenizer,\n",
    "            #                                                             trained_model=model,\n",
    "            #                                                             args_predict=args_predict,\n",
    "            #                                                             all_src_encodec=selected_src_encodec,\n",
    "            #                                                             all_instruction=selected_instruction,\n",
    "            #                                                             iteration = iteration,\n",
    "            #                                                             num_evaluations = num_eval,\n",
    "            #                                                             eval_data_len=eval_train_data_len,\n",
    "            #                                                             selected_indices=eval_train_indices,\n",
    "            #                                                             device=device,\n",
    "            #                                                             clap_model=clap_model,\n",
    "            #                                                             accelerator=accelerator\n",
    "            #                                                             )\n",
    "            # logging.info(f\"Trained Model Iteration {iteration} Train Set Evaluation: \")\n",
    "            # logging.info(f\"EVAL: Cosine_Sim metrics Training Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            # logging.info(f\"EVAL: Cosine_Sim score Training Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "            \n",
    "            # eval dpo mos\n",
    "            trained_model_metrics_mos, trained_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_train_data_len,\n",
    "                                                                        selected_indices=eval_train_indices,\n",
    "                                                                        device=device\n",
    "                                                                        )\n",
    "            logging.info(f\"EVAL: MOS metrics Training Set for iteration {iteration}: {trained_model_metrics_mos}\")\n",
    "            logging.info(f\"EVAL: MOS score Training Set for iteration {iteration}: {trained_model_rewards_mos}\")\n",
    "            \n",
    "            # reward_list = []\n",
    "            # for rewards in trained_model_rewards:\n",
    "            #     filter_rewards = [r for r in rewards if r is not None]\n",
    "            #     if len(filter_rewards) == 0:\n",
    "            #         reward_list.append(None)\n",
    "            #     else:\n",
    "            #         reward_list.append(np.mean(filter_rewards))\n",
    "            # logging.info(f\"EVAL: Trained model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "            reward_list_mos = []\n",
    "            for rewards in trained_model_rewards_mos:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list_mos.append(None)\n",
    "                else:\n",
    "                    reward_list_mos.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model MOS score list on training set: {reward_list_mos}\")\n",
    "            \n",
    "            # filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            # if len(filter_reward_list) != 0:\n",
    "            #     logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: {np.mean(filter_reward_list)}\")\n",
    "            # else:\n",
    "            #     logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: None\")\n",
    "            \n",
    "            filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "            if len(filter_reward_list_mos) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: {np.mean(filter_reward_list_mos)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: None\")\n",
    "                \n",
    "            # weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "            weighted_reward = np.mean(filter_reward_list_mos)/5\n",
    "            logging.info(f\"EVAL: Trained model weighted average score on training set for iteration {iteration}: {weighted_reward}\")\n",
    "\n",
    "        if eval_test:\n",
    "            trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_test_data_len,\n",
    "                                                                        selected_indices=eval_test_indices,\n",
    "                                                                        device=device,\n",
    "                                                                        clap_model=clap_model,\n",
    "                                                                        accelerator=accelerator\n",
    "                                                                        )\n",
    "            logging.info(f\"Trained Model Iteration {iteration} Test Set Evaluation: \")\n",
    "            logging.info(f\"EVAL: Cosine_Sim metrics Testing Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            logging.info(f\"EVAL: Cosine_Sim score Testing Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "\n",
    "            reward_list = []\n",
    "            for rewards in trained_model_rewards:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list.append(None)\n",
    "                else:\n",
    "                    reward_list.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model Cosine_Sim score list on testing set: {reward_list}\")\n",
    "            filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            if len(filter_reward_list) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: {np.mean(filter_reward_list)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: None\")\n",
    "\n",
    "    logging.info(f\"-----------Finished iteration {iteration}-----------\")\n",
    "total_end_time = time.time()\n",
    "\n",
    "# Calculate total time taken\n",
    "total_time_taken = total_end_time - total_start_time\n",
    "logging.info(f\"Total time taken for the entire process: {total_time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Function to parse the log file for both EVAL and Original model metrics\n",
    "def parse_log_file(log_path):\n",
    "    eval_pattern = re.compile(\n",
    "        r\"EVAL: Cosine_Sim metrics Training Set for iteration (\\d+): (.+)\"\n",
    "    )\n",
    "    original_model_pattern = re.compile(\n",
    "        r\"Original model metrics on training set: (.+)\"\n",
    "    )\n",
    "    \n",
    "    data = {\"EVAL\": {}, \"Original\": []}\n",
    "\n",
    "    # Read the log file line by line\n",
    "    with open(log_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            eval_match = eval_pattern.search(line)\n",
    "            original_match = original_model_pattern.search(line)\n",
    "\n",
    "            # If it's an EVAL line\n",
    "            if eval_match:\n",
    "                iteration = int(eval_match.group(1)) + 1  # Adding 1 to iteration as requested\n",
    "                metrics_list = eval_match.group(2).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                # Store means and std_devs for this iteration\n",
    "                means = []\n",
    "                std_devs = []\n",
    "                counts = []\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    count = len(metrics['metrics']['rewards'])  # Number of rewards is the sample size\n",
    "\n",
    "                    means.append(mean)\n",
    "                    std_devs.append(std_dev)\n",
    "                    counts.append(count)\n",
    "\n",
    "                # Store mean, std_dev, and count for each iteration\n",
    "                data[\"EVAL\"][iteration] = {\n",
    "                    \"means\": means,\n",
    "                    \"std_devs\": std_devs,\n",
    "                    \"counts\": counts\n",
    "                }\n",
    "\n",
    "            # If it's an Original Model Metrics line\n",
    "            elif original_match:\n",
    "                metrics_list = original_match.group(1).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    data[\"Original\"].append((mean, std_dev))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to calculate the pooled standard deviation\n",
    "def pooled_std_dev(std_devs, counts):\n",
    "    # Pooled variance formula\n",
    "    numerator = sum((counts[i] - 1) * (std_devs[i] ** 2) for i in range(len(std_devs)))\n",
    "    denominator = sum(counts[i] - 1 for i in range(len(counts)))\n",
    "\n",
    "    if denominator > 0:\n",
    "        pooled_variance = numerator / denominator\n",
    "        return np.sqrt(pooled_variance)\n",
    "    else:\n",
    "        return 0  # In case of single value or no variance\n",
    "\n",
    "# Function to plot iteration vs the average mean and pooled std_dev\n",
    "def plot_metrics(data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot EVAL data (average across all idx)\n",
    "    iterations = sorted(data[\"EVAL\"].keys())\n",
    "    avg_means = []\n",
    "    pooled_std_devs = []\n",
    "\n",
    "    for iteration in iterations:\n",
    "        means = data[\"EVAL\"][iteration][\"means\"]\n",
    "        std_devs = data[\"EVAL\"][iteration][\"std_devs\"]\n",
    "        counts = data[\"EVAL\"][iteration][\"counts\"]\n",
    "\n",
    "        # Calculate the average mean for the iteration\n",
    "        avg_mean = sum(means) / len(means)\n",
    "        avg_means.append(avg_mean)\n",
    "\n",
    "        # Calculate the pooled standard deviation for the iteration\n",
    "        pooled_std_dev_value = pooled_std_dev(std_devs, counts)\n",
    "        pooled_std_devs.append(pooled_std_dev_value)\n",
    "\n",
    "    # Plot the average means with pooled std_dev as error bars\n",
    "    plt.errorbar(iterations, avg_means, yerr=pooled_std_devs, fmt='o-', capsize=5, label='Average Mean with Pooled Std Dev')\n",
    "\n",
    "    # Plot Original Model data (if available)\n",
    "    if \"Original\" in data and len(data[\"Original\"]) > 0:\n",
    "        original_means = [item[0] for item in data[\"Original\"]]\n",
    "        original_std_devs = [item[1] for item in data[\"Original\"]]\n",
    "        avg_original_mean = np.mean(original_means)\n",
    "        pooled_original_std_dev = pooled_std_dev(original_std_devs, [10] * len(original_std_devs))  # Assuming 10 samples per idx\n",
    "\n",
    "        plt.errorbar([0], [avg_original_mean], yerr=[pooled_original_std_dev], fmt='x', color='r', label='Original Model Average Mean')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Mean')\n",
    "    plt.title('Iteration vs Average Mean with Pooled Std Dev')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parse the log file\n",
    "data = parse_log_file(log_path)\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
