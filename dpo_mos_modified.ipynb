{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\")\n",
    "import importlib\n",
    "import vc\n",
    "importlib.reload(vc)\n",
    "import torch\n",
    "from vc.trainer_encodec_vc_inference import pack_inputs_v2, get_ar_prediction_get_audio, get_ar_prediction_audio_batch\n",
    "from types import SimpleNamespace\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from trl import DPOTrainer, DPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from dpo_eval import get_reward_claps ,eval_dpo_claps_batch, convert_array_to_tensor_format\n",
    "from dpo_eval import get_reward_mos, process_and_get_mos_reward, eval_dpo_mos\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "import argparse\n",
    "import soundfile as sf\n",
    "\n",
    "sys.path.append('/work/b0990106x/trl/CLAPS')\n",
    "from CLAPS.inference import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate_output_batch(\n",
    "        model,\n",
    "        ar_model, \n",
    "        nar_model, \n",
    "        ar_tokenizer, \n",
    "        nar_tokenizer, \n",
    "        clap_model,\n",
    "        accelerator,\n",
    "        src_encodec: list, \n",
    "        instruction: list, \n",
    "        args_predict: SimpleNamespace, \n",
    "        episode_counter: int = 0, \n",
    "        base_path: str = \"/work/b0990106x/trl\", \n",
    "        temperature: float = 1.0\n",
    ") -> tuple[float, str]:\n",
    "    '''\n",
    "    Generates output from AR model, synthesize the audio, and evaluate the audio using NISQA.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            reward(float): The reward of the audio.\n",
    "            tokenized_decode_ar(str): The tokenized output of the AR model - first layer.\n",
    "    '''\n",
    "    # Generate predictions using the AR model\n",
    "    audio_list, decode_ar_list = get_ar_prediction_audio_batch(\n",
    "        args_predict, model, nar_model, ar_tokenizer, nar_tokenizer, src_encodec, instruction, episode_counter, temperature=temperature\n",
    "    )\n",
    "    # extract the instruction from the list \n",
    "    reward_list,tokenized_decode_ar_list = [], []\n",
    "\n",
    "    for i, audio in enumerate(audio_list): \n",
    "        # audio ---> tensor([])\n",
    "        if audio is not None:\n",
    "            # tensor_audio = convert_array_to_tensor_format(audio)\n",
    "            # if tensor_audio[0].shape[0]==1:\n",
    "            #     tensor_audio[0] = tensor_audio[0].squeeze(0)\n",
    "            # print(tensor_audio)\n",
    "            # reward_claps = get_reward_claps(clap_model=clap_model, accelerator=accelerator, prompts = instruction[i], wavs = tensor_audio)\n",
    "            # reward_mos = process_and_get_mos_reward(model=model, nar_model=nar_model, ar_tokenizer=ar_tokenizer, nar_tokenizer=nar_tokenizer, src_encodec=src_encodec[i], instruction=instruction[i], args_predict=args_predict, episode_counter=episode_counter, base_path=base_path)\n",
    "            output_path_ckpt = args_predict.output_path.replace(\".wav\", f\"_generate_{episode_counter}_item_{i}.wav\")\n",
    "            sf.write(output_path_ckpt, np.ravel(audio), samplerate=24000)\n",
    "            reward_mos = get_reward_mos(output_path=output_path_ckpt, base_path=base_path)\n",
    "            reward = reward_mos / 5\n",
    "        else: \n",
    "            reward = 0\n",
    "        reward_list.append(reward)\n",
    "    \n",
    "    for decode_ar in decode_ar_list:\n",
    "        list_decode_ar = decode_ar.flatten().tolist()   \n",
    "        filtered_decode_ar_list = list_decode_ar[2:-1]\n",
    "        decode_ar_tokens = ar_tokenizer.convert_ids_to_tokens(filtered_decode_ar_list)\n",
    "        tokenized_decode_ar = ar_tokenizer.convert_tokens_to_string(decode_ar_tokens)\n",
    "        tokenized_decode_ar_list.append(tokenized_decode_ar)\n",
    "        \n",
    "    return reward_list, tokenized_decode_ar_list\n",
    "\n",
    "def extract_data_from_json(file_path: str) -> Tuple[List[list], List[str], List[list]]:\n",
    "    \"\"\"\n",
    "    Loads data from a JSON file and extracts 'src_encodec', 'instruction', and 'tgt_encodec'.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            all_src_encodec (List[list]): A list containing the 'src_encodec' data from each item in the JSON file.\n",
    "            all_instruction (List[str]): A list containing the 'instruction' data from each item in the JSON file.\n",
    "            all_tgt_encodec (List[list]): A list containing the 'tgt_encodec' data from each item in the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    all_src_encodec = [item[\"src_encodec\"] for item in data]\n",
    "    all_instruction = [item[\"instruction\"] for item in data]\n",
    "\n",
    "    return all_src_encodec, all_instruction\n",
    "\n",
    "def train_model(\n",
    "        model,\n",
    "        model_ref,\n",
    "        ar_tokenizer,\n",
    "        train_dataset: Dataset,\n",
    "        val_dataset: Dataset,\n",
    "        model_output_dir: str,\n",
    "        beta: float,\n",
    "        resume_from_checkpoint: bool,\n",
    "        model_checkpoint: str,\n",
    "        learning_rate: float = 5e-07,\n",
    "        num_train_epochs: int = 200,\n",
    "        max_length: int = 1024*9,\n",
    "        max_prompt_length: int = 1024*9,\n",
    "        max_target_length: int = 1024*9,\n",
    "        per_device_train_batch_size: int = 1,\n",
    "        gradient_accumulation_steps: int = 1,\n",
    "        seed: int = 42\n",
    ") -> None:\n",
    "    '''\n",
    "    Train the DPO model and save the model.\n",
    "\n",
    "    Args:\n",
    "        model(AutoModelForSeq2SeqLMWithValueHead): The DPO model.\n",
    "        model_ref(AutoModelForCausalLM): The reference model.\n",
    "        ar_tokenizer(AutoTokenizer): The tokenizer.\n",
    "        train_dataset(Dataset): The training dataset.\n",
    "        val_dataset(Dataset): The validation dataset.\n",
    "        model_output_dir(str): The output directory for the model.\n",
    "        beta(float): The beta value.\n",
    "        resume_from_checkpoint(bool): Whether to resume from a checkpoint.\n",
    "        model_checkpoint(str): The path to the model\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    training_args = DPOConfig(\n",
    "        beta = beta,\n",
    "        output_dir = model_output_dir,\n",
    "        resume_from_checkpoint = model_checkpoint if resume_from_checkpoint else None,\n",
    "        seed = seed,\n",
    "        per_device_train_batch_size = per_device_train_batch_size,\n",
    "        num_train_epochs = num_train_epochs,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "        learning_rate = learning_rate,\n",
    "        max_length = max_length,\n",
    "        max_prompt_length = max_prompt_length,\n",
    "        max_target_length = max_target_length,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps = 5000,\n",
    "        logging_dir = f\"{model_output_dir}/logs\"\n",
    "    )\n",
    "    \n",
    "    trainer = DPOTrainer(\n",
    "        model=model,\n",
    "        ref_model=model_ref,\n",
    "        args=training_args,\n",
    "        tokenizer=ar_tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    # trainer.save_model(f\"{model_output_dir}/dpo_model\")\n",
    "    model.config.to_json_file(f\"{model_output_dir}/config.json\")\n",
    "    # ar_tokenizer.save_pretrained(f\"{model_output_dir}/dpo_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def process_data_batch(sample_size: int, \n",
    "                       model,\n",
    "                        ar_model, \n",
    "                        nar_model, \n",
    "                        ar_tokenizer, \n",
    "                        nar_tokenizer, \n",
    "                        clap_model,\n",
    "                        accelerator,\n",
    "                        selected_src_encodec: List[list], \n",
    "                        selected_instruction: List[str],\n",
    "                        args_predict: SimpleNamespace, \n",
    "                        base_path: str = \"/work/b0990106x/trl\", \n",
    "                        temperature: float = 1.0, \n",
    "                        iteration: int = 0\n",
    ") -> Tuple[List[str], List[str], List[str], List[float], List[float], List[float]]:\n",
    "    # If sample size is 1, we cannot choose the best and worst outputs\n",
    "    if sample_size < 2:\n",
    "        raise ValueError(\"Parameter 'sample_size' must be greater than 1.\")\n",
    "\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = [], [], [], [], [], []\n",
    "\n",
    "    disable_tqdm = not os.isatty(1)\n",
    "    for i in tqdm(range(len(selected_src_encodec)), desc=\"Processing Data\", disable=disable_tqdm):\n",
    "        rewards, tokenized_outputs = [], []\n",
    "        size_of_packed_input = (\n",
    "            len(selected_src_encodec[i][0]) +\n",
    "            len(ar_tokenizer(selected_instruction[i])[\"input_ids\"][1:-1]) +\n",
    "            3\n",
    "        )\n",
    "        if 4 < size_of_packed_input <= 1024:\n",
    "            selected_src_encodec_list = [selected_src_encodec[i]]*sample_size\n",
    "            selected_instruction_list = [selected_instruction[i]]*sample_size\n",
    "            rewards, tokenized_outputs = generate_output_batch(\n",
    "                model=model,\n",
    "                ar_model=ar_model, \n",
    "                nar_model=nar_model, \n",
    "                ar_tokenizer=ar_tokenizer, \n",
    "                nar_tokenizer=nar_tokenizer,\n",
    "                src_encodec = selected_src_encodec_list,\n",
    "                instruction=selected_instruction_list, \n",
    "                clap_model=clap_model,\n",
    "                accelerator=accelerator,\n",
    "                args_predict=args_predict,\n",
    "                episode_counter=f\"data_{i}\",\n",
    "                base_path=base_path, \n",
    "                temperature=temperature\n",
    "            )\n",
    "\n",
    "        valid_rewards = [r for r in rewards if r is not None]\n",
    "        valid_outputs = [tokenized_outputs[j] for j in range(len(rewards)) if rewards[j] is not None]\n",
    "\n",
    "        if len(valid_rewards) >= 2:\n",
    "            max_reward_index = np.argmax(valid_rewards)\n",
    "            min_reward_index = np.argmin(valid_rewards)\n",
    "            average_reward = np.mean(valid_rewards)\n",
    "            chosen_output = valid_outputs[max_reward_index]\n",
    "            rejected_output = valid_outputs[min_reward_index]\n",
    "            # add <s> and </s> to the chosen_output and rejected_output\n",
    "            # chosen_output = \"<s> \" + chosen_output + \" </s>\"\n",
    "            # rejected_output = \"<s> \" + rejected_output + \" </s>\"\n",
    "\n",
    "            obs_input = pack_inputs_v2(ar_tokenizer, selected_src_encodec[i], selected_instruction[i])\n",
    "            tokenize_input = ar_tokenizer.convert_ids_to_tokens(obs_input)\n",
    "            tokenize_input_str = ar_tokenizer.convert_tokens_to_string(tokenize_input)\n",
    "            prompts.append(tokenize_input_str)\n",
    "\n",
    "            chosen.append(chosen_output)\n",
    "            chosen_rewards.append(valid_rewards[max_reward_index])\n",
    "            rejected.append(rejected_output)\n",
    "            rejected_rewards.append(valid_rewards[min_reward_index])\n",
    "            average_rewards.append(average_reward)\n",
    "        else:\n",
    "            print(f\"Not enough valid rewards for data index {i}\")\n",
    "\n",
    "    # If there is only one data, we need to double the data because we need it for training set and validation set\n",
    "    if len(selected_src_encodec) == 1:\n",
    "        chosen *= 2\n",
    "        rejected *= 2\n",
    "        prompts *= 2\n",
    "        chosen_rewards *= 2\n",
    "        rejected_rewards *= 2\n",
    "        average_rewards *= 2    \n",
    "    \n",
    "    return chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards\n",
    "\n",
    "def generate_data(model,\n",
    "                  ar_model, \n",
    "                  ar_tokenizer, \n",
    "                  nar_model, \n",
    "                  nar_tokenizer, \n",
    "                  clap_model,\n",
    "                  accelerator,\n",
    "                  selected_src_encodec: List[list], \n",
    "                  selected_instruction: List[str],\n",
    "                  args_predict: SimpleNamespace, \n",
    "                  sample_size: int, \n",
    "                  iteration: int, \n",
    "                  agent_output_dir: str, \n",
    "                  base_path: str = \"/work/b0990106x/trl\", \n",
    "                  temperature: float = 1.0\n",
    ") -> Tuple[dict, List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Generates data for the dataset and saves info to a JSON file.\n",
    "    Returns:\n",
    "        tuple:\n",
    "            data_for_dataset (dict): A dictionary containing the data for the dataset.\n",
    "            chosen_rewards (List[float]): A list of rewards for the chosen outputs.\n",
    "            rejected_rewards (List[float]): A list of rewards for the rejected outputs.\n",
    "    \"\"\"\n",
    "    chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards = process_data_batch(\n",
    "        sample_size=sample_size,\n",
    "        model=model,\n",
    "        ar_model=ar_model,\n",
    "        nar_model=nar_model,\n",
    "        ar_tokenizer=ar_tokenizer,\n",
    "        nar_tokenizer=nar_tokenizer,\n",
    "        selected_src_encodec=selected_src_encodec,\n",
    "        selected_instruction=selected_instruction,\n",
    "        args_predict=args_predict,\n",
    "        base_path=base_path,\n",
    "        temperature=temperature,\n",
    "        iteration = iteration,\n",
    "        clap_model=clap_model,\n",
    "        accelerator=accelerator\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"prompt\": prompts,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "        \"chosen_rewards\": chosen_rewards,\n",
    "        \"rejected_rewards\": rejected_rewards,\n",
    "        \"average_rewards\": average_rewards\n",
    "    }\n",
    "\n",
    "    with open(f\"{agent_output_dir}/data_iter_{iteration}.json\", \"w\") as outfile:\n",
    "        json.dump(data, outfile, indent=4)\n",
    "\n",
    "    data_for_dataset = {key: data[key] for key in [\"prompt\", \"chosen\", \"rejected\"]}\n",
    "\n",
    "    return data_for_dataset, chosen_rewards, rejected_rewards\n",
    "\n",
    "def train_iteration(model, \n",
    "                    model_checkpoint,\n",
    "                    iteration, \n",
    "                    data_size, \n",
    "                    sample_size, \n",
    "                    ar_model, \n",
    "                    ar_tokenizer,\n",
    "                    nar_model, \n",
    "                    nar_tokenizer,\n",
    "                    all_src_encodec, \n",
    "                    all_instruction, \n",
    "                    args_predict, \n",
    "                    agent_output_dir,\n",
    "                    model_output_dir_base, \n",
    "                    clap_model,\n",
    "                    accelerator,\n",
    "                    beta = 0.1, \n",
    "                    temperature = 1.0,\n",
    "                    base_path=\"/work/b0990106x/trl\",\n",
    "                    resume_from_checkpoint = False,\n",
    "                    learning_rate = 5e-07,\n",
    "                    num_train_epochs = 100,\n",
    "                    max_length = 1024*9,\n",
    "                    max_prompt_length = 1024*9,\n",
    "                    max_target_length = 1024*9,\n",
    "                    per_device_train_batch_size = 1,\n",
    "                    gradient_accumulation_steps = 1,\n",
    "                    seed = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes one training iteration: generates data, trains the model, and saves the output.\n",
    "    \"\"\"\n",
    "    # print(f\"Iteration {iteration}\")\n",
    "\n",
    "    # ar_model = BartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "    # ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "    # ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "    # nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "    # nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "\n",
    "    selected_src_encodec = all_src_encodec[:data_size]\n",
    "    selected_instruction = all_instruction[:data_size]\n",
    "\n",
    "    data_for_dataset, chosen_rewards, rejected_rewards = generate_data(model=model, \n",
    "                                                                    ar_model=ar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_model=nar_model,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    selected_src_encodec=selected_src_encodec,\n",
    "                                                                    selected_instruction=selected_instruction,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    sample_size=sample_size,\n",
    "                                                                    iteration=iteration,\n",
    "                                                                    agent_output_dir=agent_output_dir,\n",
    "                                                                    base_path=base_path,\n",
    "                                                                    temperature=temperature,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator)\n",
    "\n",
    "    dataset = Dataset.from_dict(data_for_dataset)\n",
    "    dataset_dict = dataset.train_test_split(test_size=0.1, shuffle=True, seed=seed)\n",
    "    train_dataset = dataset_dict[\"train\"]\n",
    "    val_dataset = dataset_dict[\"test\"]\n",
    "    \n",
    "    # print train_dataset and val_dataset\n",
    "    if iteration < 2:\n",
    "        print(\"train_dataset\", train_dataset.to_dict())\n",
    "        print(\"val_dataset\", val_dataset.to_dict())\n",
    "\n",
    "    model_output_dir = f\"{model_output_dir_base}/iter_{iteration}\"\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    # model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "    model_ref = create_reference_model(model)\n",
    "    \n",
    "    train_model(model=model,\n",
    "                model_ref=model_ref,\n",
    "                ar_tokenizer=ar_tokenizer,\n",
    "                train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                model_output_dir=model_output_dir,\n",
    "                beta=beta,\n",
    "                resume_from_checkpoint=resume_from_checkpoint,\n",
    "                model_checkpoint=model_checkpoint,\n",
    "                learning_rate = learning_rate,\n",
    "                num_train_epochs = num_train_epochs,\n",
    "                max_length = max_length,\n",
    "                max_prompt_length = max_prompt_length,\n",
    "                max_target_length = max_target_length,\n",
    "                per_device_train_batch_size = per_device_train_batch_size,\n",
    "                gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "                seed = seed)\n",
    "\n",
    "    return f\"{model_output_dir}/dpo_model\", chosen_rewards, rejected_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 1022-0945\n",
      "length of all_src_encodec: 9254\n",
      "length of all_instruction: 9254\n"
     ]
    }
   ],
   "source": [
    "# Load all data\n",
    "selected_src_encodec, selected_instruction = extract_data_from_json('dpo_data/src_encodec.json')\n",
    "\n",
    "# Define paths and device\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define timestamp\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# Define paths\n",
    "model_output_dir = os.path.join(base_path, \"model_output\", ts) # Location where the model are saved\n",
    "agent_output_dir = os.path.join(base_path, \"output\", ts) # Path of saving the generated audio for reward model to evaluate\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(agent_output_dir, exist_ok=True)\n",
    "\n",
    "seed = 42 # Training: seed\n",
    "\n",
    "# Define arguments \n",
    "args_predict = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=seed, device=device)\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "# Models and Iterations\n",
    "model_checkpoint = ar_checkpoint # Prepare: set the initial model checkpoint\n",
    "sample_size = 10 # Prepare Dataset: generate how many outputs to select max and min for chosen and rejected (original: 10)\n",
    "num_iterations = 1000  # Training: train how many iterations (original: 100)\n",
    "train_selected_indices = [8]\n",
    "# train_selected_indices = [9]\n",
    "# train_selected_indices = random.sample(range(len(selected_src_encodec)), 5) # Training: train on selected data indicies from all_src_encodec\n",
    " # Training: train on selected data indicies from all_src_encodec\n",
    "data_size_per_iteration = len(train_selected_indices) # Training: each iteration will train how many data\n",
    "\n",
    "# Define Training Configuration\n",
    "beta = 0.1 # Training: beta value for DPO\n",
    "learning_rate = 5e-07 # Training: learning rate (original: 5e-07)\n",
    "num_train_epochs = 3 # Training: number of training epochs (original: 3)\n",
    "max_length = 1024*9 # Training: max length of the model\n",
    "max_prompt_length = 1024*9 # Training: max length of the prompt\n",
    "max_target_length = 1024*9 # Training: max length of the target\n",
    "per_device_train_batch_size = 8 # Training: batch size (original: 1)\n",
    "gradient_accumulation_steps = 1 # Training: gradient accumulation steps\n",
    "\n",
    "# Evaluation Configuration\n",
    "eval_train = True # Evaluation: evaluate on training data or not\n",
    "eval_test = False # Evaluation: evaluate on testing data or not\n",
    "eval_train_indices = train_selected_indices # Evaluation: evaluate on training data indicies from all_src_encodec\n",
    "eval_test_indices = random.sample(range(len(selected_src_encodec)), 5) # Evaluation: evaluate on testing data indicies from all_src_encodec\n",
    "eval_train_data_len = 1000 # Evaluation: evaluate how many training data\n",
    "eval_test_data_len = len(eval_test_indices) # Evaluation: evaluate how many testing data\n",
    "num_eval = 10 # Evaluation: evaluate how many times per data (original: 10)\n",
    "eval_frequency = 1 # Evaluation: evaluate every how many iterations\n",
    "# Define temperature\n",
    "# eval_selected_indices = random.sample(range(len(all_src_encodec)), eval_data_len) # Evaluation: select 10 data for evaluation\n",
    "print(f\"length of all_src_encodec: {len(selected_src_encodec)}\") # ~ 9000 data\n",
    "print(f\"length of all_instruction: {len(selected_instruction)}\") # ~ 9000 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from /work/b0990106x/trl/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "sr = 24000\n",
    "text_enc_name = \"google/flan-t5-large\"\n",
    "text_enc_dim = 1024\n",
    "text_blstm_dim = 256\n",
    "speech_enc_name = \"wavlm\"\n",
    "speech_enc_dim = 768\n",
    "speech_blstm_dim = 256\n",
    "rep_dim = 512\n",
    "sub_dim = 0\n",
    "n_sub = 1\n",
    "ckpt_pth=f'{base_path}/CLAPS/pretrained/7d/cp_claps_blstm_m_50k_v3/cp_0045000'\n",
    "project_dir = \"cp_claps\"\n",
    "\n",
    "a = argparse.Namespace(\n",
    "        sr=sr,\n",
    "        text_enc_name=text_enc_name,\n",
    "        text_enc_dim=text_enc_dim,\n",
    "        text_blstm_dim=text_blstm_dim,\n",
    "        speech_enc_name=speech_enc_name,\n",
    "        speech_enc_dim=speech_enc_dim,\n",
    "        speech_blstm_dim=speech_blstm_dim,\n",
    "        rep_dim=rep_dim,\n",
    "        sub_dim=sub_dim,\n",
    "        n_sub=n_sub,  # Number of subspaces, if any\n",
    "        ckpt_pth=ckpt_pth,  # Set your checkpoint path\n",
    "        project_dir=project_dir  # Example project directory\n",
    "    )\n",
    "\n",
    "clap_model, accelerator = load_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_iterations: 1000\n",
      "data_size_per_iteration: 1\n",
      "sample_size: 10\n",
      "beta: 0.1\n",
      "learning_rate: 5e-08\n",
      "num_train_epochs: 3\n",
      "ar_checkpoint: lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\n",
      "nar_checkpoint: lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\n",
      "args_predict: namespace(output_path='/work/b0990106x/trl/output/1022-0945/example.wav', seed=42, device='cuda')\n",
      "model_output_dir: /work/b0990106x/trl/model_output/1022-0945\n",
      "agent_output_dir: /work/b0990106x/trl/output/1022-0945\n",
      "base_path: /work/b0990106x/trl\n",
      "device: cuda\n",
      "eval_train_data_len: 1000\n",
      "eval_test_data_len: 5\n",
      "eval_train_indices: [8]\n",
      "eval_test_indices: [1824, 409, 4506, 4012, 3657]\n",
      "eval_train: True\n",
      "eval_test: False\n",
      "num_eval: 10\n",
      "training idx 8 : Significantly dampen the vibrations of the high notes.\n",
      "evaluation idx 8 : Significantly dampen the vibrations of the high notes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_iterations: {num_iterations}\")\n",
    "print(f\"data_size_per_iteration: {data_size_per_iteration}\")\n",
    "print(f\"sample_size: {sample_size}\")\n",
    "print(f\"beta: {beta}\")\n",
    "print(f\"learning_rate: {learning_rate}\")\n",
    "print(f\"num_train_epochs: {num_train_epochs}\")\n",
    "print(f\"ar_checkpoint: {ar_checkpoint}\")\n",
    "print(f\"nar_checkpoint: {nar_checkpoint}\")\n",
    "print(f\"args_predict: {args_predict}\")\n",
    "print(f\"model_output_dir: {model_output_dir}\")\n",
    "print(f\"agent_output_dir: {agent_output_dir}\")\n",
    "print(f\"base_path: {base_path}\")\n",
    "print(f\"device: {device}\")\n",
    "print(f\"eval_train_data_len: {eval_train_data_len}\")\n",
    "print(f\"eval_test_data_len: {eval_test_data_len}\")\n",
    "print(f\"eval_train_indices: {eval_train_indices}\")\n",
    "print(f\"eval_test_indices: {eval_test_indices}\")\n",
    "print(f\"eval_train: {eval_train}\")\n",
    "print(f\"eval_test: {eval_test}\")\n",
    "print(f\"num_eval: {num_eval}\")\n",
    "\n",
    "# print training data\n",
    "for i in train_selected_indices:\n",
    "    print('training idx', i,':', selected_instruction[i])\n",
    "    \n",
    "# print evaluation data\n",
    "if eval_test:\n",
    "    for i in eval_test_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "if eval_train:\n",
    "    for i in eval_train_indices:\n",
    "        print('evaluation idx', i,':', selected_instruction[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model_checkpoint, return_dict=True)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "# ar_tokenizer.pad_token = ar_tokenizer.eos_token\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: /work/b0990106x/trl/model_output/1022-0945/log_training.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "log_path = f'{model_output_dir}/log_training.log'\n",
    "print(f\"Logging to: {log_path}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=log_path, \n",
    "    filemode='a', \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    f\"Parameters:\\n\"\n",
    "    f\"Prepare Data: sample_size: {sample_size}\\n\"\n",
    "    f\"Training: num_iterations: {num_iterations}\\n\"\n",
    "    f\"Training: data_size_per_iteration: {data_size_per_iteration}\\n\"\n",
    "    f\"Training: train_selected_indices: {train_selected_indices}\\n\"\n",
    "    f\"Training: beta: {beta}\\n\"\n",
    "    f\"Training: learning_rate: {learning_rate}\\n\"\n",
    "    f\"Training: num_train_epochs: {num_train_epochs}\\n\"\n",
    "    f\"Training: max_length: {max_length}\\n\"\n",
    "    f\"Training: max_prompt_length: {max_prompt_length}\\n\"\n",
    "    f\"Training: max_target_length: {max_target_length}\\n\"\n",
    "    f\"Training: per_device_train_batch_size: {per_device_train_batch_size}\\n\"\n",
    "    f\"Training: gradient_accumulation_steps: {gradient_accumulation_steps}\\n\"\n",
    "    f\"Training: seed: {seed}\\n\"\n",
    "    f\"Training: ar_checkpoint: {ar_checkpoint}\\n\"\n",
    "    f\"Training: nar_checkpoint: {nar_checkpoint}\\n\"\n",
    "    f\"Training: args_predict: {args_predict}\\n\"\n",
    "    f\"Training: model_output_dir: {model_output_dir}\\n\"\n",
    "    f\"Training: agent_output_dir: {agent_output_dir}\\n\"\n",
    "    f\"Training: base_path: {base_path}\\n\"\n",
    "    f\"Training: device: {device}\\n\"\n",
    "    f\"Evaluation: eval_train_data_len: {eval_train_data_len}\\n\"\n",
    "    f\"Evaluation: eval_test_data_len: {eval_test_data_len}\\n\"\n",
    "    f\"Evaluation: eval_train_indices: {eval_train_indices}\\n\"\n",
    "    f\"Evaluation: eval_test_indices: {eval_test_indices}\\n\"\n",
    "    f\"Evaluation: eval_train: {eval_train}\\n\"\n",
    "    f\"Evaluation: eval_test: {eval_test}\\n\"\n",
    "    f\"Evaluation: num_eval: {num_eval}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_-1_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_-1_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "total_start_time = time.time()\n",
    "if eval_train:\n",
    "    # eval dpo claps\n",
    "    # original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "    #                                                                 ar_tokenizer=ar_tokenizer,\n",
    "    #                                                                 nar_tokenizer=nar_tokenizer,\n",
    "    #                                                                 trained_model=model,\n",
    "    #                                                                 args_predict=args_predict,\n",
    "    #                                                                 all_src_encodec=selected_src_encodec,\n",
    "    #                                                                 all_instruction=selected_instruction,\n",
    "    #                                                                 iteration = -1,\n",
    "    #                                                                 num_evaluations = num_eval,\n",
    "    #                                                                 eval_data_len=eval_train_data_len,\n",
    "    #                                                                 selected_indices=eval_train_indices,\n",
    "    #                                                                 device=device,\n",
    "    #                                                                 clap_model=clap_model,\n",
    "    #                                                                 accelerator=accelerator\n",
    "    #                                                                 )\n",
    "    # logging.info(f\"Original Model Train Set Evaluation: \")\n",
    "    # logging.info(f\"Original model metrics on training set: {original_model_metrics}\")\n",
    "    # logging.info(f\"Original model rewards on training set: {original_model_rewards}\")\n",
    "    \n",
    "    # eval dpo mos\n",
    "    original_model_metrics_mos, original_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_train_data_len,\n",
    "                                                                    selected_indices=eval_train_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    )\n",
    "    logging.info(f\"Original model metrics on training set: {original_model_metrics_mos}\")\n",
    "    logging.info(f\"Original model rewards on training set: {original_model_rewards_mos}\")\n",
    "    \n",
    "    # reward_list = []\n",
    "    # for rewards in original_model_rewards:\n",
    "    #     filter_rewards = [r for r in rewards if r is not None]\n",
    "    #     if len(filter_rewards) == 0:\n",
    "    #         reward_list.append(None)\n",
    "    #     else:\n",
    "    #         reward_list.append(np.mean(filter_rewards))\n",
    "    # logging.info(f\"Original model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "    reward_list_mos = []\n",
    "    for rewards in original_model_rewards_mos:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list_mos.append(None)\n",
    "        else:\n",
    "            reward_list_mos.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model MOS score list on training set: {reward_list_mos}\")\n",
    "    \n",
    "    # filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    # if len(filter_reward_list) != 0:\n",
    "    #     logging.info(f\"Original model average rewards on training set: {np.mean(filter_reward_list)}\")\n",
    "    # else: \n",
    "    #     logging.info(f\"Original model average rewards on training set: None\")\n",
    "        \n",
    "    filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "    if len(filter_reward_list_mos) != 0:\n",
    "        logging.info(f\"Original model average MOS on training set: {np.mean(filter_reward_list_mos)}\")\n",
    "    else:\n",
    "        logging.info(f\"Original model average MOS on training set: None\")\n",
    "        \n",
    "    # weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "    weighted_reward = np.mean(filter_reward_list_mos)/5\n",
    "    logging.info(f\"Original model weighted average rewards on training set: {weighted_reward}\")\n",
    "    \n",
    "if eval_test:\n",
    "    original_model_metrics, original_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                    ar_tokenizer=ar_tokenizer,\n",
    "                                                                    nar_tokenizer=nar_tokenizer,\n",
    "                                                                    trained_model=model,\n",
    "                                                                    args_predict=args_predict,\n",
    "                                                                    all_src_encodec=selected_src_encodec,\n",
    "                                                                    all_instruction=selected_instruction,\n",
    "                                                                    iteration = -1,\n",
    "                                                                    num_evaluations = num_eval,\n",
    "                                                                    eval_data_len=eval_test_data_len,\n",
    "                                                                    selected_indices=eval_test_indices,\n",
    "                                                                    device=device,\n",
    "                                                                    clap_model=clap_model,\n",
    "                                                                    accelerator=accelerator\n",
    "                                                                    )\n",
    "    logging.info(f\"Original Model Test Set Evaluation: \")\n",
    "    logging.info(f\"Original model metrics on testing set: {original_model_metrics}\")\n",
    "    logging.info(f\"Original model rewards on testing set: {original_model_rewards}\")\n",
    "    reward_list = []\n",
    "    for rewards in original_model_rewards:\n",
    "        filter_rewards = [r for r in rewards if r is not None]\n",
    "        if len(filter_rewards) == 0:\n",
    "            reward_list.append(None)\n",
    "        else:\n",
    "            reward_list.append(np.mean(filter_rewards))\n",
    "    logging.info(f\"Original model reward list on testing set: {reward_list}\")\n",
    "    filter_reward_list = [r for r in reward_list if r is not None]\n",
    "    if len(filter_reward_list) != 0:\n",
    "        logging.info(f\"Original model average rewards on testing set: {np.mean(filter_reward_list)}\")\n",
    "    else: \n",
    "        logging.info(f\"Original model average rewards on testing set: None\")\n",
    "    \n",
    "# If train_selected_indices is not empty, we will use the selected indices for training\n",
    "if train_selected_indices:\n",
    "    batch_src_encodec = [selected_src_encodec[i] for i in train_selected_indices]\n",
    "    batch_instruction = [selected_instruction[i] for i in train_selected_indices]\n",
    "    logging.info(f\"Processing data from selected indices: {train_selected_indices}\")\n",
    "else:\n",
    "    start_idx = 0\n",
    "    end_idx = data_size_per_iteration\n",
    "    batch_src_encodec = selected_src_encodec[start_idx:end_idx] \n",
    "    batch_instruction = selected_instruction[start_idx:end_idx]\n",
    "    logging.info(f\"Processing data from index {start_idx} to {end_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_738v_tok_738v_tok_876v_tok_835v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_411v_tok_59v_tok_411v_tok_479v_tok_411v_tok_453v_tok_23v_tok_922v_tok_835v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_862v_tok_505v_tok_407v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_430v_tok_738v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_228v_tok_151v_tok_906v_tok_151v_tok_151v_tok_151v_tok_136v_tok_151v_tok_151v_tok_502v_tok_901v_tok_890v_tok_1011v_tok_523v_tok_457v_tok_523v_tok_753v_tok_321v_tok_325v_tok_523v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_738v_tok_738v_tok_835v_tok_876v_tok_393v_tok_709v_tok_709v_tok_463v_tok_176v_tok_339v_tok_339v_tok_709v_tok_339v_tok_395v_tok_709v_tok_339v_tok_339'], 'rejected': ['v_tok_408v_tok_835v_tok_408v_tok_876v_tok_751v_tok_182v_tok_411v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_59v_tok_59v_tok_453v_tok_881v_tok_922v_tok_475v_tok_835v_tok_876v_tok_747v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_862v_tok_505v_tok_679v_tok_23v_tok_23v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_887v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_855v_tok_602v_tok_588v_tok_151v_tok_151v_tok_151v_tok_563v_tok_151v_tok_151v_tok_1008v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_753v_tok_967v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_738v_tok_738v_tok_876v_tok_73v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_463v_tok_709v_tok_395v_tok_339v_tok_339v_tok_339v_tok_475']}\n",
      "val_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_738v_tok_738v_tok_876v_tok_835v_tok_751v_tok_1008v_tok_479v_tok_479v_tok_479v_tok_411v_tok_59v_tok_411v_tok_479v_tok_411v_tok_453v_tok_23v_tok_922v_tok_835v_tok_835v_tok_876v_tok_233v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_862v_tok_505v_tok_407v_tok_23v_tok_495v_tok_598v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_430v_tok_738v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_228v_tok_151v_tok_906v_tok_151v_tok_151v_tok_151v_tok_136v_tok_151v_tok_151v_tok_502v_tok_901v_tok_890v_tok_1011v_tok_523v_tok_457v_tok_523v_tok_753v_tok_321v_tok_325v_tok_523v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_738v_tok_738v_tok_835v_tok_876v_tok_393v_tok_709v_tok_709v_tok_463v_tok_176v_tok_339v_tok_339v_tok_709v_tok_339v_tok_395v_tok_709v_tok_339v_tok_339'], 'rejected': ['v_tok_408v_tok_835v_tok_408v_tok_876v_tok_751v_tok_182v_tok_411v_tok_479v_tok_479v_tok_479v_tok_59v_tok_479v_tok_59v_tok_59v_tok_453v_tok_881v_tok_922v_tok_475v_tok_835v_tok_876v_tok_747v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_862v_tok_505v_tok_679v_tok_23v_tok_23v_tok_563v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_887v_tok_133v_tok_835v_tok_835v_tok_835v_tok_738v_tok_835v_tok_855v_tok_602v_tok_588v_tok_151v_tok_151v_tok_151v_tok_563v_tok_151v_tok_151v_tok_1008v_tok_901v_tok_862v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_753v_tok_967v_tok_971v_tok_604v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_835v_tok_835v_tok_106v_tok_738v_tok_738v_tok_876v_tok_73v_tok_463v_tok_463v_tok_463v_tok_709v_tok_339v_tok_463v_tok_709v_tok_395v_tok_339v_tok_339v_tok_339v_tok_475']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 169.20 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 220.21 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_0_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_0_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_796v_tok_479v_tok_479v_tok_479v_tok_914v_tok_479v_tok_479v_tok_796v_tok_796v_tok_583v_tok_865v_tok_835v_tok_876v_tok_876v_tok_411v_tok_575v_tok_808v_tok_291v_tok_155v_tok_942v_tok_862v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_971v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_276v_tok_907v_tok_59v_tok_901v_tok_151v_tok_151v_tok_151v_tok_598v_tok_151v_tok_901v_tok_862v_tok_1022v_tok_901v_tok_598v_tok_155v_tok_323v_tok_323v_tok_971v_tok_699v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_1017v_tok_835v_tok_835v_tok_408v_tok_835v_tok_935v_tok_176v_tok_176v_tok_463v_tok_176v_tok_395v_tok_25v_tok_176v_tok_339v_tok_339v_tok_395v_tok_395v_tok_395</s><pad>'], 'rejected': ['v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_967v_tok_479v_tok_479v_tok_479v_tok_961v_tok_411v_tok_411v_tok_479v_tok_939v_tok_197v_tok_922v_tok_133v_tok_876v_tok_1019v_tok_372v_tok_358v_tok_808v_tok_291v_tok_945v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_563v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_228v_tok_126v_tok_228v_tok_133v_tok_133v_tok_835v_tok_1019v_tok_876v_tok_738v_tok_133v_tok_559v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_151v_tok_598v_tok_890v_tok_1008v_tok_901v_tok_291v_tok_1001v_tok_323v_tok_136v_tok_598v_tok_967v_tok_971v_tok_753v_tok_310v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_323v_tok_709v_tok_148v_tok_463v_tok_463v_tok_463v_tok_395v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_475</s><pad>']}\n",
      "val_dataset {'prompt': ['<s>Significantly dampen the vibrations of the high notes.</s>v_tok_835v_tok_835v_tok_339v_tok_835v_tok_339v_tok_751v_tok_1008v_tok_479v_tok_535v_tok_535v_tok_479v_tok_479v_tok_479v_tok_479v_tok_479v_tok_453v_tok_881v_tok_922v_tok_339v_tok_835v_tok_876v_tok_951v_tok_358v_tok_808v_tok_291v_tok_925v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_843v_tok_530v_tok_563v_tok_1001v_tok_690v_tok_224v_tok_430v_tok_126v_tok_819v_tok_133v_tok_339v_tok_835v_tok_339v_tok_835v_tok_339v_tok_25v_tok_940v_tok_479v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_502v_tok_901v_tok_533v_tok_1008v_tok_185v_tok_291v_tok_155v_tok_323v_tok_565v_tok_323v_tok_967v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_339v_tok_339v_tok_835v_tok_835v_tok_835v_tok_339v_tok_409v_tok_160v_tok_148v_tok_176v_tok_148v_tok_463v_tok_176v_tok_160v_tok_176v_tok_709v_tok_709v_tok_709v_tok_709</s>'], 'chosen': ['v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_1008v_tok_796v_tok_479v_tok_479v_tok_479v_tok_914v_tok_479v_tok_479v_tok_796v_tok_796v_tok_583v_tok_865v_tok_835v_tok_876v_tok_876v_tok_411v_tok_575v_tok_808v_tok_291v_tok_155v_tok_942v_tok_862v_tok_505v_tok_415v_tok_23v_tok_495v_tok_807v_tok_1001v_tok_530v_tok_563v_tok_1001v_tok_971v_tok_224v_tok_430v_tok_126v_tok_604v_tok_133v_tok_835v_tok_835v_tok_1019v_tok_835v_tok_835v_tok_276v_tok_907v_tok_59v_tok_901v_tok_151v_tok_151v_tok_151v_tok_598v_tok_151v_tok_901v_tok_862v_tok_1022v_tok_901v_tok_598v_tok_155v_tok_323v_tok_323v_tok_971v_tok_699v_tok_971v_tok_753v_tok_321v_tok_1019v_tok_432v_tok_1019v_tok_1017v_tok_1017v_tok_835v_tok_835v_tok_408v_tok_835v_tok_935v_tok_176v_tok_176v_tok_463v_tok_176v_tok_395v_tok_25v_tok_176v_tok_339v_tok_339v_tok_395v_tok_395v_tok_395</s><pad>'], 'rejected': ['v_tok_835v_tok_835v_tok_835v_tok_1017v_tok_751v_tok_967v_tok_479v_tok_479v_tok_479v_tok_961v_tok_411v_tok_411v_tok_479v_tok_939v_tok_197v_tok_922v_tok_133v_tok_876v_tok_1019v_tok_372v_tok_358v_tok_808v_tok_291v_tok_945v_tok_942v_tok_901v_tok_505v_tok_415v_tok_23v_tok_563v_tok_598v_tok_1001v_tok_530v_tok_860v_tok_598v_tok_690v_tok_224v_tok_228v_tok_126v_tok_228v_tok_133v_tok_133v_tok_835v_tok_1019v_tok_876v_tok_738v_tok_133v_tok_559v_tok_59v_tok_317v_tok_151v_tok_151v_tok_151v_tok_502v_tok_151v_tok_151v_tok_598v_tok_890v_tok_1008v_tok_901v_tok_291v_tok_1001v_tok_323v_tok_136v_tok_598v_tok_967v_tok_971v_tok_753v_tok_310v_tok_1019v_tok_432v_tok_1019v_tok_738v_tok_835v_tok_835v_tok_408v_tok_408v_tok_835v_tok_323v_tok_709v_tok_148v_tok_463v_tok_463v_tok_463v_tok_395v_tok_709v_tok_709v_tok_339v_tok_339v_tok_339v_tok_475</s><pad>']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 127.37 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 215.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_1_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_1_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 188.98 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 198.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_2_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_2_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 172.49 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 174.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_3_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_3_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 198.20 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 103.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_4_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_4_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 131.83 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 194.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_5_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_5_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 207.51 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 176.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_6_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_6_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.36 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 91.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_7_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_7_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 200.78 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 147.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_8_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_8_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 211.52 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 209.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_9_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_9_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 138.76 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 208.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_10_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_10_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 222.65 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 215.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_4.wav\n",
      "Error: No columns to parse from file\n",
      "get_reward function end ___________________________\n",
      "Episode eval_11_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_11_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_11_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 168.55 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 211.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_5.wav\n",
      "Episode eval_12_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_12_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_12_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,3,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 226.24 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 203.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_13_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_13_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 117.74 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 201.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_0 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_1 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_2 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_3 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_4 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_5 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_6 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_7 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_8 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode eval_14_data_8_9 : audio saved to  /work/b0990106x/trl/output/1022-0945/example_save_eval_14_data_8_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b0990106x/trl/NISQA/nisqa/NISQA_model.py:77: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  existing_df = pd.read_csv(output_path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# model_checkpoint is the model checkpoint from the previous iteration\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# chosen_rewards and rejected_rewards are the rewards of the data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model_checkpoint, chosen_rewards, rejected_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                            \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_size_per_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mall_src_encodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_src_encodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mall_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                            \u001b[49m\u001b[43margs_predict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[43magent_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_output_dir_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_prompt_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_prompt_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_target_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_target_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mclap_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclap_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                            \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m       \n\u001b[1;32m     40\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChosen rewards for iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_rewards\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRejected rewards for iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrejected_rewards\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 186\u001b[0m, in \u001b[0;36mtrain_iteration\u001b[0;34m(model, model_checkpoint, iteration, data_size, sample_size, ar_model, ar_tokenizer, nar_model, nar_tokenizer, all_src_encodec, all_instruction, args_predict, agent_output_dir, model_output_dir_base, clap_model, accelerator, beta, temperature, base_path, resume_from_checkpoint, learning_rate, num_train_epochs, max_length, max_prompt_length, max_target_length, per_device_train_batch_size, gradient_accumulation_steps, seed)\u001b[0m\n\u001b[1;32m    183\u001b[0m selected_src_encodec \u001b[38;5;241m=\u001b[39m all_src_encodec[:data_size]\n\u001b[1;32m    184\u001b[0m selected_instruction \u001b[38;5;241m=\u001b[39m all_instruction[:data_size]\n\u001b[0;32m--> 186\u001b[0m data_for_dataset, chosen_rewards, rejected_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mselected_src_encodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_src_encodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mselected_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43margs_predict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43magent_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mclap_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclap_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(data_for_dataset)\n\u001b[1;32m    203\u001b[0m dataset_dict \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39mseed)\n",
      "Cell \u001b[0;32mIn[17], line 110\u001b[0m, in \u001b[0;36mgenerate_data\u001b[0;34m(model, ar_model, ar_tokenizer, nar_model, nar_tokenizer, clap_model, accelerator, selected_src_encodec, selected_instruction, args_predict, sample_size, iteration, agent_output_dir, base_path, temperature)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_data\u001b[39m(model,\n\u001b[1;32m     87\u001b[0m                   ar_model, \n\u001b[1;32m     88\u001b[0m                   ar_tokenizer, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m                   temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    101\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mdict\u001b[39m, List[\u001b[38;5;28mfloat\u001b[39m], List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Generates data for the dataset and saves info to a JSON file.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m            rejected_rewards (List[float]): A list of rewards for the rejected outputs.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     chosen, rejected, prompts, chosen_rewards, rejected_rewards, average_rewards \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselected_src_encodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_src_encodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselected_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_predict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclap_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclap_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompts,\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchosen\u001b[39m\u001b[38;5;124m\"\u001b[39m: chosen,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage_rewards\u001b[39m\u001b[38;5;124m\"\u001b[39m: average_rewards\n\u001b[1;32m    134\u001b[0m     }\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data_iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n",
      "Cell \u001b[0;32mIn[17], line 33\u001b[0m, in \u001b[0;36mprocess_data_batch\u001b[0;34m(sample_size, model, ar_model, nar_model, ar_tokenizer, nar_tokenizer, clap_model, accelerator, selected_src_encodec, selected_instruction, args_predict, base_path, temperature, iteration)\u001b[0m\n\u001b[1;32m     31\u001b[0m     selected_src_encodec_list \u001b[38;5;241m=\u001b[39m [selected_src_encodec[i]]\u001b[38;5;241m*\u001b[39msample_size\n\u001b[1;32m     32\u001b[0m     selected_instruction_list \u001b[38;5;241m=\u001b[39m [selected_instruction[i]]\u001b[38;5;241m*\u001b[39msample_size\n\u001b[0;32m---> 33\u001b[0m     rewards, tokenized_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_output_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_encodec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mselected_src_encodec_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_instruction_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclap_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclap_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_predict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepisode_counter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m valid_rewards \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rewards \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     50\u001b[0m valid_outputs \u001b[38;5;241m=\u001b[39m [tokenized_outputs[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rewards)) \u001b[38;5;28;01mif\u001b[39;00m rewards[j] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m, in \u001b[0;36mgenerate_output_batch\u001b[0;34m(model, ar_model, nar_model, ar_tokenizer, nar_tokenizer, clap_model, accelerator, src_encodec, instruction, args_predict, episode_counter, base_path, temperature)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mGenerates output from AR model, synthesize the audio, and evaluate the audio using NISQA.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m        tokenized_decode_ar(str): The tokenized output of the AR model - first layer.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Generate predictions using the AR model\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m audio_list, decode_ar_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_ar_prediction_audio_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_encodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_counter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# extract the instruction from the list \u001b[39;00m\n\u001b[1;32m     28\u001b[0m reward_list,tokenized_decode_ar_list \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/work/b0990106x/trl/vc/trainer_encodec_vc_inference.py:436\u001b[0m, in \u001b[0;36mget_ar_prediction_audio_batch\u001b[0;34m(args, ar_model, nar_model, ar_tokenizer, nar_tokenizer, batch_src_encodec, batch_instruction, episode_counter, temperature)\u001b[0m\n\u001b[1;32m    434\u001b[0m ar_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    435\u001b[0m nar_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 436\u001b[0m layer_list_batch, decode_ar_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcascade_ar_nar_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnar_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_src_encodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_instruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m audio_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(layer_list_batch)):\n",
      "File \u001b[0;32m/work/b0990106x/trl/vc/trainer_encodec_vc_inference.py:298\u001b[0m, in \u001b[0;36mcascade_ar_nar_batch\u001b[0;34m(ar_model, nar_model, ar_tokenizer, nar_tokenizer, device, batch_src_encodec, batch_instruction, temperature)\u001b[0m\n\u001b[1;32m    295\u001b[0m vocab_ids \u001b[38;5;241m=\u001b[39m [[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m50265\u001b[39m)]\n\u001b[1;32m    296\u001b[0m bad_words_ids\u001b[38;5;241m.\u001b[39mextend(vocab_ids)\n\u001b[0;32m--> 298\u001b[0m decode_ar_batch \u001b[38;5;241m=\u001b[39m \u001b[43mar_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbad_words_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbad_words_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# decode_ar_batch --> tensor([[],[],[],[],[],[],[],[]], device = 'cuda:0')\u001b[39;00m\n\u001b[1;32m    300\u001b[0m filtered_sequences \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/work/b0990106x/trl/trl/models/modeling_value_head.py:438\u001b[0m, in \u001b[0;36mAutoModelForSeq2SeqLMWithValueHead.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    We call `generate` on the wrapped model.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1588\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1581\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1582\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1583\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1585\u001b[0m     )\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2655\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;66;03m# pre-process distribution\u001b[39;00m\n\u001b[0;32m-> 2655\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2656\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m logits_warper(input_ids, next_token_scores)\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;66;03m# Store scores, attentions and hidden_states when required\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py:97\u001b[0m, in \u001b[0;36mLogitsProcessorList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         scores \u001b[38;5;241m=\u001b[39m processor(input_ids, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py:636\u001b[0m, in \u001b[0;36mSequenceBiasLogitsProcessor.__call__\u001b[0;34m(self, input_ids, scores)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(LOGITS_PROCESSOR_INPUTS_DOCSTRING)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor, scores: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;66;03m# 1 - Prepares the bias tensors. This is only needed the first time the logit processor is called.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepared_bias_variables:\n\u001b[0;32m--> 636\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_bias_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;66;03m# 2 - prepares an empty bias to add\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     bias \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(scores)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py:702\u001b[0m, in \u001b[0;36mSequenceBiasLogitsProcessor._prepare_bias_variables\u001b[0;34m(self, scores)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    697\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting a bias on sequences that share a common token termination is not yet supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    698\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open an issue if you see this error message (after checking that it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    699\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexist).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m             )\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_greather_than_1_bias[sequence_ids[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m bias\n\u001b[0;32m--> 702\u001b[0m     \u001b[43mtokens_with_bias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepared_bias_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "disable_tqdm = not os.isatty(1)\n",
    "for iteration in tqdm(range(num_iterations), desc=\"Training Iterations\", disable=disable_tqdm):\n",
    "    logging.info(f\"-----------Starting iteration {iteration}-----------\")\n",
    "    \n",
    "    # resume = iteration > 0 # resume from the previous checkpoint when iteration > 0\n",
    "    resume = False\n",
    "    \n",
    "    # model_checkpoint is the model checkpoint from the previous iteration\n",
    "    # chosen_rewards and rejected_rewards are the rewards of the data\n",
    "    model_checkpoint, chosen_rewards, rejected_rewards = train_iteration(model,\n",
    "                                model_checkpoint,\n",
    "                                iteration=iteration,\n",
    "                                data_size=data_size_per_iteration,\n",
    "                                sample_size=sample_size,\n",
    "                                ar_model=ar_model,\n",
    "                                ar_tokenizer=ar_tokenizer,\n",
    "                                nar_model=nar_model,\n",
    "                                nar_tokenizer=nar_tokenizer,\n",
    "                                all_src_encodec=batch_src_encodec,\n",
    "                                all_instruction=batch_instruction,\n",
    "                                args_predict=args_predict,\n",
    "                                agent_output_dir=agent_output_dir,\n",
    "                                model_output_dir_base=model_output_dir,\n",
    "                                temperature = 1.0,\n",
    "                                beta=beta,\n",
    "                                base_path=base_path,\n",
    "                                resume_from_checkpoint=resume, \n",
    "                                learning_rate=learning_rate,\n",
    "                                num_train_epochs=num_train_epochs,\n",
    "                                max_length=max_length,\n",
    "                                max_prompt_length=max_prompt_length,\n",
    "                                max_target_length=max_target_length,\n",
    "                                per_device_train_batch_size=per_device_train_batch_size,\n",
    "                                gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                                seed=seed,\n",
    "                                clap_model=clap_model,\n",
    "                                accelerator=accelerator\n",
    "                                )       \n",
    "\n",
    "    logging.info(f\"Chosen rewards for iteration {iteration}: {chosen_rewards}\")\n",
    "    logging.info(f\"Rejected rewards for iteration {iteration}: {rejected_rewards}\")\n",
    "    logging.info(f\"Finished training iteration {iteration}\")\n",
    "\n",
    "    if (iteration+1) % eval_frequency == 0:\n",
    "    # Evaluate the result of the current iteration\n",
    "        if eval_train:\n",
    "            # eval dpo claps\n",
    "            # trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "            #                                                             ar_tokenizer=ar_tokenizer,\n",
    "            #                                                             nar_tokenizer=nar_tokenizer,\n",
    "            #                                                             trained_model=model,\n",
    "            #                                                             args_predict=args_predict,\n",
    "            #                                                             all_src_encodec=selected_src_encodec,\n",
    "            #                                                             all_instruction=selected_instruction,\n",
    "            #                                                             iteration = iteration,\n",
    "            #                                                             num_evaluations = num_eval,\n",
    "            #                                                             eval_data_len=eval_train_data_len,\n",
    "            #                                                             selected_indices=eval_train_indices,\n",
    "            #                                                             device=device,\n",
    "            #                                                             clap_model=clap_model,\n",
    "            #                                                             accelerator=accelerator\n",
    "            #                                                             )\n",
    "            # logging.info(f\"Trained Model Iteration {iteration} Train Set Evaluation: \")\n",
    "            # logging.info(f\"EVAL: Cosine_Sim metrics Training Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            # logging.info(f\"EVAL: Cosine_Sim score Training Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "            \n",
    "            # eval dpo mos\n",
    "            trained_model_metrics_mos, trained_model_rewards_mos = eval_dpo_mos(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_train_data_len,\n",
    "                                                                        selected_indices=eval_train_indices,\n",
    "                                                                        device=device\n",
    "                                                                        )\n",
    "            logging.info(f\"EVAL: MOS metrics Training Set for iteration {iteration}: {trained_model_metrics_mos}\")\n",
    "            logging.info(f\"EVAL: MOS score Training Set for iteration {iteration}: {trained_model_rewards_mos}\")\n",
    "            \n",
    "            # reward_list = []\n",
    "            # for rewards in trained_model_rewards:\n",
    "            #     filter_rewards = [r for r in rewards if r is not None]\n",
    "            #     if len(filter_rewards) == 0:\n",
    "            #         reward_list.append(None)\n",
    "            #     else:\n",
    "            #         reward_list.append(np.mean(filter_rewards))\n",
    "            # logging.info(f\"EVAL: Trained model Cosine_Sim score list on training set: {reward_list}\")\n",
    "            \n",
    "            reward_list_mos = []\n",
    "            for rewards in trained_model_rewards_mos:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list_mos.append(None)\n",
    "                else:\n",
    "                    reward_list_mos.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model MOS score list on training set: {reward_list_mos}\")\n",
    "            \n",
    "            # filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            # if len(filter_reward_list) != 0:\n",
    "            #     logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: {np.mean(filter_reward_list)}\")\n",
    "            # else:\n",
    "            #     logging.info(f\"EVAL: Trained model average Cosine_Sim score on training set for iteration {iteration}: None\")\n",
    "            \n",
    "            filter_reward_list_mos = [r for r in reward_list_mos if r is not None]\n",
    "            if len(filter_reward_list_mos) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: {np.mean(filter_reward_list_mos)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average MOS score on training set for iteration {iteration}: None\")\n",
    "                \n",
    "            # weighted_reward = 0.5 * np.mean(filter_reward_list) + 0.5 * np.mean(filter_reward_list_mos)/5\n",
    "            weighted_reward = np.mean(filter_reward_list_mos)/5\n",
    "            logging.info(f\"EVAL: Trained model weighted average score on training set for iteration {iteration}: {weighted_reward}\")\n",
    "\n",
    "        if eval_test:\n",
    "            trained_model_metrics, trained_model_rewards = eval_dpo_claps_batch(nar_model=nar_model,\n",
    "                                                                        ar_tokenizer=ar_tokenizer,\n",
    "                                                                        nar_tokenizer=nar_tokenizer,\n",
    "                                                                        trained_model=model,\n",
    "                                                                        args_predict=args_predict,\n",
    "                                                                        all_src_encodec=selected_src_encodec,\n",
    "                                                                        all_instruction=selected_instruction,\n",
    "                                                                        iteration = iteration,\n",
    "                                                                        num_evaluations = num_eval,\n",
    "                                                                        eval_data_len=eval_test_data_len,\n",
    "                                                                        selected_indices=eval_test_indices,\n",
    "                                                                        device=device,\n",
    "                                                                        clap_model=clap_model,\n",
    "                                                                        accelerator=accelerator\n",
    "                                                                        )\n",
    "            logging.info(f\"Trained Model Iteration {iteration} Test Set Evaluation: \")\n",
    "            logging.info(f\"EVAL: Cosine_Sim metrics Testing Set for iteration {iteration}: {trained_model_metrics}\")\n",
    "            logging.info(f\"EVAL: Cosine_Sim score Testing Set for iteration {iteration}: {trained_model_rewards}\")\n",
    "\n",
    "            reward_list = []\n",
    "            for rewards in trained_model_rewards:\n",
    "                filter_rewards = [r for r in rewards if r is not None]\n",
    "                if len(filter_rewards) == 0:\n",
    "                    reward_list.append(None)\n",
    "                else:\n",
    "                    reward_list.append(np.mean(filter_rewards))\n",
    "            logging.info(f\"EVAL: Trained model Cosine_Sim score list on testing set: {reward_list}\")\n",
    "            filter_reward_list = [r for r in reward_list if r is not None]\n",
    "            if len(filter_reward_list) != 0:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: {np.mean(filter_reward_list)}\")\n",
    "            else:\n",
    "                logging.info(f\"EVAL: Trained model average Cosine_Sim score on testing set: None\")\n",
    "\n",
    "    logging.info(f\"-----------Finished iteration {iteration}-----------\")\n",
    "total_end_time = time.time()\n",
    "\n",
    "# Calculate total time taken\n",
    "total_time_taken = total_end_time - total_start_time\n",
    "logging.info(f\"Total time taken for the entire process: {total_time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# Function to parse the log file for both EVAL and Original model metrics\n",
    "def parse_log_file(log_path):\n",
    "    eval_pattern = re.compile(\n",
    "        r\"EVAL: Cosine_Sim metrics Training Set for iteration (\\d+): (.+)\"\n",
    "    )\n",
    "    original_model_pattern = re.compile(\n",
    "        r\"Original model metrics on training set: (.+)\"\n",
    "    )\n",
    "    \n",
    "    data = {\"EVAL\": {}, \"Original\": []}\n",
    "\n",
    "    # Read the log file line by line\n",
    "    with open(log_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            eval_match = eval_pattern.search(line)\n",
    "            original_match = original_model_pattern.search(line)\n",
    "\n",
    "            # If it's an EVAL line\n",
    "            if eval_match:\n",
    "                iteration = int(eval_match.group(1)) + 1  # Adding 1 to iteration as requested\n",
    "                metrics_list = eval_match.group(2).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                # Store means and std_devs for this iteration\n",
    "                means = []\n",
    "                std_devs = []\n",
    "                counts = []\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    count = len(metrics['metrics']['rewards'])  # Number of rewards is the sample size\n",
    "\n",
    "                    means.append(mean)\n",
    "                    std_devs.append(std_dev)\n",
    "                    counts.append(count)\n",
    "\n",
    "                # Store mean, std_dev, and count for each iteration\n",
    "                data[\"EVAL\"][iteration] = {\n",
    "                    \"means\": means,\n",
    "                    \"std_devs\": std_devs,\n",
    "                    \"counts\": counts\n",
    "                }\n",
    "\n",
    "            # If it's an Original Model Metrics line\n",
    "            elif original_match:\n",
    "                metrics_list = original_match.group(1).strip()\n",
    "\n",
    "                # Convert the metrics_list string to a Python object (list of dicts)\n",
    "                metrics_list = ast.literal_eval(metrics_list)\n",
    "\n",
    "                for metrics in metrics_list:\n",
    "                    mean = metrics['metrics']['mean']\n",
    "                    std_dev = metrics['metrics']['std_dev']\n",
    "                    data[\"Original\"].append((mean, std_dev))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to calculate the pooled standard deviation\n",
    "def pooled_std_dev(std_devs, counts):\n",
    "    # Pooled variance formula\n",
    "    numerator = sum((counts[i] - 1) * (std_devs[i] ** 2) for i in range(len(std_devs)))\n",
    "    denominator = sum(counts[i] - 1 for i in range(len(counts)))\n",
    "\n",
    "    if denominator > 0:\n",
    "        pooled_variance = numerator / denominator\n",
    "        return np.sqrt(pooled_variance)\n",
    "    else:\n",
    "        return 0  # In case of single value or no variance\n",
    "\n",
    "# Function to plot iteration vs the average mean and pooled std_dev\n",
    "def plot_metrics(data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot EVAL data (average across all idx)\n",
    "    iterations = sorted(data[\"EVAL\"].keys())\n",
    "    avg_means = []\n",
    "    pooled_std_devs = []\n",
    "\n",
    "    for iteration in iterations:\n",
    "        means = data[\"EVAL\"][iteration][\"means\"]\n",
    "        std_devs = data[\"EVAL\"][iteration][\"std_devs\"]\n",
    "        counts = data[\"EVAL\"][iteration][\"counts\"]\n",
    "\n",
    "        # Calculate the average mean for the iteration\n",
    "        avg_mean = sum(means) / len(means)\n",
    "        avg_means.append(avg_mean)\n",
    "\n",
    "        # Calculate the pooled standard deviation for the iteration\n",
    "        pooled_std_dev_value = pooled_std_dev(std_devs, counts)\n",
    "        pooled_std_devs.append(pooled_std_dev_value)\n",
    "\n",
    "    # Plot the average means with pooled std_dev as error bars\n",
    "    plt.errorbar(iterations, avg_means, yerr=pooled_std_devs, fmt='o-', capsize=5, label='Average Mean with Pooled Std Dev')\n",
    "\n",
    "    # Plot Original Model data (if available)\n",
    "    if \"Original\" in data and len(data[\"Original\"]) > 0:\n",
    "        original_means = [item[0] for item in data[\"Original\"]]\n",
    "        original_std_devs = [item[1] for item in data[\"Original\"]]\n",
    "        avg_original_mean = np.mean(original_means)\n",
    "        pooled_original_std_dev = pooled_std_dev(original_std_devs, [10] * len(original_std_devs))  # Assuming 10 samples per idx\n",
    "\n",
    "        plt.errorbar([0], [avg_original_mean], yerr=[pooled_original_std_dev], fmt='x', color='r', label='Original Model Average Mean')\n",
    "\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Mean')\n",
    "    plt.title('Iteration vs Average Mean with Pooled Std Dev')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Parse the log file\n",
    "data = parse_log_file(log_path)\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
