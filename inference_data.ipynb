{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/b0990106x/miniconda3/envs/trl/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(59481, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=59481, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from vc.trainer_encodec_vc_inference import pack_inputs_v2\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load the model\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 0613-1859\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# define the path\n",
    "base_path = \"/work/b0990106x/trl\"\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "# if not os.path.exists(agent_output_dir):\n",
    "#     os.makedirs(agent_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = load_from_disk(agent_input_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_id', 'instruction', 'transcription', 'src_encodec_0', 'src_encodec_1', 'src_encodec_2', 'src_encodec_3', 'src_encodec_4', 'src_encodec_5', 'src_encodec_6', 'src_encodec_7', 'tgt_encodec_0', 'tgt_encodec_1', 'tgt_encodec_2', 'tgt_encodec_3', 'tgt_encodec_4', 'tgt_encodec_5', 'tgt_encodec_6', 'tgt_encodec_7'],\n",
      "    num_rows: 9957\n",
      "})\n",
      "data_len: 9957\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "data_len = len(dataset)\n",
    "print(\"data_len:\", data_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "sys.path.append(\"/work/b0990106x/trl/vc\") \n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction_v2, get_ar_prediction\n",
    "\n",
    "# Assuming `pack_inputs_v2` and `ar_tokenizer` are already defined\n",
    "\n",
    "observation_list = []\n",
    "decode_obs_input_str = []\n",
    "all_src_encodec_layers = []\n",
    "\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "all_tgt_encodec = []\n",
    "\n",
    "all_tgt_encodec_layers = []\n",
    "\n",
    "layer_len = 8\n",
    "# data_len = len(dataset)  # Assuming you have a defined `data_len`\n",
    "\n",
    "\n",
    "\n",
    "# size_of_packed_input = (len(single_src_encodec[0]) + len(ar_tokenizer(single_instruction)[\"input_ids\"][1:-1])+ 3)\n",
    "\n",
    "# if size_of_packed_input > 1024 or size_of_packed_input < 4:\n",
    "#     print(\n",
    "#         f\"Notice: Packed input size too large or too small for processing: {size_of_packed_input} elements. Instruction: '{single_instruction}'\"\n",
    "#     )\n",
    "#     continue  # Continue to select a new random item\n",
    "\n",
    "\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "    all_tgt_encodec_layers.append(dataset[f\"tgt_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    tgt_encodec = []\n",
    "    for j in range(layer_len):\n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "        tgt_encodec.append(all_tgt_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "    all_tgt_encodec.append(tgt_encodec)\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    \n",
    "\n",
    "for i in range(data_len):\n",
    "    observation_list.append(\n",
    "        {\n",
    "            \"input\": \"\",\n",
    "            \"src_encodec\": [all_src_encodec_layers[j][i] for j in range(layer_len)],\n",
    "            \"instruction\": all_instruction[i],\n",
    "            \"tgt_encodec\": [all_tgt_encodec_layers[j][i] for j in range(layer_len)],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the 'prompt' values\n",
    "prompts = []\n",
    "chosen = []\n",
    "rejected = []\n",
    "\n",
    "for obs in observation_list:\n",
    "    obs_input = pack_inputs_v2(ar_tokenizer, obs[\"src_encodec\"], obs[\"instruction\"])\n",
    "    tgt_encodec = obs[\"tgt_encodec\"]\n",
    "    \n",
    "    tokenize_tgt_encodec = ar_tokenizer.convert_tokens_to_string(\n",
    "                [f\"v_tok_{u}\" for u in tgt_encodec[0]]\n",
    "            )  \n",
    "    tokenize_input= ar_tokenizer.convert_ids_to_tokens(obs_input)\n",
    "    tokenize_input_str = ar_tokenizer.convert_tokens_to_string(tokenize_input)\n",
    "    prompts.append(tokenize_input_str)\n",
    "    chosen.append(tokenize_tgt_encodec)\n",
    "\n",
    "args = SimpleNamespace(output_path=f\"{base_path}/output/{ts}/example.wav\", seed=0, device=device)\n",
    "\n",
    "for i in range(data_len):\n",
    "    single_src_encodec = all_src_encodec[i]\n",
    "    single_instruction = all_instruction[i]\n",
    "    try:\n",
    "        predicted_ids, decode_ar = get_ar_prediction(args, ar_model, nar_model, ar_tokenizer, nar_tokenizer, single_src_encodec, single_instruction, episode_counter=0)\n",
    "    except Exception as e:\n",
    "        print(\"i:\", i)\n",
    "        print(\"single_src_encodec:\", single_src_encodec)\n",
    "        print(\"single_instruction:\", single_instruction)\n",
    "        print(e)\n",
    "        break\n",
    "    decode_ar_list = decode_ar.flatten().tolist()\n",
    "    decode_ar_tokens = ar_tokenizer.convert_ids_to_tokens(decode_ar_list)\n",
    "    decode_ar_str = ar_tokenizer.convert_tokens_to_string(\n",
    "                [f\"v_tok_{u}\" for u in predicted_ids]\n",
    "            ) \n",
    "    rejected.append(decode_ar_str)\n",
    "\n",
    "\n",
    "# Construct the JSON structure\n",
    "data = {\n",
    "    \"prompt\": prompts,\n",
    "    \"chosen\": chosen,  # Placeholder for chosen responses\n",
    "    \"rejected\": rejected  # Placeholder for rejected responses\n",
    "}\n",
    "\n",
    "# Save the JSON to a file\n",
    "with open(\"dpo_data_all.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
